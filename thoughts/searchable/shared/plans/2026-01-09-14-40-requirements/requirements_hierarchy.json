{
  "requirements": [
    {
      "id": "REQ_000",
      "description": "The UI must be a typical conversation UI built using Svelte framework",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_000.1",
          "description": "Implement Svelte component architecture",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.implement",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_000.2",
          "description": "Design and implement the core layout for the conversation UI, adhering to the requested three-column structure: left sidebar for projects/conversations, center panel for the chat, and a file attachment area.  This includes defining the responsive behavior for different screen sizes.",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "The UI renders a three-column layout as specified.",
            "The left sidebar is collapsible/expandable.",
            "The center panel displays the conversation messages.",
            "The file attachment area is clearly defined and functional.",
            "The layout adapts correctly to different screen sizes (desktop, tablet, mobile).",
            "UI elements are accessible and usable according to accessibility guidelines."
          ],
          "implementation": {
            "frontend": [
              "Svelte components for the sidebar, chat panel, file attachment area, and message display.",
              "CSS styling for the layout and UI elements.",
              "JavaScript for handling user interactions (e.g., expanding/collapsing the sidebar, attaching files)."
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "UI component definitions (e.g., Message, Attachment, FileInput)",
              "Configuration for UI styles and themes"
            ]
          },
          "testable_properties": [],
          "function_id": "UI_ConversationLayout",
          "related_concepts": [
            "Svelte",
            "UI Design",
            "Responsive Design",
            "Sidebar Layout",
            "Chat Interface"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.2.1",
          "description": "Implement the functionality for users to attach files to the conversation. This includes a file input element, a preview mechanism, and handling of file uploads.",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "Users can drag and drop files into the attachment area.",
            "Users can select files from the file system using a file input element.",
            "Uploaded files are displayed as thumbnails or previews.",
            "Files are securely uploaded to the backend.",
            "Error handling for invalid file types or upload failures."
          ],
          "implementation": {
            "frontend": [
              "Svelte component for the file attachment area.",
              "File input element.",
              "Drag and drop handlers.",
              "Image preview component."
            ],
            "backend": [
              "API endpoint for receiving file uploads.",
              "File storage mechanism (e.g., cloud storage, local storage)."
            ],
            "middleware": [],
            "shared": [
              "File upload configuration",
              "File storage settings"
            ]
          },
          "testable_properties": [],
          "function_id": "UI_AttachmentArea",
          "related_concepts": [
            "File Upload",
            "Drag and Drop",
            "File Preview",
            "Frontend I/O"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.2.2",
          "description": "Integrate a speech-to-text service (e.g., Whisper) to transcribe audio recordings into text. This includes capturing audio, sending it to the transcription service, and displaying the transcribed text.",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "The UI allows users to record audio.",
            "The recorded audio is sent to a speech-to-text service.",
            "The transcribed text is displayed in the conversation.",
            "The transcription process is reasonably accurate.",
            "The UI provides feedback on the transcription progress."
          ],
          "implementation": {
            "frontend": [
              "Svelte component for the audio recording interface.",
              "Audio recording element (e.g., using the MediaRecorder API).",
              "UI elements for displaying the transcription progress."
            ],
            "backend": [
              "API endpoint for sending audio to the transcription service.",
              "Integration with the chosen speech-to-text service (e.g., Whisper).",
              "Server-side processing of the transcription results."
            ],
            "middleware": [],
            "shared": [
              "Configuration for the speech-to-text service.",
              "Audio processing libraries (if needed)."
            ]
          },
          "testable_properties": [],
          "function_id": "Audio_Transcription_Integration",
          "related_concepts": [
            "Speech-to-Text",
            "Audio Recording",
            "Transcription Service",
            "Real-time Processing"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.2.3",
          "description": "Leverage the existing agent orchestration framework (Python + Go) to manage the overall workflow of the writing agent.",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "The agent can be triggered to initiate the writing process.",
            "The agent can handle the different stages of the workflow (e.g., file ingestion, theme extraction, content generation).",
            "The agent can manage the context window array (CWA).",
            "The agent can integrate with the Claude/GPT-4 LLM.",
            "The agent can checkpoint and resume the workflow."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Python and Go orchestrators.",
              "Integration with the Claude/GPT-4 LLM.",
              "Configuration for the workflow stages."
            ],
            "middleware": [],
            "shared": [
              "Configuration for the workflow stages.",
              "LLM integration settings."
            ]
          },
          "testable_properties": [],
          "function_id": "Agent_Orchestration",
          "related_concepts": [
            "Agent Orchestration",
            "Workflow Management",
            "Parallel Processing",
            "Claude/GPT-4 Integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.3",
          "description": "Set up Svelte project structure",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.set",
          "related_concepts": [],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_001",
      "description": "The system must have a left column for displaying project folders and conversations",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_001.1",
          "description": "Create a reusable sidebar component with collapsible sections, responsive layout, and proper accessibility attributes for navigation",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Sidebar component renders with fixed left positioning and configurable width (default 280px)",
            "Component accepts props for collapsed/expanded state with smooth CSS transitions",
            "Sidebar includes header section for branding/title and scrollable content area",
            "Component is keyboard navigable with proper ARIA labels and roles",
            "Sidebar collapses to icon-only view on mobile screens (<768px)",
            "Component exposes events for collapse/expand actions",
            "Sidebar maintains scroll position when navigating between views",
            "Component supports light/dark theme variants"
          ],
          "implementation": {
            "frontend": [
              "Create Sidebar.svelte component with slot-based content composition",
              "Implement collapse/expand animation using CSS transitions",
              "Add responsive breakpoint handling for mobile/desktop views",
              "Create SidebarHeader and SidebarContent sub-components",
              "Implement keyboard navigation (Tab, Arrow keys, Enter)",
              "Add ARIA attributes (role='navigation', aria-label, aria-expanded)",
              "Style component with CSS variables for theming support",
              "Add resize handle for user-adjustable width (optional)"
            ],
            "backend": [
              "Create GET /api/user/preferences endpoint to retrieve sidebar state",
              "Create PATCH /api/user/preferences endpoint to persist collapsed/width state",
              "Implement user preference schema in database (sidebar_collapsed, sidebar_width)"
            ],
            "middleware": [
              "Add authentication check for user preference endpoints",
              "Validate sidebar width values (min: 200px, max: 500px)",
              "Add rate limiting for preference update requests"
            ],
            "shared": [
              "Define SidebarProps interface (collapsed: boolean, width: number, theme: string)",
              "Create SidebarState type for component state management",
              "Define UserPreferences model including sidebar configuration",
              "Create constants for default sidebar dimensions and breakpoints"
            ]
          },
          "testable_properties": [],
          "function_id": "Sidebar.createComponent",
          "related_concepts": [
            "component architecture",
            "UI layout",
            "accessibility",
            "responsive design",
            "state management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.2",
          "description": "Implement hierarchical project folder navigation with expand/collapse functionality, drag-and-drop reordering, and visual indicators for active selection",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Project folders display in hierarchical tree structure with proper indentation (16px per level)",
            "Users can expand/collapse folders by clicking chevron icon or folder name",
            "Active project/folder is visually highlighted with distinct background color",
            "Folder icons change based on expanded/collapsed state",
            "Empty folders display 'No items' placeholder message",
            "Folder tree persists expansion state across page refreshes",
            "Users can create new folders with right-click context menu or '+' button",
            "Folders support drag-and-drop reordering within same parent",
            "Folder names are editable inline with validation (no special characters, max 100 chars)",
            "Long folder names truncate with ellipsis and show full name on hover tooltip"
          ],
          "implementation": {
            "frontend": [
              "Create ProjectFolder.svelte component for individual folder rendering",
              "Create ProjectTree.svelte component for hierarchical tree structure",
              "Implement recursive rendering for nested folder levels",
              "Add expand/collapse animation with chevron rotation",
              "Implement drag-and-drop using HTML5 Drag API or SortableJS",
              "Create context menu component for folder actions (New, Rename, Delete)",
              "Add inline editing mode for folder name with validation",
              "Implement active selection state management using Svelte stores",
              "Add folder icon components (open/closed states)",
              "Create tooltip component for truncated folder names",
              "Implement keyboard navigation (Arrow keys for navigation, Enter to expand/collapse)"
            ],
            "backend": [
              "Create GET /api/projects endpoint to fetch project folder hierarchy",
              "Create POST /api/projects/folders endpoint to create new folder",
              "Create PATCH /api/projects/folders/:id endpoint to rename folder",
              "Create DELETE /api/projects/folders/:id endpoint to delete folder",
              "Create PATCH /api/projects/folders/:id/move endpoint for drag-and-drop reordering",
              "Implement hierarchical query to fetch nested folder structure",
              "Add validation for folder name uniqueness within parent",
              "Implement soft delete for folders with archive functionality"
            ],
            "middleware": [
              "Add authentication to verify user owns/has access to project",
              "Validate folder name format (alphanumeric, spaces, hyphens only)",
              "Check folder depth limit (max 5 levels to prevent excessive nesting)",
              "Validate move operations to prevent circular references",
              "Add authorization checks for folder create/update/delete operations"
            ],
            "shared": [
              "Define ProjectFolder interface (id, name, parentId, order, children, isExpanded)",
              "Create FolderTreeNode type for recursive tree structure",
              "Define FolderValidation rules (name pattern, max length, depth limit)",
              "Create utility function buildFolderTree(flatFolders) for hierarchy construction",
              "Define FolderActionType enum (Create, Rename, Delete, Move)",
              "Create constants for folder constraints (MAX_DEPTH, MAX_NAME_LENGTH)"
            ]
          },
          "testable_properties": [],
          "function_id": "ProjectNavigation.implementFolderTree",
          "related_concepts": [
            "tree view",
            "hierarchical data",
            "drag and drop",
            "file system navigation",
            "project structure"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.3",
          "description": "Display searchable, filterable list of conversations with timestamps, preview text, unread indicators, and infinite scroll pagination",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Conversations display in reverse chronological order (newest first)",
            "Each conversation item shows title, timestamp, and last message preview (max 60 chars)",
            "Unread conversations show badge with unread message count",
            "Active conversation is highlighted with distinct background color",
            "Search bar filters conversations by title or message content with debounced input (300ms)",
            "Filter dropdown allows filtering by date range, folder, or unread status",
            "List supports infinite scroll loading 20 conversations at a time",
            "Empty state displays 'No conversations' message with 'Start New' CTA",
            "Conversation items show participant avatars/names for group conversations",
            "Right-click context menu provides actions (Rename, Archive, Delete, Mark as Read)",
            "New messages update conversation order in real-time without page refresh",
            "Archived conversations are hidden by default with toggle to show/hide"
          ],
          "implementation": {
            "frontend": [
              "Create ConversationList.svelte component for list container",
              "Create ConversationItem.svelte component for individual conversation",
              "Implement search input with debounced filtering using Svelte reactive statements",
              "Create FilterDropdown.svelte component for date/folder/status filters",
              "Implement infinite scroll using Intersection Observer API",
              "Add UnreadBadge.svelte component for message count display",
              "Create context menu component for conversation actions",
              "Implement optimistic UI updates for real-time message arrivals",
              "Add skeleton loading states for initial load and pagination",
              "Create EmptyState.svelte component with 'Start New Conversation' button",
              "Implement conversation item hover effects and active state styling",
              "Add timestamp formatting utility (relative time: '2 hours ago', etc.)"
            ],
            "backend": [
              "Create GET /api/conversations endpoint with pagination (limit, offset)",
              "Add query parameters for search (q), filter (folder_id, unread, date_range)",
              "Create GET /api/conversations/:id/unread-count endpoint",
              "Create PATCH /api/conversations/:id endpoint to update title or archive status",
              "Create DELETE /api/conversations/:id endpoint for soft delete",
              "Create PATCH /api/conversations/:id/mark-read endpoint",
              "Implement full-text search on conversation titles and message content",
              "Add WebSocket or SSE endpoint for real-time conversation updates",
              "Create database indexes on created_at, folder_id, user_id for query performance",
              "Implement archive/unarchive logic with is_archived flag"
            ],
            "middleware": [
              "Add authentication to verify user access to conversations",
              "Validate pagination parameters (limit max 50, offset >= 0)",
              "Sanitize search query to prevent SQL injection",
              "Add rate limiting for search endpoint (max 10 requests/minute)",
              "Validate filter parameters (valid date formats, existing folder IDs)",
              "Add authorization to ensure user can only access their own conversations"
            ],
            "shared": [
              "Define Conversation interface (id, title, folder_id, last_message_at, unread_count, is_archived, participants)",
              "Create ConversationPreview type (conversation + last_message_preview)",
              "Define ConversationFilter interface (search_query, folder_id, is_unread, date_from, date_to)",
              "Create PaginationParams type (limit, offset, total)",
              "Define ConversationSortOrder enum (Recent, Alphabetical, Unread)",
              "Create utility function formatRelativeTime(timestamp) for display",
              "Define WebSocketMessage type for real-time conversation updates",
              "Create constants for pagination defaults (DEFAULT_PAGE_SIZE: 20, MAX_PAGE_SIZE: 50)"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationList.displayConversations",
          "related_concepts": [
            "conversation history",
            "list rendering",
            "search",
            "filtering",
            "pagination",
            "real-time updates"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.4",
          "description": "Implement centralized state management for tracking selected folder and conversation with URL synchronization, browser history integration, and persistence",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Selected folder ID is stored in global state accessible across components",
            "Selected conversation ID is stored in global state accessible across components",
            "Selection state syncs with URL parameters (e.g., ?folder=123&conversation=456)",
            "Browser back/forward buttons correctly navigate between selections",
            "URL updates without full page reload when selection changes",
            "Last selected folder/conversation persists in localStorage for session restoration",
            "Selecting new folder clears conversation selection and loads folder's conversations",
            "Selecting conversation auto-selects its parent folder if different",
            "Invalid folder/conversation IDs in URL redirect to default view",
            "State change triggers reactive updates in all dependent components",
            "Deep links to specific conversations work correctly on page load"
          ],
          "implementation": {
            "frontend": [
              "Create selectionStore.ts Svelte writable store for folder/conversation state",
              "Implement selectFolder(folderId) action that updates store and URL",
              "Implement selectConversation(conversationId) action that updates store and URL",
              "Create URL synchronization service using SvelteKit's goto() and page store",
              "Add popstate event listener for browser back/forward navigation",
              "Implement localStorage persistence with 'lastSelectedFolder' and 'lastSelectedConversation' keys",
              "Create derived store for computed selection state (isConversationSelected, currentFolder)",
              "Add validation logic for folder/conversation ID existence before setting state",
              "Implement clearSelection() action for resetting to default state",
              "Create selectionHistory store for tracking navigation history",
              "Add reactive subscriptions in components to respond to state changes"
            ],
            "backend": [
              "Create GET /api/conversations/:id/folder endpoint to fetch conversation's parent folder",
              "Create GET /api/folders/:id/exists endpoint for validation",
              "Create GET /api/conversations/:id/exists endpoint for validation",
              "Add folder and conversation existence checks in relevant endpoints"
            ],
            "middleware": [
              "Add authentication for folder/conversation existence validation",
              "Validate folder_id and conversation_id format (UUID or integer)",
              "Add authorization to verify user has access to specified resources"
            ],
            "shared": [
              "Define SelectionState interface (selectedFolderId: string | null, selectedConversationId: string | null)",
              "Create SelectionAction type union (SelectFolder | SelectConversation | ClearSelection)",
              "Define URLParams interface for route parameter parsing",
              "Create utility function parseSelectionFromURL(searchParams) to extract IDs",
              "Create utility function buildSelectionURL(folderId, conversationId) for URL construction",
              "Define StorageKeys constants (LAST_FOLDER_KEY, LAST_CONVERSATION_KEY)",
              "Create type guard functions isValidFolderId() and isValidConversationId()",
              "Define SelectionDefaults constants (DEFAULT_FOLDER_ID, fallback behavior)"
            ]
          },
          "testable_properties": [],
          "function_id": "SelectionState.manageFolderConversationSelection",
          "related_concepts": [
            "state management",
            "routing",
            "URL parameters",
            "browser history",
            "local storage",
            "reactive stores"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_002",
      "description": "The system must have a center column for displaying the conversation and messages",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_002.1",
          "description": "Create a message list component that displays all messages in the conversation with proper structure and styling",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Component must accept an array of message objects as props",
            "Component must render messages in chronological order (oldest to newest)",
            "Component must handle empty state (no messages yet)",
            "Component must support message grouping by sender and time proximity",
            "Component must display user avatars or initials for each message sender",
            "Component must show message timestamps in human-readable format",
            "Component must be responsive and adapt to different screen sizes",
            "Component must support both user messages and agent/assistant messages with distinct styling",
            "Component must handle loading states during message fetching",
            "Component must optimize rendering performance for large message lists (100+ messages)"
          ],
          "implementation": {
            "frontend": [
              "MessageList.svelte component with message array prop binding",
              "Message item subcomponent for individual message rendering",
              "Empty state placeholder UI when no messages exist",
              "Loading skeleton UI during data fetch",
              "Responsive CSS grid or flexbox layout",
              "Message grouping logic based on sender and timestamp proximity",
              "Avatar component with initials fallback",
              "Timestamp formatting utility integration",
              "Distinct styling for user vs. assistant messages (alignment, colors, borders)",
              "Virtual scrolling implementation for performance optimization"
            ],
            "backend": [
              "GET /api/conversations/{conversationId}/messages endpoint to fetch messages",
              "Pagination support with limit and offset query parameters",
              "Message data transformation service to format timestamps and metadata",
              "Message ordering logic ensuring chronological delivery",
              "Filtering service to exclude deleted or hidden messages"
            ],
            "middleware": [
              "Authentication middleware to verify user access to conversation",
              "Authorization check ensuring user owns or has access to the conversation",
              "Rate limiting on message fetch endpoint to prevent abuse",
              "Request validation for conversationId parameter",
              "Response caching headers for message list endpoint"
            ],
            "shared": [
              "Message data model with fields: id, conversationId, senderId, senderType (user|assistant), content, timestamp, metadata",
              "MessageList interface defining component props structure",
              "Timestamp formatting utility function (relative time, absolute time)",
              "Message grouping utility function based on sender and time threshold",
              "Avatar generation utility for initials and color assignment",
              "Message type enum (text, audio, attachment, system)",
              "Constants for message grouping time threshold (e.g., 5 minutes)"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageList.renderMessages",
          "related_concepts": [
            "component architecture",
            "list rendering",
            "virtual scrolling",
            "message grouping",
            "timestamp formatting",
            "user avatars",
            "message metadata"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.2",
          "description": "Implement message rendering logic that supports multiple content types including text, audio transcriptions, file attachments, and system notifications",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Renderer must support plain text messages with proper line breaks and formatting",
            "Renderer must support markdown formatting (bold, italic, lists, links, code blocks)",
            "Renderer must sanitize user input to prevent XSS attacks",
            "Renderer must display code blocks with syntax highlighting",
            "Renderer must render audio transcriptions with playback controls",
            "Renderer must display file attachment previews with download links",
            "Renderer must show extracted themes as highlighted tags or badges",
            "Renderer must handle system messages differently (e.g., 'User joined', 'Conversation started')",
            "Renderer must support streaming content updates for AI-generated responses",
            "Renderer must handle error states for failed content rendering",
            "Renderer must preserve whitespace and formatting in code blocks",
            "Renderer must make URLs clickable and open in new tabs"
          ],
          "implementation": {
            "frontend": [
              "MessageContent.svelte component with content type detection",
              "Markdown renderer integration (e.g., marked.js or remark)",
              "Code syntax highlighter integration (e.g., Prism.js or highlight.js)",
              "Audio player component with waveform visualization",
              "Attachment preview component with thumbnail and metadata display",
              "Theme badge component for displaying extracted themes",
              "System message styling component with icon and muted appearance",
              "Streaming text component with cursor animation for AI responses",
              "Error boundary component for rendering failures",
              "Content sanitization utility to prevent XSS",
              "URL detection and auto-linking utility",
              "Whitespace preservation CSS for code blocks"
            ],
            "backend": [
              "Content type detection service analyzing message metadata",
              "Markdown to HTML conversion service (server-side option)",
              "File metadata retrieval service for attachment rendering",
              "Audio file URL generation service with signed URLs",
              "Theme extraction result formatting service",
              "Content sanitization service for dangerous HTML/scripts",
              "Streaming message endpoint supporting Server-Sent Events (SSE)"
            ],
            "middleware": [
              "Content-Security-Policy headers to prevent XSS",
              "File access authorization for attachment preview URLs",
              "Rate limiting on streaming message endpoints",
              "CORS configuration for audio file access",
              "Request validation for content type parameters"
            ],
            "shared": [
              "MessageContent type union (TextContent | AudioContent | AttachmentContent | SystemContent)",
              "ContentType enum (text, markdown, code, audio, attachment, system)",
              "AttachmentMetadata model with fields: fileName, fileSize, mimeType, url",
              "AudioMetadata model with fields: duration, transcription, waveformData, audioUrl",
              "Theme model with fields: name, confidence, keywords",
              "Sanitization configuration constants (allowed HTML tags, attributes)",
              "Markdown rendering options configuration",
              "Code language detection utility",
              "Content streaming event types (start, delta, complete, error)"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageRenderer.renderContent",
          "related_concepts": [
            "content type handling",
            "markdown rendering",
            "code syntax highlighting",
            "attachment preview",
            "audio player integration",
            "theme display",
            "rich text formatting",
            "XSS protection"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.3",
          "description": "Display the complete conversation thread with proper context, including conversation metadata, participant information, and thread navigation",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Component must display conversation title at the top of the thread",
            "Component must show conversation participants with avatars and names",
            "Component must display conversation creation date and last activity timestamp",
            "Component must show conversation status (active, archived, paused)",
            "Component must display extracted themes for the entire conversation",
            "Component must show typing indicators when agent is generating response",
            "Component must handle conversation loading state with skeleton UI",
            "Component must support conversation header actions (archive, settings, export)",
            "Component must display unread message count and mark messages as read on scroll",
            "Component must show conversation context (project folder, tags, categories)",
            "Component must handle error states (conversation not found, access denied)",
            "Component must auto-refresh when new messages arrive in real-time"
          ],
          "implementation": {
            "frontend": [
              "ConversationThread.svelte main container component",
              "ConversationHeader.svelte with title, metadata, and action buttons",
              "ParticipantList.svelte showing conversation participants",
              "ConversationContext.svelte displaying project folder and tags",
              "TypingIndicator.svelte animated component for AI response generation",
              "ConversationStatus badge component (active, archived, paused)",
              "Theme summary component displaying conversation-level themes",
              "Skeleton loader for conversation thread loading state",
              "Error state component for access denied or not found errors",
              "Action menu component (archive, export, settings, delete)",
              "Unread message counter with scroll-to-unread functionality",
              "Real-time WebSocket connection for live updates",
              "Intersection Observer for read receipt marking",
              "Auto-scroll to bottom on new messages"
            ],
            "backend": [
              "GET /api/conversations/{conversationId} endpoint for conversation metadata",
              "GET /api/conversations/{conversationId}/participants endpoint",
              "GET /api/conversations/{conversationId}/themes endpoint for aggregated themes",
              "PATCH /api/conversations/{conversationId}/status endpoint for status updates",
              "POST /api/conversations/{conversationId}/mark-read endpoint",
              "WebSocket endpoint /ws/conversations/{conversationId} for real-time updates",
              "Conversation aggregation service computing statistics and summaries",
              "Participant resolution service mapping user IDs to user profiles",
              "Theme aggregation service combining themes across all messages",
              "Real-time notification service pushing updates via WebSocket"
            ],
            "middleware": [
              "Authentication middleware for conversation access",
              "Authorization middleware checking user permissions (owner, viewer, editor)",
              "WebSocket authentication and connection management",
              "Rate limiting on conversation metadata endpoints",
              "Request validation for conversationId format",
              "Conversation access logging for audit trails"
            ],
            "shared": [
              "Conversation model with fields: id, title, projectId, status, createdAt, updatedAt, participantIds, metadata",
              "ConversationStatus enum (active, archived, paused, deleted)",
              "Participant model with fields: userId, role, joinedAt, avatar, displayName",
              "ConversationMetadata model with fields: messageCount, unreadCount, lastMessageAt, themes",
              "WebSocketMessage type union for real-time events (newMessage, typing, statusChange)",
              "ConversationContext model with projectFolder, tags, categories",
              "TypingState enum (idle, typing, generating)",
              "Theme aggregation utility combining and deduplicating themes",
              "Timestamp utility for relative time display",
              "Constants for auto-refresh intervals and WebSocket reconnection logic"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationThread.displayThread",
          "related_concepts": [
            "conversation context",
            "thread management",
            "participant tracking",
            "conversation metadata",
            "thread navigation",
            "conversation state",
            "read receipts",
            "typing indicators"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.4",
          "description": "Add a scrollable message area with intelligent auto-scroll behavior, scroll-to-bottom button, infinite scroll for message history, and scroll position preservation",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Container must be scrollable with smooth scrolling enabled",
            "Container must auto-scroll to bottom when new messages arrive if user is at bottom",
            "Container must NOT auto-scroll if user has scrolled up to read history",
            "Container must show a 'scroll to bottom' button when user scrolls up (with unread count)",
            "Container must implement infinite scroll loading older messages when scrolling to top",
            "Container must preserve scroll position after loading older messages",
            "Container must detect when user is 'near bottom' (within 100px threshold)",
            "Container must handle rapid message arrivals without scroll jank",
            "Container must restore scroll position on component remount (browser back/forward)",
            "Container must provide visual feedback during history loading (spinner at top)",
            "Container must handle window resize without losing scroll position",
            "Container must optimize scroll performance with debouncing and throttling",
            "Container must support keyboard navigation (Page Up/Down, Home/End)"
          ],
          "implementation": {
            "frontend": [
              "ScrollableMessageArea.svelte wrapper component with overflow-y scroll",
              "Scroll event listener with throttling for performance",
              "IntersectionObserver for detecting top/bottom visibility",
              "ScrollToBottom button component with unread count badge",
              "Infinite scroll trigger component at top of message list",
              "Scroll position state management (isAtBottom, lastScrollTop)",
              "Auto-scroll logic based on user scroll state",
              "Smooth scroll animation utility",
              "Scroll position preservation on history load using anchor element",
              "Loading spinner component for history fetch",
              "Keyboard event handlers for Page Up/Down/Home/End",
              "Window resize event listener for scroll adjustment",
              "Near-bottom detection utility (within threshold)",
              "Scroll restoration on component mount from browser history"
            ],
            "backend": [
              "GET /api/conversations/{conversationId}/messages pagination with cursor-based or offset-based approach",
              "Message history endpoint supporting 'before' parameter for loading older messages",
              "Configurable page size for message batches (default 50 messages)",
              "Total message count endpoint for scroll position calculations",
              "Message batch prefetching service for smoother infinite scroll"
            ],
            "middleware": [
              "Authentication for message history access",
              "Rate limiting on message history endpoint to prevent abuse",
              "Cache headers for message history responses",
              "Request validation for pagination parameters (before, limit)"
            ],
            "shared": [
              "ScrollState model with fields: isAtBottom, lastScrollTop, isLoadingHistory, hasMoreMessages",
              "MessagePage model with fields: messages, cursor, hasMore, totalCount",
              "ScrollBehavior enum (auto, smooth, instant)",
              "Scroll threshold constants (NEAR_BOTTOM_THRESHOLD = 100px)",
              "Throttle/debounce utility functions for scroll events",
              "Pagination cursor utility for encoding/decoding message IDs",
              "Scroll position storage interface for browser history integration",
              "Message batch size constant (DEFAULT_PAGE_SIZE = 50)",
              "Infinite scroll configuration options (threshold, prefetch distance)"
            ]
          },
          "testable_properties": [],
          "function_id": "ScrollableMessageArea.manageScroll",
          "related_concepts": [
            "scroll management",
            "auto-scroll behavior",
            "infinite scroll",
            "scroll position preservation",
            "viewport detection",
            "performance optimization",
            "user scroll detection",
            "scroll anchoring"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_003",
      "description": "The user message area must allow for file attachments",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_003.1",
          "description": "Implement a reusable file upload component in Svelte that allows users to select files from their filesystem with support for multiple file types and size validation",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Component renders a visible file input button or trigger element",
            "Component accepts configuration for allowed file types (e.g., images, documents, audio)",
            "Component validates file size against configurable maximum (e.g., 10MB default)",
            "Component supports single and multiple file selection modes",
            "Component displays error messages for invalid file types or sizes",
            "Component emits events when files are selected or validation fails",
            "Component is keyboard accessible and screen reader compatible",
            "Component shows loading state during file processing",
            "Component integrates with existing Svelte form patterns",
            "Component can be styled to match application design system"
          ],
          "implementation": {
            "frontend": [
              "Svelte component FileUpload.svelte with props for maxSize, allowedTypes, multiple",
              "File input element with change event listener",
              "File validation logic for type and size checking",
              "Error display UI for validation failures",
              "File selection event emitter to parent components",
              "Loading spinner or progress indicator",
              "Accessible labels and ARIA attributes",
              "Styling with Tailwind CSS or component styles"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "FileValidationConfig interface defining maxSize, allowedTypes",
              "FILE_UPLOAD_CONSTANTS for default sizes and types",
              "validateFile utility function for client-side validation",
              "FileUploadError type for error handling"
            ]
          },
          "testable_properties": [],
          "function_id": "FileUploadComponent.render",
          "related_concepts": [
            "File input element",
            "File type validation",
            "File size constraints",
            "Multiple file selection",
            "Accessible file upload",
            "Error messaging",
            "Loading states"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.2",
          "description": "Create an intuitive drag-and-drop zone that allows users to drag files from their desktop and drop them into the message input area with visual feedback during drag operations",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Drop zone highlights or changes appearance when user drags files over it",
            "Drop zone accepts files dropped from desktop or file explorer",
            "Drop zone prevents default browser behavior (opening file in new tab)",
            "Drop zone validates dropped files using same rules as file input",
            "Drop zone provides visual feedback for drag states (hover, active, invalid)",
            "Drop zone works in conjunction with file upload component",
            "Drop zone displays helpful instructional text when empty",
            "Drop zone handles edge cases (dragging non-file items, multiple files when single mode)",
            "Drop zone is responsive and works on different screen sizes",
            "Drop zone maintains functionality when files are already attached"
          ],
          "implementation": {
            "frontend": [
              "DragDropZone.svelte component wrapping message input area",
              "Event listeners for dragenter, dragover, dragleave, drop events",
              "State management for drag active/hover states",
              "Visual styling for different drag states (idle, hover, active, error)",
              "File extraction from dataTransfer object",
              "Integration with file validation logic from shared utilities",
              "Instructional text overlay ('Drag files here or click to upload')",
              "Prevent default dragover and drop behaviors",
              "Emit file selection events to parent components"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "extractFilesFromDataTransfer utility function",
              "DragDropState type definition (idle, hover, active, error)",
              "File validation utilities (reused from FileUploadComponent)"
            ]
          },
          "testable_properties": [],
          "function_id": "DragDropZone.handleDrop",
          "related_concepts": [
            "Drag and drop API",
            "Drop zone visual states",
            "File dataTransfer",
            "Drag enter/leave/over events",
            "Drop event handling",
            "Visual feedback",
            "Accessibility considerations"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.3",
          "description": "Handle FormData submission that bundles message text and file attachments into a single multipart/form-data request to the backend API",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Form submission constructs FormData object with message text and all attached files",
            "Submission uses multipart/form-data content type",
            "Submission includes file metadata (name, type, size) in request",
            "Submission handles both text-only and text-with-attachments cases",
            "Submission shows upload progress for large files",
            "Submission disables submit button during upload to prevent duplicates",
            "Submission handles network errors gracefully with user feedback",
            "Submission validates all files before sending request",
            "Submission clears attachments from UI after successful upload",
            "Submission includes conversation ID or context in request payload",
            "Submission supports cancellation of in-progress uploads"
          ],
          "implementation": {
            "frontend": [
              "MessageInput.svelte component with form submission handler",
              "FormData construction logic bundling text and files",
              "Fetch API call with multipart/form-data to backend endpoint",
              "Upload progress tracking using XMLHttpRequest or fetch extensions",
              "Submit button disabled state during upload",
              "Error handling UI for failed uploads",
              "Success callback to clear input and attachments",
              "Cancel upload button for in-progress uploads",
              "Optimistic UI updates showing message before confirmation"
            ],
            "backend": [
              "POST /api/messages endpoint accepting multipart/form-data",
              "File extraction from request.files or equivalent",
              "Message text extraction from request.body",
              "Conversation context extraction (conversation_id, user_id)"
            ],
            "middleware": [
              "Request size limit validation (e.g., 50MB total)",
              "Authentication check to ensure user owns conversation",
              "Rate limiting to prevent upload abuse"
            ],
            "shared": [
              "MessageSubmitPayload interface with text and file[] fields",
              "createFormData utility function to construct FormData",
              "UploadProgress type for tracking upload state",
              "API_ENDPOINTS constant for message submission URL"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageInput.submitWithAttachments",
          "related_concepts": [
            "FormData API",
            "Multipart form data",
            "File blob handling",
            "Async form submission",
            "Request payload construction",
            "Error handling",
            "Progress tracking",
            "Network optimization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.4",
          "description": "Display visual previews of attached files showing file names, types, sizes, and thumbnails (for images) with options to remove files before submission",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Preview displays file name, type, and size for each attached file",
            "Preview shows thumbnail images for image file types (jpg, png, gif, etc.)",
            "Preview shows appropriate icons for non-image file types (pdf, doc, audio, etc.)",
            "Preview includes remove button for each file to delete before submission",
            "Preview updates immediately when files are added or removed",
            "Preview handles multiple files with scrollable or grid layout",
            "Preview displays loading state while generating image thumbnails",
            "Preview shows file count and total size of all attachments",
            "Preview is responsive and works on mobile devices",
            "Preview handles large numbers of files (10+) gracefully",
            "Preview revokes blob URLs when files are removed to prevent memory leaks"
          ],
          "implementation": {
            "frontend": [
              "AttachmentPreview.svelte component receiving array of File objects",
              "FileReader API usage to generate image thumbnails as data URLs",
              "File type detection to determine icon or thumbnail display",
              "Grid or list layout for multiple file previews",
              "Remove button for each file item emitting removal events",
              "File size formatting utility (bytes to KB/MB)",
              "Total size and count summary display",
              "Loading placeholders during thumbnail generation",
              "File type icons from icon library (Lucide, Heroicons)",
              "Blob URL cleanup on component destroy or file removal"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "formatFileSize utility function (bytes to human-readable)",
              "getFileTypeIcon utility function mapping MIME types to icon names",
              "generateThumbnail utility function using FileReader",
              "AttachmentFile interface with metadata (name, size, type, preview)",
              "FILE_TYPE_ICONS constant mapping types to icon identifiers"
            ]
          },
          "testable_properties": [],
          "function_id": "AttachmentPreview.render",
          "related_concepts": [
            "File thumbnails",
            "Image preview generation",
            "File metadata display",
            "File removal interaction",
            "FileReader API",
            "Blob URLs",
            "Icon representation",
            "Responsive layout"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.5",
          "description": "Build a backend API endpoint that receives multipart/form-data uploads, validates files, stores them securely, and returns file metadata for message association",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Endpoint accepts POST requests with multipart/form-data content type",
            "Endpoint parses file uploads and message text from request body",
            "Endpoint validates file types against allowed list (images, docs, audio)",
            "Endpoint validates total upload size does not exceed limit (50MB)",
            "Endpoint validates individual file sizes do not exceed limit (10MB each)",
            "Endpoint generates unique identifiers for each uploaded file",
            "Endpoint stores files in secure location (filesystem or cloud storage)",
            "Endpoint extracts file metadata (size, type, original name, upload timestamp)",
            "Endpoint creates database records associating files with messages",
            "Endpoint returns file URLs or identifiers in response",
            "Endpoint handles duplicate file names appropriately",
            "Endpoint performs virus scanning or security checks on uploaded files",
            "Endpoint logs upload events for audit purposes",
            "Endpoint handles storage failures with appropriate error responses",
            "Endpoint supports resumable uploads for large files (optional enhancement)"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "POST /api/messages endpoint in FastAPI or Express.js",
              "Multipart form parser (FastAPI UploadFile, multer for Express)",
              "File validation service checking types and sizes",
              "File storage service (local filesystem or S3/GCS integration)",
              "Unique filename generation (UUID + original extension)",
              "Database service to create attachment records",
              "Message service to associate attachments with messages",
              "File metadata extraction (MIME type detection, size calculation)",
              "Error handling for validation failures, storage errors",
              "Response builder returning attachment metadata"
            ],
            "middleware": [
              "Authentication middleware to verify user session",
              "Authorization middleware to verify conversation access",
              "Request size limit middleware (50MB max)",
              "Rate limiting middleware to prevent abuse",
              "Content-Type validation middleware (multipart/form-data only)"
            ],
            "shared": [
              "AttachmentModel database schema (id, message_id, file_path, file_name, file_size, file_type, uploaded_at)",
              "MessageModel updated with has_attachments boolean field",
              "FileValidationRules configuration (allowedTypes, maxFileSize, maxTotalSize)",
              "StorageConfig for filesystem or cloud storage settings",
              "AttachmentResponse interface for API responses",
              "ValidationError types for different failure scenarios"
            ]
          },
          "testable_properties": [],
          "function_id": "UploadService.handleUpload",
          "related_concepts": [
            "Multipart parsing",
            "File storage",
            "File validation",
            "Cloud storage integration",
            "File security",
            "Metadata extraction",
            "Virus scanning",
            "CDN integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.6",
          "description": "Implement state management for tracking attached files, handling additions and removals, and coordinating between upload component, drag-drop zone, and preview display",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "State maintains array of currently attached File objects",
            "State updates when files are added via upload button or drag-drop",
            "State updates when files are removed via preview remove buttons",
            "State prevents duplicate files based on name and size",
            "State enforces maximum file count limits (e.g., 10 files max)",
            "State enforces total size limits across all files",
            "State is accessible to all child components (upload, preview, submit)",
            "State persists during component re-renders",
            "State resets after successful message submission",
            "State provides computed properties (total size, file count, validation status)"
          ],
          "implementation": {
            "frontend": [
              "Svelte writable store for attachments array in MessageInput component",
              "addFiles function validating and adding files to state",
              "removeFile function filtering out specified file",
              "clearFiles function resetting state after submission",
              "Derived stores for totalSize, fileCount, isValid",
              "File deduplication logic comparing name and size",
              "Maximum file count validation (reject if exceeds limit)",
              "Total size validation (reject if exceeds limit)",
              "Event handlers in FileUpload and DragDrop components updating store",
              "Store subscription in AttachmentPreview for reactive display"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "AttachmentState interface defining store structure",
              "MAX_ATTACHMENTS constant (default 10)",
              "MAX_TOTAL_SIZE constant (default 50MB)",
              "isDuplicateFile utility function",
              "calculateTotalSize utility function"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageInput.manageAttachmentState",
          "related_concepts": [
            "Svelte stores",
            "State synchronization",
            "File array management",
            "Event coordination",
            "State persistence",
            "Optimistic updates"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.7",
          "description": "Render attached files in message display, showing clickable thumbnails or download links for files associated with user and assistant messages in the conversation",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Attached files display below or alongside message text",
            "Image attachments show as clickable thumbnails",
            "Non-image attachments show as download links with icons",
            "Clicking image thumbnails opens full-size view (lightbox or new tab)",
            "Clicking download links initiates file download",
            "File names and sizes display for all attachments",
            "Attachments load lazily if message is off-screen",
            "Attachments include proper authentication for secure access",
            "Attachments display loading placeholders while fetching",
            "Attachments handle missing or deleted files gracefully"
          ],
          "implementation": {
            "frontend": [
              "MessageAttachments.svelte component rendering file list",
              "Thumbnail grid layout for image attachments",
              "Download link list for non-image attachments",
              "Lightbox modal component for full-size image viewing",
              "Lazy loading using Intersection Observer",
              "Authenticated file URLs (signed URLs or session-based access)",
              "Error state UI for failed file loads",
              "Loading placeholder skeletons"
            ],
            "backend": [
              "GET /api/attachments/:id endpoint serving files",
              "Authentication check verifying user has conversation access",
              "File streaming response with appropriate Content-Type headers",
              "Signed URL generation for time-limited file access (optional)",
              "File existence validation before serving"
            ],
            "middleware": [
              "Authentication middleware for file access",
              "Authorization middleware verifying file ownership or conversation membership"
            ],
            "shared": [
              "AttachmentMetadata interface with id, url, fileName, fileType, fileSize",
              "getAttachmentUrl utility function constructing authenticated URLs",
              "isImageType utility function checking MIME types"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageDisplay.renderAttachments",
          "related_concepts": [
            "File download links",
            "Image galleries",
            "Thumbnail display",
            "File access control",
            "Lazy loading",
            "Lightbox modals"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.8",
          "description": "Integrate cloud storage service (AWS S3, Google Cloud Storage, or Azure Blob Storage) for scalable, secure, and durable file storage instead of local filesystem",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Storage service connects to cloud provider with proper credentials",
            "Files upload to designated bucket with organized folder structure",
            "Files are stored with private access by default",
            "Signed URLs are generated for time-limited file access",
            "Files are retrievable via unique identifiers or paths",
            "Storage service handles upload failures with retry logic",
            "Storage service supports file deletion when messages are deleted",
            "Storage service integrates with CDN for faster file delivery",
            "Storage configuration is environment-specific (dev/staging/prod buckets)",
            "Storage service logs operations for debugging and auditing"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Cloud storage SDK integration (boto3 for S3, @google-cloud/storage, @azure/storage-blob)",
              "StorageService class with upload, download, delete, getSignedUrl methods",
              "Bucket name configuration from environment variables",
              "File path construction (e.g., attachments/{conversation_id}/{file_id}.ext)",
              "Upload method with retry logic and error handling",
              "Signed URL generation with configurable expiration (e.g., 1 hour)",
              "Delete method for file cleanup",
              "Connection initialization with credentials from env or IAM roles",
              "Logging integration for upload/download operations"
            ],
            "middleware": [],
            "shared": [
              "StorageConfig interface (bucketName, region, credentials, cdnUrl)",
              "StorageProvider enum (S3, GCS, AZURE)",
              "STORAGE_SETTINGS environment variable configuration",
              "FileStorageError custom error types"
            ]
          },
          "testable_properties": [],
          "function_id": "FileStorage.integrateCloudStorage",
          "related_concepts": [
            "Cloud storage SDKs",
            "Bucket configuration",
            "Object storage",
            "Access control policies",
            "CDN integration",
            "Storage lifecycle",
            "Cost optimization"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_004",
      "description": "The system must ingest the writer's raw text or audio recordings",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_004.1",
          "description": "Accept and validate text input from the writer through the conversation UI, supporting multi-line text, paste operations, and real-time character counting",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Text input field accepts plain text with minimum 1 character and maximum 50,000 characters",
            "Input supports multi-line text with proper line break preservation",
            "Paste operations from clipboard are supported with automatic sanitization",
            "Real-time character counter displays remaining characters",
            "Input validates for empty or whitespace-only submissions and shows error message",
            "Special characters and Unicode content are properly encoded and preserved",
            "Input field provides visual feedback for validation states (valid, invalid, empty)",
            "Submitted text is trimmed of leading/trailing whitespace before processing",
            "Input supports keyboard shortcuts (Ctrl+Enter to submit, Escape to clear)",
            "Text content is sanitized to prevent XSS attacks while preserving legitimate formatting"
          ],
          "implementation": {
            "frontend": [
              "MessageInput.svelte component with textarea element",
              "Character counter component showing current/max length",
              "Input validation UI with error message display",
              "Keyboard shortcut handlers for submit and clear",
              "Visual state indicators (focus, valid, invalid, disabled)",
              "Paste event handler with sanitization",
              "Form submission handler with validation checks"
            ],
            "backend": [
              "POST /api/conversations/{id}/messages endpoint to receive text input",
              "Text validation service to check length and content requirements",
              "Content sanitization service to clean input while preserving legitimate text",
              "Text encoding service to handle Unicode and special characters"
            ],
            "middleware": [
              "Authentication middleware to verify user session",
              "Request validation middleware to check required fields",
              "Rate limiting middleware to prevent spam submissions",
              "Content-Type validation for application/json requests"
            ],
            "shared": [
              "TextMessage model with fields: id, conversation_id, content, timestamp, user_id",
              "ValidationRules constants for min/max length, allowed characters",
              "SanitizationConfig for XSS prevention rules",
              "ErrorMessages constants for validation failures"
            ]
          },
          "testable_properties": [],
          "function_id": "TextInputService.acceptTextInput",
          "related_concepts": [
            "text validation",
            "input sanitization",
            "character encoding",
            "content length limits",
            "markdown support",
            "rich text formatting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.2",
          "description": "Handle audio file uploads from the writer, supporting multiple audio formats (MP3, WAV, M4A, WEBM), validating file size and type, and providing upload progress feedback",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Audio file upload supports MP3, WAV, M4A, WEBM, OGG, and FLAC formats",
            "File size is validated with maximum limit of 25MB per audio file",
            "MIME type validation ensures only audio files are accepted",
            "Upload progress is tracked and reported as percentage (0-100%)",
            "Failed uploads display specific error messages (file too large, invalid format, network error)",
            "Uploaded files are stored temporarily with unique identifiers",
            "File corruption is detected and rejected before processing",
            "Multiple file uploads in a single message are supported (max 5 files)",
            "Upload can be cancelled by user before completion",
            "Uploaded files are associated with the conversation and message context",
            "File metadata is extracted and stored (duration, bitrate, sample rate)"
          ],
          "implementation": {
            "frontend": [
              "FileUpload.svelte component with drag-and-drop zone",
              "File type filter for audio-only selection",
              "Upload progress bar component",
              "File preview list showing selected files with remove option",
              "Upload cancel button",
              "Error message display for invalid files",
              "File size validation before upload attempt",
              "Multiple file selection support"
            ],
            "backend": [
              "POST /api/conversations/{id}/audio-upload endpoint with multipart/form-data",
              "File validation service checking MIME type, size, and format",
              "Temporary file storage service (filesystem or S3)",
              "File metadata extraction service using audio libraries",
              "Unique file identifier generation (UUID)",
              "File corruption detection using format-specific validation",
              "Cleanup service for temporary files after processing"
            ],
            "middleware": [
              "Authentication middleware to verify user permissions",
              "File upload middleware (e.g., multer) with size limits",
              "MIME type validation middleware",
              "Rate limiting middleware for upload endpoints",
              "File scanning middleware for malware detection (optional)"
            ],
            "shared": [
              "AudioFile model with fields: id, conversation_id, message_id, file_path, original_name, mime_type, size, duration, bitrate, sample_rate, upload_timestamp",
              "FileValidationRules constants for allowed MIME types and max size",
              "AudioFormat enum (MP3, WAV, M4A, WEBM, OGG, FLAC)",
              "UploadStatus enum (PENDING, UPLOADING, COMPLETED, FAILED, CANCELLED)",
              "ErrorCodes constants for upload failures"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioUploadService.handleAudioFileUpload",
          "related_concepts": [
            "file upload",
            "multipart/form-data",
            "MIME type validation",
            "file size limits",
            "upload progress tracking",
            "temporary file storage",
            "audio format detection",
            "file corruption detection"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.3",
          "description": "Process raw text content by normalizing formatting, detecting language, extracting metadata, and preparing content for theme extraction and analysis",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Text content is normalized to consistent line endings (LF)",
            "Language is automatically detected from content (supporting English, Spanish, French, German, etc.)",
            "Text metadata is extracted (word count, sentence count, paragraph count, reading time estimate)",
            "Content is segmented into logical units (paragraphs, sentences) for analysis",
            "Character encoding is detected and standardized to UTF-8",
            "Content fingerprint is generated for deduplication checks",
            "Processing handles edge cases (empty paragraphs, excessive whitespace, special characters)",
            "Formatting markers (bold, italic, lists) are preserved if present",
            "Processing completes within 5 seconds for texts up to 50,000 characters",
            "Processed content maintains original semantic meaning",
            "Processing errors are logged with specific failure reasons"
          ],
          "implementation": {
            "frontend": [
              "Processing status indicator showing \"Processing content...\"",
              "Loading spinner during processing phase",
              "Error display if processing fails",
              "Processed content preview (optional)"
            ],
            "backend": [
              "Content normalization service to standardize line endings and whitespace",
              "Language detection service using language detection libraries",
              "Metadata extraction service calculating word/sentence/paragraph counts",
              "Text segmentation service splitting content into analyzable units",
              "Content fingerprinting service using hash algorithms",
              "Deduplication service checking for existing identical content",
              "POST /api/content/process endpoint triggering processing pipeline",
              "Processing status tracking with job IDs for async operations"
            ],
            "middleware": [
              "Authentication middleware to verify user ownership",
              "Request timeout middleware (10 second timeout)",
              "Content validation middleware ensuring non-empty processed content"
            ],
            "shared": [
              "ProcessedContent model with fields: id, raw_content, normalized_content, language, word_count, sentence_count, paragraph_count, reading_time_minutes, content_fingerprint, processing_timestamp",
              "LanguageCode enum (EN, ES, FR, DE, etc.)",
              "ContentMetadata interface for statistical information",
              "ProcessingStatus enum (QUEUED, PROCESSING, COMPLETED, FAILED)",
              "TextSegment model for segmented content units"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentProcessingService.processRawTextContent",
          "related_concepts": [
            "text normalization",
            "language detection",
            "metadata extraction",
            "content preprocessing",
            "text segmentation",
            "encoding detection",
            "content fingerprinting",
            "deduplication"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.4",
          "description": "Store ingested content (text and audio) in the database with proper associations to conversations, messages, and users, implementing versioning and retrieval capabilities",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Text content is stored in database with association to conversation_id and message_id",
            "Audio file metadata is stored with references to file storage location",
            "Content versioning supports storing multiple revisions if user edits",
            "Storage operation completes within 2 seconds for standard text content",
            "Database indexes are created for efficient retrieval by conversation, user, and timestamp",
            "Content is retrievable by unique identifiers (content_id, message_id, conversation_id)",
            "Storage implements soft delete to maintain data integrity",
            "Foreign key constraints ensure referential integrity with conversations and users",
            "Storage supports full-text search indexing for content retrieval",
            "Stored content includes all metadata (timestamps, user_id, content_type, processing_status)",
            "Storage transaction is atomic (all-or-nothing) to prevent partial saves",
            "Content retrieval supports pagination for large conversation histories"
          ],
          "implementation": {
            "frontend": [
              "Success confirmation message after content saved",
              "Error message display if storage fails with retry option",
              "Visual indicator showing content is saved (checkmark icon)"
            ],
            "backend": [
              "Database schema with tables: messages, content, audio_files, conversations, users",
              "Content storage service with CRUD operations",
              "Database transaction manager for atomic operations",
              "Content retrieval service with filtering and pagination",
              "Versioning service tracking content revisions",
              "Full-text search indexing service",
              "POST /api/content/store endpoint for storage operations",
              "GET /api/content/{id} endpoint for retrieval",
              "GET /api/conversations/{id}/content endpoint for conversation content",
              "Soft delete implementation updating deleted_at timestamp"
            ],
            "middleware": [
              "Authentication middleware verifying user permissions",
              "Database connection middleware managing connection pooling",
              "Transaction middleware wrapping storage operations",
              "Authorization middleware checking user can access/modify content"
            ],
            "shared": [
              "Content model with fields: id, conversation_id, message_id, user_id, content_type (TEXT/AUDIO), content_text, content_metadata_json, version, created_at, updated_at, deleted_at",
              "StorageResult interface with success status and error messages",
              "ContentType enum (TEXT, AUDIO, FILE)",
              "RetrievalOptions interface for pagination and filtering",
              "Database migration scripts for schema versioning",
              "Database indexes definition for optimized queries"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentStorageService.storeIngestedContent",
          "related_concepts": [
            "data persistence",
            "relational database storage",
            "content versioning",
            "indexing for search",
            "data retention policies",
            "backup strategies",
            "query optimization",
            "content relationships"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.5",
          "description": "Capture real-time audio recording from user's microphone using browser MediaRecorder API, providing recording controls (start, pause, resume, stop), visual feedback, and encoding to supported audio format",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Recording requests microphone permissions from browser on first use",
            "Recording starts immediately after permission granted and start button clicked",
            "Visual feedback shows recording in progress (animated icon, timer)",
            "Recording timer displays elapsed time in MM:SS format",
            "Pause and resume controls allow user to temporarily stop/continue recording",
            "Stop button ends recording and prepares audio blob for processing",
            "Recording automatically stops after 10 minutes maximum duration",
            "Audio is encoded to WebM format with Opus codec (fallback to available format)",
            "Audio visualization shows waveform or volume meter during recording",
            "Recording can be cancelled discarding audio data",
            "Recording handles microphone disconnection gracefully with error message",
            "Multiple recordings can be created in sequence without page reload",
            "Browser compatibility check warns users on unsupported browsers"
          ],
          "implementation": {
            "frontend": [
              "AudioRecorder.svelte component with recording controls",
              "Microphone permission request handler",
              "Recording timer component displaying elapsed time",
              "Recording state management (idle, recording, paused, stopped)",
              "Visual recording indicator (pulsing red dot)",
              "Audio waveform or volume meter visualization using Web Audio API",
              "Start, pause, resume, stop, and cancel button handlers",
              "MediaRecorder initialization with optimal audio settings",
              "Audio blob accumulation from ondataavailable events",
              "Automatic stop handler for max duration",
              "Error handler for MediaRecorder errors",
              "Browser compatibility detection (MediaRecorder support check)"
            ],
            "backend": [
              "Audio processing is handled client-side; backend receives completed audio blob via upload endpoint",
              "No specific backend service needed for capture phase"
            ],
            "middleware": [
              "No middleware needed for capture phase; middleware applies during upload"
            ],
            "shared": [
              "RecordingState enum (IDLE, REQUESTING_PERMISSION, RECORDING, PAUSED, STOPPED, ERROR)",
              "AudioEncodingOptions interface with codec, bitrate, sample rate",
              "RecordingConfig constants for max duration, audio constraints",
              "AudioBlob type for captured audio data"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecordingService.captureAudioRecording",
          "related_concepts": [
            "MediaRecorder API",
            "getUserMedia",
            "microphone permissions",
            "audio encoding",
            "real-time recording",
            "audio visualization",
            "recording duration limits",
            "browser compatibility"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.6",
          "description": "Transcribe uploaded or recorded audio content to text using OpenAI Whisper API or alternative speech-to-text service, handling async processing, progress tracking, and error recovery",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Audio file is sent to Whisper API for transcription immediately after upload completes",
            "Transcription request includes language hint if detected from user profile or prior content",
            "Transcription job is processed asynchronously with job ID returned to client",
            "Client polls for transcription status every 2 seconds until completion",
            "Transcription result includes full text, detected language, and confidence score",
            "Transcription with timestamps (word-level or sentence-level) is optionally available",
            "Failed transcriptions retry up to 3 times with exponential backoff",
            "Transcription errors provide specific failure reasons (API error, audio quality, unsupported language)",
            "Completed transcription is stored in database associated with audio file and message",
            "Transcription processing completes within 30 seconds for 5-minute audio clips",
            "User receives notification when transcription completes",
            "Transcription UI shows progress indicator and estimated completion time"
          ],
          "implementation": {
            "frontend": [
              "Transcription status component showing \"Transcribing audio...\"",
              "Progress indicator (indeterminate or percentage-based)",
              "Polling mechanism checking transcription status every 2 seconds",
              "Transcription result display showing full text",
              "Error message display for transcription failures with retry button",
              "Notification when transcription completes"
            ],
            "backend": [
              "POST /api/audio/{id}/transcribe endpoint initiating transcription",
              "Integration with OpenAI Whisper API client",
              "Transcription job queue service for async processing",
              "Job status tracking service storing job state in database",
              "GET /api/transcription/status/{job_id} endpoint for status polling",
              "Retry mechanism with exponential backoff for API failures",
              "Transcription result storage service saving text to database",
              "Webhook handler for transcription completion notifications (if supported by API)",
              "Error logging and monitoring for transcription failures"
            ],
            "middleware": [
              "Authentication middleware verifying user owns audio file",
              "Rate limiting middleware for transcription requests",
              "API key management for Whisper API credentials"
            ],
            "shared": [
              "Transcription model with fields: id, audio_file_id, job_id, transcription_text, detected_language, confidence_score, word_timestamps_json, status, created_at, completed_at",
              "TranscriptionStatus enum (QUEUED, PROCESSING, COMPLETED, FAILED)",
              "WhisperAPIRequest interface with audio_file, language, response_format options",
              "WhisperAPIResponse interface matching API response structure",
              "TranscriptionJob model for job queue with retry_count, error_message",
              "ErrorCode enum for transcription-specific errors"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.transcribeAudioContent",
          "related_concepts": [
            "speech-to-text",
            "OpenAI Whisper API",
            "async job processing",
            "transcription accuracy",
            "language detection",
            "speaker diarization",
            "timestamp generation",
            "transcription confidence scores"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_005",
      "description": "The system must transcribe any audio recordings to text",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_005.1",
          "description": "Integrate transcription service API (OpenAI Whisper, Google Speech-to-Text, or Azure Speech Services) with proper authentication, configuration, and error handling",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Transcription service API client is configured with valid API keys from environment variables",
            "API client supports at least one transcription service (OpenAI Whisper recommended)",
            "Connection to transcription service is validated on application startup",
            "API client implements retry logic with exponential backoff for transient failures",
            "API client handles rate limiting with appropriate backoff strategies",
            "Service configuration includes timeout settings (minimum 60 seconds for long audio)",
            "API errors are caught and logged with descriptive error messages",
            "Unit tests verify API client initialization and configuration",
            "Integration tests verify successful connection to transcription service",
            "Documentation includes setup instructions for API keys and service selection"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create TranscriptionService class with API client initialization",
              "Implement configuration loading from environment variables (OPENAI_API_KEY, etc.)",
              "Add retry policy with exponential backoff (3 retries, 1s initial delay)",
              "Implement rate limiting checks and backoff logic",
              "Add connection validation method for health checks",
              "Create error handling wrapper for API calls",
              "Add logging for API requests and responses",
              "Implement timeout configuration (default 120 seconds)"
            ],
            "middleware": [
              "Add environment variable validation middleware for API keys",
              "Implement service health check endpoint"
            ],
            "shared": [
              "Define TranscriptionConfig data model with API keys, service type, timeout",
              "Create TranscriptionServiceType enum (Whisper, GoogleSpeech, AzureSpeech)",
              "Define TranscriptionError exception classes",
              "Add retry policy configuration constants"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.integrateTranscriptionAPI",
          "related_concepts": [
            "API integration",
            "service configuration",
            "authentication",
            "environment variables",
            "API client initialization",
            "retry policies",
            "rate limiting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.2",
          "description": "Upload audio files to the transcription service with proper format validation, file size checks, and streaming support for large files",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Audio files are validated for supported formats (mp3, mp4, wav, m4a, webm) before upload",
            "File size is checked against service limits (25MB for OpenAI Whisper)",
            "Large files are streamed to the transcription service rather than loaded into memory",
            "Audio files are temporarily stored in a secure location before upload",
            "Temporary files are automatically cleaned up after transcription completes or fails",
            "Upload progress is tracked for files larger than 5MB",
            "Audio metadata (duration, sample rate, channels) is extracted and logged",
            "Corrupted or invalid audio files are rejected with clear error messages",
            "Multiple concurrent uploads are supported with queue management",
            "Unit tests verify format validation and file size checks",
            "Integration tests verify successful upload to transcription service"
          ],
          "implementation": {
            "frontend": [
              "Add file upload validation in MessageInput component before sending to backend",
              "Display upload progress bar for audio files",
              "Show audio file preview with duration and format information",
              "Add error messages for invalid formats or oversized files"
            ],
            "backend": [
              "Create uploadAudioFile endpoint (POST /api/audio/upload)",
              "Implement audio format validation using file magic numbers",
              "Add file size validation against service-specific limits",
              "Implement streaming file upload to transcription service",
              "Create temporary file storage with automatic cleanup",
              "Extract audio metadata using audio library (pydub or ffmpeg)",
              "Implement upload queue with concurrency limits (max 3 concurrent)",
              "Add upload progress tracking and reporting",
              "Create cleanup job for orphaned temporary files"
            ],
            "middleware": [
              "Add file upload size limit middleware (50MB max)",
              "Implement multipart form data parsing",
              "Add request timeout handling for large file uploads (10 minutes)"
            ],
            "shared": [
              "Define AudioFile data model with format, size, duration, sample_rate",
              "Create SupportedAudioFormats enum (MP3, WAV, M4A, WEBM, MP4)",
              "Define AudioValidationError exception class",
              "Add file size limit constants (WHISPER_MAX_SIZE = 25MB)",
              "Create UploadProgress data model with bytes_uploaded, total_bytes, percentage"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioUploadHandler.uploadToTranscriptionService",
          "related_concepts": [
            "file upload",
            "audio format validation",
            "streaming upload",
            "file size limits",
            "multipart form data",
            "temporary file storage",
            "audio preprocessing"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.3",
          "description": "Receive transcription results from the API, parse the response, handle different response formats, and extract metadata like confidence scores and timestamps",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Transcription response is successfully parsed from API JSON format",
            "Transcribed text is extracted and stored as a string",
            "Confidence scores are extracted and stored if provided by the service",
            "Word-level timestamps are extracted if available (Whisper provides this)",
            "Language detection result is captured if provided",
            "Empty or null transcription results are handled with appropriate error messages",
            "API response validation checks for required fields",
            "Partial results from streaming transcription are aggregated correctly",
            "Response metadata (processing time, model used) is logged",
            "Unit tests verify response parsing for successful and error cases",
            "Integration tests verify handling of actual API responses"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create parseTranscriptionResponse method in TranscriptionService",
              "Implement JSON response parsing with schema validation",
              "Extract transcribed text from response body",
              "Parse confidence scores (overall and word-level if available)",
              "Extract timestamp data for word-level or phrase-level segments",
              "Capture language detection result from response",
              "Implement validation for required fields in response",
              "Handle streaming response aggregation for real-time transcription",
              "Add logging for response metadata and processing time",
              "Create error recovery for malformed responses"
            ],
            "middleware": [
              "Add response validation middleware for transcription API calls"
            ],
            "shared": [
              "Define TranscriptionResult data model with text, confidence, timestamps, language",
              "Create TranscriptionSegment model for word/phrase timestamps",
              "Define TranscriptionMetadata model with duration, model_used, processing_time",
              "Add response schema validation constants",
              "Create TranscriptionResponse interface matching API format"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.receiveAndProcessResults",
          "related_concepts": [
            "API response parsing",
            "result validation",
            "confidence scores",
            "timestamp extraction",
            "language detection",
            "response transformation",
            "error recovery"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.4",
          "description": "Display transcription results in the conversation UI with formatting, highlighting, editing capabilities, and visual feedback for confidence levels",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Transcribed text is displayed in a dedicated message bubble in the conversation",
            "Audio file name and duration are shown above the transcription",
            "Low-confidence words are highlighted with a different color or underline",
            "Users can click on the transcription to edit it before submission",
            "Transcription in progress shows a loading indicator with partial results",
            "Completed transcription shows a checkmark icon",
            "Failed transcription shows an error message with retry option",
            "Transcription supports formatting for multiple speakers if detected",
            "Timestamps are displayed for different segments of long transcriptions",
            "Copy-to-clipboard button is available for transcribed text",
            "Screen readers can access transcription content and status",
            "Unit tests verify rendering of different transcription states",
            "Visual tests verify confidence highlighting and formatting"
          ],
          "implementation": {
            "frontend": [
              "Create TranscriptionMessage component for displaying results",
              "Add AudioFilePreview component showing file name, duration, format",
              "Implement confidence-based highlighting (red for <0.5, yellow for 0.5-0.8, green for >0.8)",
              "Create editable text area for post-transcription editing",
              "Add loading state with spinner and 'Transcribing...' message",
              "Implement streaming display for real-time transcription updates",
              "Add success/error status icons and messages",
              "Create segment viewer for long transcriptions with timestamps",
              "Add copy-to-clipboard button with toast notification",
              "Implement retry button for failed transcriptions",
              "Add ARIA labels and roles for accessibility"
            ],
            "backend": [
              "Create getTranscriptionStatus endpoint (GET /api/audio/transcription/{id}/status)",
              "Implement Server-Sent Events (SSE) for streaming transcription updates",
              "Add webhook handler for asynchronous transcription completion"
            ],
            "middleware": [],
            "shared": [
              "Define TranscriptionDisplayState enum (Loading, Streaming, Complete, Error)",
              "Create TranscriptionUIModel with text, confidence, segments, status",
              "Add formatting utilities for timestamp display (formatDuration, formatTimestamp)",
              "Define confidence level thresholds (LOW = 0.5, MEDIUM = 0.8)"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionUI.displayTranscriptionOutput",
          "related_concepts": [
            "UI rendering",
            "text formatting",
            "confidence visualization",
            "interactive editing",
            "real-time updates",
            "streaming display",
            "accessibility"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.5",
          "description": "Store transcribed text in the database with metadata, associate it with the conversation and audio file, enable search and retrieval, and maintain audit trail",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Transcribed text is stored in the database with a unique identifier",
            "Transcription is associated with the originating conversation ID",
            "Transcription is linked to the source audio file record",
            "Metadata (confidence scores, timestamps, language) is stored alongside text",
            "Timestamp of transcription creation is recorded",
            "User who uploaded the audio is recorded for audit purposes",
            "Transcriptions are searchable using full-text search",
            "Original audio file reference is maintained for re-transcription if needed",
            "Soft delete is implemented to allow recovery of deleted transcriptions",
            "Database indexes are created for conversation_id and created_at for efficient querying",
            "Unit tests verify data persistence and retrieval",
            "Integration tests verify foreign key relationships and cascading behavior"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create Transcription database table with schema",
              "Implement saveTranscription method in TranscriptionRepository",
              "Add foreign key relationships to Conversation and AudioFile tables",
              "Create indexes on conversation_id, user_id, created_at columns",
              "Implement full-text search index on transcribed_text column",
              "Add getTranscriptionById query method",
              "Implement getTranscriptionsByConversation query method",
              "Create searchTranscriptions method with full-text search",
              "Implement soft delete with deleted_at timestamp",
              "Add audit logging for create, update, delete operations",
              "Create data retention policy for old transcriptions (archive after 1 year)"
            ],
            "middleware": [
              "Add authorization check to ensure users can only access their own transcriptions"
            ],
            "shared": [
              "Define Transcription database model with id, conversation_id, audio_file_id, text, confidence, language, timestamps_json, created_at, updated_at, deleted_at, user_id",
              "Create TranscriptionMetadata model for structured metadata storage",
              "Define TranscriptionSearchQuery interface with filters (date_range, confidence_range, conversation_id)",
              "Add database migration script for Transcription table creation",
              "Define indexes: idx_transcription_conversation, idx_transcription_user, idx_transcription_created"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionStorage.storeTranscribedText",
          "related_concepts": [
            "database persistence",
            "data modeling",
            "conversation association",
            "metadata storage",
            "search indexing",
            "audit logging",
            "data retention"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.6",
          "description": "Orchestrate the complete end-to-end workflow from audio recording/upload through transcription to storage and display, with error handling and user notifications at each step",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Complete workflow is triggered when user uploads or records audio",
            "Each step in the workflow reports progress to the frontend",
            "Workflow state is persisted to allow resume after failures",
            "User receives real-time notifications for each workflow stage (upload, transcribing, complete)",
            "Failed workflow steps trigger automatic retries with exponential backoff",
            "After 3 failed retries, user is notified with error details and manual retry option",
            "Successful completion triggers storage and display of transcription",
            "Workflow supports both synchronous (small files) and asynchronous (large files) processing",
            "Job queue manages concurrent transcription requests with priority ordering",
            "Monitoring dashboard shows active, completed, and failed transcription jobs",
            "Unit tests verify workflow state transitions",
            "Integration tests verify end-to-end workflow from upload to display"
          ],
          "implementation": {
            "frontend": [
              "Create AudioRecorder component with recording controls and visual feedback",
              "Implement workflow status display with step indicators (Upload \u2192 Transcribe \u2192 Complete)",
              "Add toast notifications for workflow events (upload success, transcription started, complete)",
              "Create error notification component with retry button",
              "Implement WebSocket connection for real-time workflow updates",
              "Add progress indicators for each workflow step"
            ],
            "backend": [
              "Create transcribeAudio endpoint (POST /api/audio/transcribe)",
              "Implement TranscriptionWorkflowOrchestrator class",
              "Add workflow state machine with states (Uploaded, Validating, Transcribing, Storing, Complete, Failed)",
              "Implement async job queue using Celery or similar (store jobs in Redis/database)",
              "Create workflow step methods (validateAudio, uploadToService, receiveResults, storeTranscription)",
              "Add retry logic with exponential backoff for each step",
              "Implement WebSocket or SSE for real-time status updates to frontend",
              "Create workflow monitoring endpoint (GET /api/admin/transcription-jobs)",
              "Add logging for each workflow state transition",
              "Implement cleanup for failed workflows (remove temporary files, mark as failed)"
            ],
            "middleware": [
              "Add authentication middleware for transcription endpoints",
              "Implement rate limiting for transcription requests (10 per user per hour)"
            ],
            "shared": [
              "Define TranscriptionWorkflowState enum (Uploaded, Validating, Transcribing, Storing, Complete, Failed)",
              "Create TranscriptionJob model with id, user_id, workflow_state, audio_file_id, transcription_id, retry_count, created_at, updated_at",
              "Define WorkflowEvent model for state transitions and notifications",
              "Add retry policy constants (MAX_RETRIES = 3, INITIAL_BACKOFF = 2s, MAX_BACKOFF = 60s)",
              "Create notification templates for workflow events"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionWorkflow.orchestrateEndToEnd",
          "related_concepts": [
            "workflow orchestration",
            "state management",
            "error handling",
            "user notifications",
            "async processing",
            "job queue",
            "monitoring"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_006",
      "description": "The system must implement browser-based audio recording capability",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_006.1",
          "description": "Implement MediaRecorder API integration with browser audio capture capabilities and format configuration",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "MediaRecorder instance is successfully created with audio-only stream from getUserMedia",
            "Audio MIME type is detected and set to preferred format (webm, mp4, or ogg) based on browser support",
            "Audio bitrate is configured (minimum 128kbps recommended for transcription quality)",
            "Sample rate is set appropriately (16kHz minimum for Whisper API compatibility)",
            "Error handling is implemented for unsupported browsers or missing MediaRecorder API",
            "Permission denied scenarios are gracefully handled with user-friendly error messages",
            "Audio stream constraints specify audio-only capture with echoCancellation and noiseSuppression enabled",
            "MediaRecorder state changes (inactive, recording, paused) are properly tracked",
            "ondataavailable event handler is configured to collect audio chunks",
            "onstop event handler is configured to finalize recording",
            "onerror event handler captures and reports recording errors"
          ],
          "implementation": {
            "frontend": [
              "AudioRecorder Svelte component with MediaRecorder initialization logic",
              "Permission request UI flow with explanatory messaging",
              "Browser compatibility detection and fallback messaging",
              "Loading state indicators during MediaRecorder setup",
              "Error toast/modal for permission denied or unsupported browser",
              "Audio format selection UI (optional, for advanced users)"
            ],
            "backend": [
              "Audio format validation endpoint to verify supported upload formats",
              "Server-side MIME type verification for uploaded audio files",
              "Audio metadata extraction service (duration, bitrate, sample rate)"
            ],
            "middleware": [
              "Request validation for audio upload file size limits",
              "MIME type verification middleware for audio uploads",
              "Rate limiting for audio recording endpoints to prevent abuse"
            ],
            "shared": [
              "AudioConfig interface defining supported formats, bitrates, and constraints",
              "MediaRecorderOptions type with codec and bitrate specifications",
              "AudioStreamConstraints type for getUserMedia configuration",
              "BrowserCapabilities utility to detect MediaRecorder and codec support",
              "AudioFormatValidator utility to check MIME type compatibility",
              "ErrorCode constants for audio recording failures"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.initializeMediaRecorder",
          "related_concepts": [
            "MediaRecorder Web API",
            "getUserMedia permissions",
            "Audio stream constraints",
            "MIME type support detection",
            "Browser compatibility",
            "Audio encoding formats",
            "Blob handling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.2",
          "description": "Create intuitive recording UI controls with start, pause, resume, stop, and cancel functionality including visual feedback",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "Start recording button initiates audio capture and transitions to recording state",
            "Pause button temporarily suspends recording and allows resume",
            "Resume button continues recording from paused state",
            "Stop button finalizes recording and makes audio available for upload",
            "Cancel button aborts recording and discards audio data",
            "Recording duration timer displays elapsed time in MM:SS format",
            "Visual indicator (pulsing red dot or waveform) shows active recording state",
            "Button states are disabled/enabled appropriately based on recording state (e.g., pause only available when recording)",
            "Maximum recording duration limit is enforced (e.g., 10 minutes) with user warning at 90% threshold",
            "Audio level visualization provides real-time feedback using AudioContext AnalyserNode",
            "Keyboard shortcuts are implemented (Space to start/stop, Esc to cancel)",
            "ARIA labels and roles ensure screen reader accessibility",
            "Mobile-friendly touch targets meet minimum 44x44px size requirement",
            "Loading spinner appears while initializing MediaRecorder",
            "Confirmation dialog prevents accidental cancellation of long recordings"
          ],
          "implementation": {
            "frontend": [
              "RecordingControls Svelte component with state-driven button rendering",
              "RecordingTimer component displaying elapsed time with zero-padding",
              "AudioVisualizer component using Canvas API and AudioContext for waveform/level display",
              "RecordingButton component with icon transitions (mic \u2192 pause \u2192 stop)",
              "ConfirmationDialog component for cancel action",
              "Keyboard event listeners for recording shortcuts",
              "Tooltip component showing keyboard shortcuts on hover",
              "Accessible focus management for screen readers",
              "Responsive CSS for mobile and desktop layouts",
              "Animation states for pulsing recording indicator"
            ],
            "backend": [
              "Recording session metadata endpoint (start time, duration, user ID)",
              "Recording duration validation service",
              "Audio file size estimation service based on duration and bitrate"
            ],
            "middleware": [
              "Session tracking middleware to associate recordings with users",
              "Recording duration limit enforcement in backend validation"
            ],
            "shared": [
              "RecordingState enum (IDLE, INITIALIZING, RECORDING, PAUSED, STOPPED, ERROR)",
              "RecordingControls interface defining button states and handlers",
              "AudioVisualizationConfig type for waveform/level display settings",
              "TimerFormatter utility to convert milliseconds to MM:SS display",
              "KeyboardShortcuts constant mapping keys to recording actions",
              "RecordingLimits constant defining max duration and file size",
              "RecordingMetadata interface (startTime, duration, state, audioLevel)"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorderUI.createRecordingControls",
          "related_concepts": [
            "Recording state management",
            "Visual audio feedback",
            "Waveform visualization",
            "Recording duration timer",
            "User experience patterns",
            "Accessibility (ARIA labels)",
            "Keyboard shortcuts",
            "Mobile touch interactions"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.3",
          "description": "Capture audio stream from user microphone with real-time processing for quality monitoring and data collection",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "getUserMedia successfully requests and obtains audio-only MediaStream with appropriate constraints",
            "AudioContext is created for real-time audio analysis and level monitoring",
            "AnalyserNode is connected to MediaStream source for frequency and time-domain data",
            "Audio chunks are collected via MediaRecorder.ondataavailable events into an array buffer",
            "Audio level is calculated in real-time using AnalyserNode frequency data for UI visualization",
            "Silence detection identifies periods of no audio input (e.g., >3 seconds of silence) and notifies user",
            "Audio quality metrics (clipping detection, excessive noise) are monitored during capture",
            "Memory management prevents buffer overflow by limiting chunk array size",
            "MediaStream tracks are properly stopped when recording ends or is cancelled",
            "AudioContext is closed after recording to free resources",
            "Error handling captures stream interruptions (device disconnection, permission revocation)",
            "Background tab handling pauses or warns user if recording is affected by tab state"
          ],
          "implementation": {
            "frontend": [
              "AudioStreamManager service class handling MediaStream lifecycle",
              "AudioAnalyzer service using AudioContext and AnalyserNode for real-time metrics",
              "SilenceDetector utility monitoring audio levels and triggering warnings",
              "AudioQualityMonitor component displaying quality warnings (clipping, noise)",
              "MemoryManager utility tracking buffer size and preventing overflow",
              "StreamHealthIndicator component showing stream status (active, interrupted, quality issues)",
              "Tab visibility handler to detect background tab state and warn user",
              "Resource cleanup logic in component onDestroy lifecycle"
            ],
            "backend": [
              "Audio quality analysis endpoint for post-recording validation",
              "Transcription service integration checking audio quality before processing",
              "Audio preprocessing service (noise reduction, normalization) if quality is poor"
            ],
            "middleware": [
              "Audio quality validation middleware rejecting files with excessive silence or noise",
              "File integrity check middleware ensuring audio chunks are not corrupted"
            ],
            "shared": [
              "MediaStreamConfig interface for getUserMedia constraints and AudioContext settings",
              "AudioChunk type representing individual data blobs with timestamps",
              "AudioMetrics interface (level, clipping, silence duration, quality score)",
              "SilenceDetectionConfig type defining threshold and duration parameters",
              "StreamError enum (PERMISSION_DENIED, DEVICE_DISCONNECTED, STREAM_INTERRUPTED, CONTEXT_ERROR)",
              "AudioQualityThresholds constant defining acceptable ranges for level, clipping, noise",
              "ResourceCleanup utility function for safely closing AudioContext and stopping tracks"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioCapture.captureAndProcessStream",
          "related_concepts": [
            "MediaStream API",
            "AudioContext for analysis",
            "Audio chunk buffering",
            "Real-time audio level detection",
            "Silence detection",
            "Audio quality monitoring",
            "Stream error handling",
            "Resource cleanup"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.4",
          "description": "Convert captured audio chunks into uploadable format (Blob) optimized for transcription service requirements with proper encoding",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "Audio chunks array is combined into a single Blob with correct MIME type",
            "Blob is verified to be non-empty and contains valid audio data",
            "Audio format is compatible with transcription service (Whisper supports flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm)",
            "File size is validated against maximum upload limit (Whisper API: 25MB)",
            "If file exceeds size limit, compression or format conversion is applied automatically",
            "FormData object is created with audio Blob and required metadata fields",
            "Audio file is assigned a unique filename with proper extension (e.g., recording_TIMESTAMP.webm)",
            "Metadata is attached including duration, format, sample rate, and bitrate",
            "Base64 encoding option is available for APIs requiring base64 audio data",
            "Blob URL is created for local preview/playback before upload",
            "Memory is managed by revoking Blob URLs after upload completion",
            "Conversion process handles errors (empty recording, corrupted data) gracefully"
          ],
          "implementation": {
            "frontend": [
              "AudioBlobBuilder service combining chunks into final Blob",
              "AudioFormatConverter utility handling format conversion if needed",
              "FileSizeOptimizer service applying compression when exceeding limits",
              "FormDataBuilder utility creating upload-ready FormData with metadata",
              "BlobPreview component allowing playback before upload",
              "Base64Encoder utility for services requiring base64 format",
              "FilenameGenerator utility creating unique, timestamped filenames",
              "UploadPreparation component showing conversion progress and file info",
              "Error handling UI for empty or corrupted recordings"
            ],
            "backend": [
              "Audio format conversion service for unsupported formats",
              "File compression service using FFmpeg or similar for size reduction",
              "Audio validation service checking file integrity and format compatibility",
              "Transcription service client with format-specific upload logic",
              "Temporary file storage for audio uploads before transcription"
            ],
            "middleware": [
              "File upload middleware handling multipart/form-data parsing",
              "Audio file validation middleware checking MIME type, size, and integrity",
              "Virus scanning middleware for uploaded audio files",
              "Metadata extraction middleware parsing audio file headers"
            ],
            "shared": [
              "AudioBlob interface wrapping Blob with metadata (duration, format, size)",
              "UploadFormat enum (BLOB, BASE64, FORM_DATA)",
              "AudioMetadata interface (filename, mimeType, size, duration, sampleRate, bitrate, timestamp)",
              "TranscriptionServiceRequirements constant defining supported formats and size limits",
              "FileSizeLimit constant (25MB for Whisper, configurable for other services)",
              "BlobValidator utility checking Blob validity and audio content",
              "MetadataExtractor utility reading audio file metadata from Blob",
              "FilenameGenerator utility creating sanitized, unique filenames",
              "CompressionOptions type defining quality and bitrate settings for conversion"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioConverter.convertToUploadFormat",
          "related_concepts": [
            "Blob construction",
            "Audio format conversion",
            "File compression",
            "Base64 encoding",
            "FormData creation",
            "Audio metadata tagging",
            "File size optimization",
            "Format compatibility",
            "Whisper API requirements"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_007",
      "description": "The system must identify key themes in the input content",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_007.1",
          "description": "Integrate the existing decomposition pipeline to extract hierarchical themes from user input text by analyzing requirement nodes and their categorizations",
          "type": "sub_process",
          "parent_id": "REQ_007",
          "children": [],
          "acceptance_criteria": [
            "Successfully invokes decompose_requirements() from planning_pipeline/decomposition.py with user input text",
            "Returns structured RequirementHierarchy with at least one parent requirement node",
            "Each requirement node contains valid category field representing theme type",
            "Extracts acceptance_criteria from each node for theme validation",
            "Handles empty input gracefully with appropriate error message",
            "Processes both short text (<500 chars) and long text (>5000 chars) within 30 seconds",
            "Persists extracted themes to Context Window Array with EntryType.SUMMARY",
            "Maintains parent-child relationships between hierarchical themes",
            "Returns confidence score for each identified theme (0.0-1.0 scale)"
          ],
          "implementation": {
            "frontend": [
              "ThemeExtractionProgress component showing decomposition status",
              "Loading spinner during theme extraction API call",
              "Error message display for failed extractions",
              "Theme extraction trigger button in message input area"
            ],
            "backend": [
              "POST /api/themes/extract endpoint accepting text input",
              "ThemeExtractionService wrapping decomposition.py functions",
              "DecompositionConfig initialization with writing-specific parameters",
              "BAML client configuration for Claude Sonnet model",
              "Error handling for BAML API failures with retry logic",
              "Response serialization converting RequirementHierarchy to JSON",
              "Context Window Array integration for theme persistence",
              "Logging of extraction performance metrics"
            ],
            "middleware": [
              "Request validation ensuring text input is non-empty and under 50KB",
              "Rate limiting (max 10 extractions per minute per user)",
              "Authentication check for logged-in users only",
              "Input sanitization to prevent injection attacks"
            ],
            "shared": [
              "ThemeExtractionRequest model (text: string, config?: object)",
              "ThemeExtractionResponse model (themes: Theme[], hierarchy: object, confidence: number)",
              "Theme model (id: string, category: string, text: string, parent_id?: string, confidence: number)",
              "DecompositionConfig type definition",
              "Error types: ExtractionFailedError, InvalidInputError"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtraction.extractThemesUsingDecomposition",
          "related_concepts": [
            "decomposition.py adaptation",
            "BAML integration",
            "requirement hierarchy",
            "Claude API invocation",
            "context window array storage"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_007.2",
          "description": "Perform semantic analysis on input text to identify key concepts, topics, and entities using TF-IDF vectorization and category analysis schemas",
          "type": "sub_process",
          "parent_id": "REQ_007",
          "children": [],
          "acceptance_criteria": [
            "Extracts minimum 3 and maximum 15 key concepts from input text",
            "Each concept includes relevance score calculated via TF-IDF cosine similarity",
            "Identifies entities (people, places, organizations) when present",
            "Detects writing style indicators (narrative, expository, persuasive, descriptive)",
            "Recognizes domain-specific terminology and flags specialized topics",
            "Completes analysis within 5 seconds for texts up to 10,000 words",
            "Returns structured output with concepts grouped by type (entity, topic, keyword)",
            "Handles multilingual input with language detection (minimum English, Spanish, French)",
            "Filters out stop words and common phrases with low semantic value"
          ],
          "implementation": {
            "frontend": [
              "KeyConceptsDisplay component showing extracted concepts as chips/tags",
              "Concept relevance visualization (bar chart or heatmap)",
              "Interactive concept filtering by type (entity, topic, keyword)",
              "Tooltip on hover showing concept details and relevance score"
            ],
            "backend": [
              "POST /api/analysis/concepts endpoint accepting text input",
              "TextAnalysisService using VectorSearchIndex from context_window_array/search_index.py",
              "Integration with CategoryAnalysisSchema.baml for structured analysis",
              "TF-IDF vectorization pipeline for keyword extraction",
              "Entity recognition using BAML or external NER service",
              "Language detection service integration (langdetect library)",
              "Concept ranking algorithm based on TF-IDF + position + frequency",
              "Caching layer for repeated analysis of similar texts"
            ],
            "middleware": [
              "Input length validation (minimum 50 characters, maximum 100KB)",
              "Rate limiting (20 requests per minute per user)",
              "Content-Type validation for text/plain or application/json",
              "Timeout protection (kill analysis after 15 seconds)"
            ],
            "shared": [
              "ConceptAnalysisRequest model (text: string, language?: string, options?: object)",
              "ConceptAnalysisResponse model (concepts: Concept[], style: string, language: string)",
              "Concept model (text: string, type: ConceptType, relevance: number, positions: number[])",
              "ConceptType enum (ENTITY, TOPIC, KEYWORD, PHRASE)",
              "LanguageDetectionResult model (language: string, confidence: number)"
            ]
          },
          "testable_properties": [],
          "function_id": "TextAnalysis.analyzeKeyConcepts",
          "related_concepts": [
            "VectorSearchIndex TF-IDF",
            "CategoryAnalysisSchema.baml",
            "semantic search",
            "keyword extraction",
            "entity recognition",
            "topic modeling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_007.3",
          "description": "Classify extracted themes into predefined categories using CategoryFunctionalSchema, CategoryNonFunctionalSchema, and custom writing-specific schemas",
          "type": "sub_process",
          "parent_id": "REQ_007",
          "children": [],
          "acceptance_criteria": [
            "Assigns each theme to one or more categories from predefined schema",
            "Supports writing-specific categories (narrative, character, setting, conflict, theme, style, tone, perspective)",
            "Assigns priority level (high, medium, low) to each categorized theme",
            "Handles multi-label classification where themes belong to multiple categories",
            "Provides confidence score for each category assignment (0.0-1.0)",
            "Returns hierarchical category structure (parent category -> subcategories)",
            "Ensures at least one category assigned per theme",
            "Processes batch of up to 50 themes in single operation within 10 seconds",
            "Persists category assignments to database for historical tracking"
          ],
          "implementation": {
            "frontend": [
              "CategoryTreeView component displaying hierarchical theme categories",
              "Filter controls for showing/hiding categories by type",
              "Visual indicators for theme priority (color-coded badges)",
              "Multi-select category editor for manual category adjustments",
              "Category confidence display with visual indicators (progress bars)"
            ],
            "backend": [
              "POST /api/themes/categorize endpoint accepting array of themes",
              "ThemeCategorizationService using BAML category schemas",
              "CategorySchemaLoader loading writing-specific category definitions",
              "Multi-label classification logic using BAML + Claude",
              "Priority assignment algorithm based on theme frequency and position",
              "Category confidence calculation using BAML response scores",
              "Batch processing handler for efficient categorization",
              "Database persistence layer for category assignments with timestamps",
              "GET /api/categories endpoint returning available category schemas"
            ],
            "middleware": [
              "Request validation ensuring themes array is non-empty and under 100 items",
              "Schema validation for category type consistency",
              "Rate limiting (5 categorization requests per minute per user)",
              "Result caching with 1-hour TTL for identical theme sets"
            ],
            "shared": [
              "CategorizationRequest model (themes: Theme[], schemas?: string[])",
              "CategorizationResponse model (categorized_themes: CategorizedTheme[], schema_info: object)",
              "CategorizedTheme model (theme: Theme, categories: Category[], priority: Priority)",
              "Category model (name: string, type: CategoryType, parent?: string, confidence: number)",
              "CategoryType enum (NARRATIVE, CHARACTER, SETTING, CONFLICT, THEME, STYLE, TONE, PERSPECTIVE, FUNCTIONAL, NON_FUNCTIONAL)",
              "Priority enum (HIGH, MEDIUM, LOW)"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeCategorization.categorizeByType",
          "related_concepts": [
            "CategoryAnalysisSchema.baml",
            "theme taxonomy",
            "multi-label classification",
            "writing genres",
            "content types",
            "priority assignment"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_007.4",
          "description": "Render identified themes in the conversation UI with interactive features allowing users to view, filter, edit, and utilize themes for content generation",
          "type": "sub_process",
          "parent_id": "REQ_007",
          "children": [],
          "acceptance_criteria": [
            "Displays all identified themes in dedicated panel within conversation view",
            "Shows theme hierarchy with expandable/collapsible tree structure",
            "Includes visual indicators for theme categories (icons, colors, badges)",
            "Provides inline editing capability for theme text and categories",
            "Supports drag-and-drop reordering of themes by priority",
            "Implements search/filter functionality across themes by text or category",
            "Shows theme confidence scores with visual indicators",
            "Allows users to select multiple themes for batch operations",
            "Includes 'Use in prompt' button to inject selected themes into message input",
            "Supports keyboard navigation for accessibility (Tab, Arrow keys, Enter)",
            "Renders responsively on mobile (320px+) and desktop (1024px+) viewports",
            "Persists theme display preferences (collapsed state, sort order) to local storage",
            "Updates in real-time when new themes are extracted without page refresh"
          ],
          "implementation": {
            "frontend": [
              "ThemePanel.svelte main container component for theme display",
              "ThemeTree.svelte recursive component for hierarchical theme rendering",
              "ThemeItem.svelte individual theme display with edit/delete actions",
              "ThemeFilterBar.svelte search and filter controls",
              "ThemeConfidenceBadge.svelte visual confidence indicator",
              "ThemeCategoryIcon.svelte category-specific icon renderer",
              "ThemeActions.svelte action buttons (edit, delete, use in prompt)",
              "Svelte store (themeStore.ts) for reactive theme state management",
              "Theme selection state management with multi-select support",
              "Drag-and-drop handlers using Svelte DnD library",
              "Keyboard navigation event handlers",
              "Responsive CSS using Tailwind breakpoints",
              "Animation transitions for expand/collapse actions",
              "LocalStorage integration for preference persistence"
            ],
            "backend": [
              "GET /api/themes/:conversationId endpoint returning all themes for conversation",
              "PUT /api/themes/:themeId endpoint for theme updates",
              "DELETE /api/themes/:themeId endpoint for theme deletion",
              "PATCH /api/themes/:themeId/priority endpoint for priority updates",
              "WebSocket event emitter for real-time theme updates",
              "Theme state synchronization across multiple browser tabs/windows"
            ],
            "middleware": [
              "Authorization check ensuring user owns conversation",
              "WebSocket authentication for real-time updates",
              "Request validation for theme update payloads"
            ],
            "shared": [
              "ThemeDisplayState model (themes: Theme[], selectedIds: string[], collapsed: Set<string>, sortBy: SortOption)",
              "ThemeUpdateRequest model (text?: string, categories?: Category[], priority?: Priority)",
              "ThemeDisplayPreferences model (collapsed_state: object, sort_order: SortOption)",
              "SortOption enum (PRIORITY, CONFIDENCE, CATEGORY, CHRONOLOGICAL)",
              "WebSocket message types (THEME_ADDED, THEME_UPDATED, THEME_DELETED)"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeDisplay.displayIdentifiedThemes",
          "related_concepts": [
            "Svelte components",
            "reactive state management",
            "theme visualization",
            "user interaction patterns",
            "accessibility",
            "responsive design"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_008",
      "description": "The system must generate written content based on user prompts and identified themes",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_008.1",
          "description": "Build context-aware prompts by retrieving conversation history, identified themes, user input, and file attachments from the Context Window Array and formatting them into structured prompts for LLM consumption",
          "type": "sub_process",
          "parent_id": "REQ_008",
          "children": [],
          "acceptance_criteria": [
            "Retrieves last N conversation turns from CWA based on configurable limit",
            "Performs semantic search to find relevant previous context using identified themes as queries",
            "Includes all identified themes from current user input in prompt structure",
            "Incorporates file attachment content (text files, transcribed audio) into prompt context",
            "Formats prompt with clear sections: system instructions, conversation history, themes, user input, and task instructions",
            "Handles empty conversation history gracefully for first interactions",
            "Limits total prompt tokens to stay within LLM context window (configurable per provider)",
            "Prioritizes recent context over older context when approaching token limits",
            "Includes user preferences or writing style guidelines if previously established",
            "Generates BAML-compatible prompt structure for type-safe LLM invocation",
            "Logs prompt construction metadata for debugging and optimization"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "PromptBuilder service class with buildContextAwarePrompt() method",
              "Integration with context_window_array.store for conversation retrieval",
              "Integration with context_window_array.search_index for semantic context search",
              "Token counting utility to enforce context window limits",
              "Prompt template system with configurable sections",
              "Theme formatting logic to structure theme data for LLM",
              "File content extraction service to read attachment contents",
              "Configuration service to manage prompt parameters (max_tokens, context_turns, etc.)"
            ],
            "middleware": [
              "Validation to ensure required context components exist before prompt building",
              "Error handling for missing or corrupted context entries",
              "Caching layer for frequently accessed context entries"
            ],
            "shared": [
              "PromptTemplate data model with sections (system, context, themes, user_input, task)",
              "ContextRetrievalConfig model (max_turns, max_tokens, search_limit)",
              "ThemeData model for structured theme representation",
              "ConversationTurn model for conversation history entries",
              "TokenCounter utility interface for different LLM providers"
            ]
          },
          "testable_properties": [],
          "function_id": "PromptBuilder.buildContextAwarePrompt",
          "related_concepts": [
            "Context Window Array (CWA)",
            "Semantic search",
            "Prompt engineering",
            "Theme integration",
            "Conversation history management",
            "File content extraction",
            "Audio transcription context"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_008.2",
          "description": "Invoke the configured LLM (Claude/GPT-4) via BAML with the context-aware prompt to generate written content, handling retries, fallbacks, and error scenarios",
          "type": "sub_process",
          "parent_id": "REQ_008",
          "children": [],
          "acceptance_criteria": [
            "Invokes BAML function with constructed prompt and generation parameters (temperature, max_tokens, etc.)",
            "Supports multiple LLM providers (Claude Sonnet, Claude Haiku, GPT-4o) with configurable primary and fallback options",
            "Applies retry policy (exponential backoff) for transient failures (rate limits, network errors)",
            "Falls back to alternative LLM provider if primary provider fails after retries",
            "Streams response tokens as they are generated (not waiting for full completion)",
            "Parses and validates LLM response structure according to BAML schema",
            "Handles malformed responses with clear error messages",
            "Tracks generation metrics (tokens used, latency, provider used, retry count)",
            "Enforces generation timeout to prevent indefinite hangs",
            "Logs all LLM invocations with request/response pairs for debugging",
            "Returns structured response containing generated content and metadata"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "ContentGenerator service class with invokeLLMForGeneration() method",
              "BAML function definition for content generation (baml_src/functions.baml)",
              "BAML client configurations for Claude and OpenAI (baml_src/clients.baml)",
              "BAML response type schema for generated content (baml_src/types.baml)",
              "Retry logic implementation using configured retry policies",
              "Fallback chain management to try alternative providers",
              "Streaming response handler to capture incremental tokens",
              "Response validation service to check BAML schema compliance",
              "LLM metrics collection service for observability",
              "Timeout management using asyncio or threading timeouts",
              "Logging service integration for request/response tracking"
            ],
            "middleware": [
              "Authentication middleware to inject API keys for LLM providers",
              "Rate limiting middleware to prevent quota exhaustion",
              "Request/response logging middleware for audit trail"
            ],
            "shared": [
              "GenerationRequest model (prompt, parameters, provider preferences)",
              "GenerationResponse model (content, metadata, provider_used, tokens_used)",
              "GenerationConfig model (temperature, max_tokens, top_p, etc.)",
              "LLMProvider enum (CLAUDE_SONNET, CLAUDE_HAIKU, GPT4O, etc.)",
              "GenerationMetrics model (latency, token_count, retry_count, provider)",
              "RetryPolicy configuration (max_retries, backoff_strategy, backoff_ms)"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentGenerator.invokeLLMForGeneration",
          "related_concepts": [
            "BAML integration",
            "LLM client configuration",
            "Retry policies",
            "Fallback strategies",
            "Claude SDK",
            "OpenAI API",
            "Streaming responses",
            "Response parsing"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_008.3",
          "description": "Ensure identified themes are explicitly incorporated into the content generation process by structuring the prompt to reference themes, using themes as content guidelines, and validating that generated content addresses the themes",
          "type": "sub_process",
          "parent_id": "REQ_008",
          "children": [],
          "acceptance_criteria": [
            "Extracts theme hierarchy from decomposition pipeline results",
            "Formats themes into explicit guidelines for LLM (e.g., 'Address theme X by doing Y')",
            "Includes theme categories (functional, non-functional, integration, etc.) in prompt structure",
            "Maps each theme to specific content sections or paragraphs to be generated",
            "Validates that generated content mentions or addresses each identified theme",
            "Calculates theme coverage score (percentage of themes addressed in output)",
            "Highlights themes that were not adequately addressed in validation report",
            "Allows user to specify theme priority or weighting for generation focus",
            "Supports multi-tiered themes (parent requirements \u2192 sub-processes \u2192 implementation details)",
            "Stores theme-to-content mapping for future reference and iteration"
          ],
          "implementation": {
            "frontend": [
              "Theme display component showing identified themes before generation",
              "Theme priority selector for user to adjust theme importance",
              "Theme coverage visualization after content generation",
              "Theme validation feedback showing which themes were addressed"
            ],
            "backend": [
              "ThemeIncorporator service class with incorporateThemesIntoGeneration() method",
              "Integration with planning_pipeline.decomposition for theme extraction",
              "Theme formatting service to convert hierarchy to LLM-friendly guidelines",
              "Theme validation service to analyze generated content for theme coverage",
              "Natural language processing utility to detect theme mentions in text",
              "Theme coverage calculation algorithm (keyword matching, semantic similarity)",
              "Theme-to-content section mapper for structured generation",
              "Theme priority weighting logic for prompt construction"
            ],
            "middleware": [
              "Validation middleware to ensure themes are present before generation",
              "Post-generation validation middleware to check theme coverage"
            ],
            "shared": [
              "Theme model (id, text, category, priority, acceptance_criteria)",
              "ThemeHierarchy model (parent_themes, sub_processes, implementation_details)",
              "ThemeGuideline model (theme_id, guideline_text, section_mapping)",
              "ThemeCoverageReport model (theme_id, addressed, coverage_score, evidence)",
              "ThemePriority enum (HIGH, MEDIUM, LOW)",
              "ThemeCategory enum (FUNCTIONAL, NON_FUNCTIONAL, INTEGRATION, etc.)"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeIncorporator.incorporateThemesIntoGeneration",
          "related_concepts": [
            "Theme extraction",
            "Requirement decomposition",
            "Content validation",
            "Prompt structuring",
            "Theme categorization",
            "Acceptance criteria mapping"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_008.4",
          "description": "Stream generated content tokens from the LLM to the Svelte UI in real-time using WebSockets or Server-Sent Events, displaying incremental updates to provide responsive user experience",
          "type": "sub_process",
          "parent_id": "REQ_008",
          "children": [],
          "acceptance_criteria": [
            "Establishes WebSocket or SSE connection between backend and frontend for streaming",
            "Sends content tokens to frontend as soon as they are received from LLM",
            "Buffers tokens into reasonable chunks (words or sentences) for smooth rendering",
            "Updates Svelte conversation component state incrementally with each chunk",
            "Handles connection interruptions with automatic reconnection logic",
            "Sends completion signal when generation finishes",
            "Sends error messages if generation fails mid-stream",
            "Displays streaming indicator (typing animation, cursor) while content generates",
            "Allows user to cancel streaming generation with stop button",
            "Persists final generated content to CWA after stream completes",
            "Maintains conversation scroll position during streaming updates",
            "Handles multiple concurrent generation requests with isolated streams"
          ],
          "implementation": {
            "frontend": [
              "WebSocket or SSE client service for establishing connections",
              "StreamingMessage Svelte component for displaying incremental content",
              "Message state store (Svelte writable store) for managing streaming state",
              "Typing indicator component to show generation in progress",
              "Stop generation button component to cancel mid-stream",
              "Auto-scroll logic to follow streaming content",
              "Error display component for streaming failures",
              "Reconnection UI feedback for connection issues"
            ],
            "backend": [
              "StreamingController service class with streamContentToUI() method",
              "WebSocket endpoint (FastAPI WebSocket route) or SSE endpoint for streaming",
              "Token buffer service to aggregate tokens into chunks",
              "Stream manager to handle multiple concurrent streams",
              "Cancellation handler to stop LLM generation on user request",
              "Stream completion handler to finalize and persist content",
              "Error handling for stream interruptions",
              "Integration with LLM streaming API (Claude/OpenAI streaming modes)"
            ],
            "middleware": [
              "WebSocket authentication middleware to verify user identity",
              "Connection heartbeat middleware to detect disconnections",
              "Rate limiting middleware to prevent stream abuse"
            ],
            "shared": [
              "StreamChunk model (chunk_id, content, is_complete, error)",
              "StreamStatus enum (CONNECTING, STREAMING, COMPLETE, ERROR, CANCELLED)",
              "StreamConfig model (buffer_size, chunk_delimiter, timeout_ms)",
              "StreamMessage model (message_id, conversation_id, chunks, status)",
              "CancellationToken interface for stopping streams",
              "StreamMetrics model (total_tokens, duration_ms, chunks_sent)"
            ]
          },
          "testable_properties": [],
          "function_id": "StreamingController.streamContentToUI",
          "related_concepts": [
            "WebSocket communication",
            "Server-Sent Events (SSE)",
            "Real-time updates",
            "Streaming responses",
            "Progressive rendering",
            "Client-side state management",
            "Token buffering"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_008.5",
          "description": "Persist generated content to the Context Window Array as a conversation turn, linking it to the original user input, themes, and attachments for future context retrieval",
          "type": "sub_process",
          "parent_id": "REQ_008",
          "children": [],
          "acceptance_criteria": [
            "Creates ContextEntry for generated content with type TASK_RESULT",
            "Links generated content entry to original user input entry via parent-child relationship",
            "Stores full generated content in entry.content field",
            "Stores concise summary of generated content in entry.summary field",
            "Includes metadata: generation timestamp, LLM provider used, tokens consumed, themes addressed",
            "Associates entry with current conversation_id and project_id",
            "Sets appropriate TTL (time-to-live) for context entry lifecycle",
            "Enables semantic search on generated content for future retrieval",
            "Updates conversation state to reflect new message count and last activity time",
            "Triggers UI update to display persisted content in conversation view",
            "Handles persistence failures with retry logic and error reporting"
          ],
          "implementation": {
            "frontend": [
              "Conversation view component refresh after content persistence",
              "Optimistic UI update to show content before persistence confirmation",
              "Error handling UI for persistence failures"
            ],
            "backend": [
              "ContentPersistence service class with saveGeneratedContent() method",
              "Integration with context_window_array.store.add() method",
              "Entry ID generation using ctx_ prefix and unique identifier",
              "Summary generation service to create concise content summaries",
              "Metadata extraction from generation response (provider, tokens, etc.)",
              "Conversation state update service to modify conversation records",
              "Retry logic for transient storage failures",
              "Event emission service to notify frontend of persistence completion"
            ],
            "middleware": [
              "Validation middleware to ensure content meets minimum quality thresholds",
              "Authorization middleware to verify user can write to conversation"
            ],
            "shared": [
              "ContextEntry model (from context_window_array.models)",
              "EntryType enum with TASK_RESULT value",
              "EntryMetadata model (generation_time, provider, tokens, themes)",
              "ConversationState model (conversation_id, message_count, last_activity)",
              "PersistenceResult model (success, entry_id, error_message)",
              "TTLConfig model (default_ttl, compress_after_turns)"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentPersistence.saveGeneratedContent",
          "related_concepts": [
            "Context Window Array storage",
            "Conversation history",
            "Message persistence",
            "Context entry creation",
            "Metadata tracking",
            "Conversation state management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_008.6",
          "description": "Implement comprehensive error handling for content generation failures including LLM errors, timeout scenarios, invalid responses, and provide user-friendly error messages with retry options",
          "type": "sub_process",
          "parent_id": "REQ_008",
          "children": [],
          "acceptance_criteria": [
            "Catches and categorizes all generation errors (rate limit, timeout, invalid response, provider error, network error)",
            "Displays user-friendly error messages in UI with specific guidance (e.g., 'Rate limit exceeded, try again in 60 seconds')",
            "Provides retry button for transient errors",
            "Logs detailed error information (stack trace, request details, provider response) for debugging",
            "Automatically retries transient errors with exponential backoff before showing error to user",
            "Falls back to alternative LLM provider if primary provider consistently fails",
            "Sends error notifications to monitoring system for critical failures",
            "Preserves user input and context when errors occur (no data loss)",
            "Allows user to edit prompt and regenerate after error",
            "Tracks error rates and patterns for system health monitoring"
          ],
          "implementation": {
            "frontend": [
              "Error message component with specific error details and guidance",
              "Retry button component to re-attempt generation",
              "Edit and regenerate button to modify prompt after failure",
              "Error state management in conversation store",
              "Toast notification system for transient errors"
            ],
            "backend": [
              "ErrorHandler service class with handleGenerationFailures() method",
              "Error categorization logic to classify error types",
              "User-friendly message generator for each error category",
              "Retry orchestration service with exponential backoff",
              "Fallback provider selection logic",
              "Logging service integration for error tracking",
              "Monitoring service integration (e.g., Sentry, DataDog) for alerting",
              "Error recovery service to restore state after failures"
            ],
            "middleware": [
              "Global error handling middleware to catch unhandled exceptions",
              "Error response formatting middleware for consistent error structure"
            ],
            "shared": [
              "ErrorCategory enum (RATE_LIMIT, TIMEOUT, INVALID_RESPONSE, PROVIDER_ERROR, NETWORK_ERROR, UNKNOWN)",
              "ErrorResponse model (category, user_message, technical_details, retry_after_seconds, can_retry)",
              "RetryStrategy model (max_attempts, backoff_multiplier, initial_delay_ms)",
              "ErrorMetrics model (error_count, error_rate, provider_failures)",
              "RecoveryAction enum (RETRY, FALLBACK, EDIT_PROMPT, CANCEL)"
            ]
          },
          "testable_properties": [],
          "function_id": "ErrorHandler.handleGenerationFailures",
          "related_concepts": [
            "Error handling",
            "Retry logic",
            "User feedback",
            "Logging and monitoring",
            "Graceful degradation",
            "Fallback strategies"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_009",
      "description": "The system must support file attachment preview functionality",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_009.1",
          "description": "Display appropriate file type icons for each attachment based on MIME type or file extension",
          "type": "sub_process",
          "parent_id": "REQ_009",
          "children": [],
          "acceptance_criteria": [
            "System correctly identifies file types from MIME types (e.g., image/png, application/pdf, text/plain)",
            "System falls back to file extension parsing if MIME type is unavailable or generic",
            "Each file type category displays a distinct, recognizable icon (documents, images, audio, video, archives, code files, etc.)",
            "Unknown or unsupported file types display a generic file icon",
            "Icons are consistently sized and aligned within the preview component",
            "Icons support both light and dark themes",
            "Icon rendering does not block or delay the display of other attachment information",
            "Minimum of 15 common file types have specific icons (PDF, DOC, DOCX, XLS, XLSX, PNG, JPG, MP3, MP4, ZIP, TXT, JSON, CSV, etc.)"
          ],
          "implementation": {
            "frontend": [
              "FileTypeIcon component that accepts MIME type and filename as props",
              "Icon library integration (e.g., lucide-react, react-icons, or custom SVG icons)",
              "MIME type to icon mapping utility function",
              "File extension fallback parser",
              "Responsive icon sizing for different preview contexts (list view, grid view, detail view)",
              "CSS classes for icon styling and theming",
              "Tooltip or label showing file type on icon hover"
            ],
            "backend": [
              "File metadata extraction service that provides MIME type",
              "MIME type validation endpoint",
              "File type categorization logic (document, image, audio, video, archive, code, other)"
            ],
            "middleware": [
              "Content-Type header validation for uploaded files",
              "File extension whitelist/blacklist enforcement"
            ],
            "shared": [
              "FileType enum or constant mapping MIME types to categories",
              "IconMap interface defining file type to icon name mappings",
              "FileMetadata interface including mimeType, extension, and category fields",
              "Utility function getMimeTypeFromExtension(filename: string): string",
              "Utility function getFileCategory(mimeType: string): FileCategory"
            ]
          },
          "testable_properties": [],
          "function_id": "FilePreview.displayFileTypeIcons",
          "related_concepts": [
            "MIME type detection",
            "icon mapping",
            "file extension parsing",
            "visual file identification",
            "icon library integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_009.2",
          "description": "Show human-readable file names and formatted file sizes for each attachment",
          "type": "sub_process",
          "parent_id": "REQ_009",
          "children": [],
          "acceptance_criteria": [
            "Full filename is displayed for files with names under 50 characters",
            "Long filenames (>50 characters) are truncated with ellipsis, showing file extension",
            "Truncated filenames show full name in tooltip on hover",
            "File sizes are formatted in human-readable units (B, KB, MB, GB)",
            "File sizes use appropriate decimal precision (0 decimals for bytes, 1-2 for KB/MB/GB)",
            "File size formatting follows conventions (1 KB = 1024 bytes, not 1000)",
            "Both filename and size are clearly readable with sufficient contrast",
            "Filename and size layout adapts to different container widths",
            "Special characters in filenames are properly escaped and displayed",
            "Zero-byte files display '0 B' as size",
            "File size calculation handles files up to multiple GB in size"
          ],
          "implementation": {
            "frontend": [
              "FileNameDisplay component with truncation logic",
              "FileSizeDisplay component with formatting utility",
              "Tooltip component for showing full filename on hover",
              "CSS flexbox or grid layout for filename and size alignment",
              "Responsive text sizing and wrapping rules",
              "Character limit configuration for filename truncation",
              "File extension preservation in truncated names"
            ],
            "backend": [
              "File size calculation during upload processing",
              "Filename sanitization service removing dangerous characters",
              "File metadata storage including originalName and sizeInBytes"
            ],
            "middleware": [
              "Request payload size validation",
              "Filename length validation (e.g., max 255 characters)",
              "Character encoding validation for filenames"
            ],
            "shared": [
              "formatFileSize(bytes: number): string utility function",
              "truncateFilename(filename: string, maxLength: number): string utility",
              "preserveExtension(truncatedName: string, originalName: string): string utility",
              "FileDisplayInfo interface with displayName, fullName, formattedSize, and sizeInBytes",
              "Constants for size units (BYTES_PER_KB, BYTES_PER_MB, etc.)",
              "Constants for filename limits (MAX_DISPLAY_LENGTH, MAX_FILENAME_LENGTH)"
            ]
          },
          "testable_properties": [],
          "function_id": "FilePreview.displayFileNamesAndSizes",
          "related_concepts": [
            "file size formatting",
            "text truncation",
            "filename sanitization",
            "human-readable units",
            "overflow handling",
            "tooltip display"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_009.3",
          "description": "Render thumbnail previews for image attachments with lazy loading and error handling",
          "type": "sub_process",
          "parent_id": "REQ_009",
          "children": [],
          "acceptance_criteria": [
            "Image attachments display thumbnail previews automatically",
            "Thumbnails maintain original aspect ratio without distortion",
            "Images are lazy-loaded only when scrolled into view",
            "Loading state displays placeholder or skeleton while image loads",
            "Failed image loads display error icon or fallback image",
            "Thumbnails are optimized for performance (max 200-300px width/height)",
            "Clicking thumbnail opens full-size image in modal or new tab",
            "Supported image formats include PNG, JPG, JPEG, GIF, WebP, SVG",
            "Large images (>5MB) show warning or are compressed before preview",
            "Animated GIFs play in thumbnail preview",
            "Image preview respects EXIF orientation data",
            "Alt text is provided for accessibility"
          ],
          "implementation": {
            "frontend": [
              "ImageThumbnail component with lazy loading using Intersection Observer",
              "Image loading state component (skeleton or spinner)",
              "Image error state component with retry button",
              "Full-size image modal/lightbox component",
              "Responsive image container with aspect ratio preservation",
              "Click handler for thumbnail expansion",
              "Object-fit CSS for proper image scaling",
              "srcset and sizes attributes for responsive image loading"
            ],
            "backend": [
              "Thumbnail generation service creating optimized preview images",
              "Image processing endpoint accepting upload and returning thumbnail URL",
              "Image dimension extraction service",
              "EXIF data parsing for orientation correction",
              "Image format conversion service (if needed)",
              "CDN or storage integration for serving thumbnails",
              "Separate endpoints for thumbnail vs. full-size image"
            ],
            "middleware": [
              "Image MIME type validation",
              "Image file size limits enforcement",
              "Image dimension limits validation",
              "Malicious file content scanning for uploaded images"
            ],
            "shared": [
              "ImagePreviewData interface with thumbnailUrl, fullUrl, width, height, alt",
              "ImageLoadState enum (LOADING, LOADED, ERROR)",
              "SupportedImageFormats constant array",
              "Thumbnail size constants (THUMBNAIL_MAX_WIDTH, THUMBNAIL_MAX_HEIGHT)",
              "generateThumbnailUrl(fileId: string): string utility",
              "isImageFile(mimeType: string): boolean validator",
              "ImageProcessingOptions interface with quality, format, maxDimensions"
            ]
          },
          "testable_properties": [],
          "function_id": "FilePreview.renderImagePreviews",
          "related_concepts": [
            "image thumbnail generation",
            "lazy loading",
            "responsive images",
            "image optimization",
            "error states",
            "loading states",
            "image aspect ratio preservation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_009.4",
          "description": "Coordinate display of multiple attachments with different types, including non-image files, with unified preview interface",
          "type": "sub_process",
          "parent_id": "REQ_009",
          "children": [],
          "acceptance_criteria": [
            "Multiple attachments display in consistent grid or list layout",
            "Each attachment type uses appropriate preview strategy (image preview, icon + name, document viewer link, etc.)",
            "Non-image files (PDFs, videos, audio) show appropriate preview or icon",
            "Attachment order is preserved from upload sequence",
            "User can remove individual attachments before sending",
            "Clear visual separation between different attachment items",
            "Total attachment count is displayed (e.g., '3 files attached')",
            "Total combined file size is calculated and displayed",
            "Maximum attachment limit is enforced (e.g., 10 files per message)",
            "Attachments can be reordered via drag-and-drop",
            "Preview layout is responsive and adapts to screen size",
            "Audio files show playback controls in preview",
            "Video files show video player thumbnail or first frame",
            "Document files (PDF, DOC) show page count if available"
          ],
          "implementation": {
            "frontend": [
              "AttachmentList component managing array of attachments",
              "AttachmentPreviewFactory component selecting appropriate preview type",
              "AttachmentItem wrapper component with remove button",
              "Drag-and-drop reordering using HTML5 drag API or library",
              "Attachment counter badge component",
              "Total size display component",
              "Grid/list toggle for different layout views",
              "AudioPreview component with mini player controls",
              "VideoPreview component with thumbnail and play button",
              "DocumentPreview component with page icon and metadata",
              "Attachment limit warning message component"
            ],
            "backend": [
              "Batch file upload endpoint accepting multiple files",
              "Attachment ordering service maintaining sequence",
              "Attachment deletion endpoint",
              "Attachment metadata aggregation service (total count, total size)",
              "Audio metadata extraction (duration, bitrate)",
              "Video metadata extraction (duration, resolution, codec)",
              "PDF page count extraction service"
            ],
            "middleware": [
              "Batch upload size limit validation",
              "Per-file and total size limit enforcement",
              "Attachment count limit validation",
              "File type diversity validation (if restrictions apply)"
            ],
            "shared": [
              "Attachment interface with id, filename, mimeType, size, order, url, metadata",
              "AttachmentType enum (IMAGE, VIDEO, AUDIO, DOCUMENT, ARCHIVE, CODE, OTHER)",
              "AttachmentCollection class with add, remove, reorder, getTotalSize methods",
              "AttachmentLimits constants (MAX_FILES, MAX_TOTAL_SIZE, MAX_FILE_SIZE)",
              "getAttachmentType(mimeType: string): AttachmentType classifier",
              "AttachmentMetadata interface with type-specific fields (duration, pageCount, dimensions)",
              "validateAttachmentLimits(attachments: Attachment[]): ValidationResult utility"
            ]
          },
          "testable_properties": [],
          "function_id": "FilePreview.handleMultipleAttachmentTypes",
          "related_concepts": [
            "multi-file handling",
            "attachment grouping",
            "file type polymorphism",
            "preview strategy pattern",
            "attachment ordering",
            "batch operations",
            "progressive disclosure"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_010",
      "description": "The system must provide a FastAPI backend for web endpoints",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_010.1",
          "description": "Initialize FastAPI application with proper configuration, CORS middleware, error handlers, and logging",
          "type": "sub_process",
          "parent_id": "REQ_010",
          "children": [],
          "acceptance_criteria": [
            "FastAPI application instance is created and configured",
            "CORS middleware is properly configured to allow frontend requests from expected origins",
            "Global exception handlers are registered for common HTTP errors (400, 404, 500)",
            "Structured logging is configured with appropriate log levels and formats",
            "Application startup and shutdown events are defined for resource management",
            "Environment-based configuration is loaded (development vs production settings)",
            "Health check endpoint (/health) returns 200 OK with service status",
            "OpenAPI documentation is accessible at /docs with proper API descriptions",
            "Server starts successfully on configured host and port",
            "All middleware executes in correct order (CORS, logging, error handling)"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create main.py or app.py with FastAPI application instance",
              "Configure CORS middleware with allowed origins, methods, and headers",
              "Implement global exception handlers for HTTPException, ValidationError, and generic exceptions",
              "Set up structured logging with uvicorn access logs and application logs",
              "Define startup event handler for initialization tasks (database connections, etc.)",
              "Define shutdown event handler for cleanup tasks",
              "Create configuration management using environment variables or config files",
              "Implement health check endpoint that verifies service dependencies",
              "Configure OpenAPI schema with title, version, and description",
              "Set up uvicorn server configuration for development and production"
            ],
            "middleware": [
              "CORS middleware configuration for cross-origin requests",
              "Request logging middleware to track all incoming requests",
              "Error handling middleware to catch and format exceptions",
              "Request ID middleware to track requests across services"
            ],
            "shared": [
              "Configuration dataclass or Pydantic BaseSettings for app config",
              "Logger utility for consistent logging across application",
              "Custom exception classes for domain-specific errors",
              "Response models for standardized API responses",
              "Constants for HTTP status codes, error messages, and configuration keys"
            ]
          },
          "testable_properties": [],
          "function_id": "FastAPIServer.setup",
          "related_concepts": [
            "FastAPI",
            "CORS",
            "middleware",
            "error_handling",
            "logging",
            "application_lifecycle"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_010.2",
          "description": "Design and implement RESTful API endpoints following best practices with proper HTTP methods, request/response models, and status codes",
          "type": "sub_process",
          "parent_id": "REQ_010",
          "children": [],
          "acceptance_criteria": [
            "API endpoints follow RESTful conventions (GET, POST, PUT, DELETE)",
            "All endpoints are versioned (e.g., /api/v1/...)",
            "Request bodies are validated using Pydantic models",
            "Response bodies use consistent Pydantic models with proper serialization",
            "Endpoints return appropriate HTTP status codes (200, 201, 400, 404, 500)",
            "API router structure organizes endpoints by domain (conversations, files, themes, etc.)",
            "All endpoints include proper OpenAPI documentation with descriptions and examples",
            "Query parameters and path parameters are properly typed and validated",
            "Endpoints handle both synchronous and asynchronous operations appropriately",
            "Error responses follow consistent format with error codes and messages"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create APIRouter instances for different domains (conversations, files, transcription, themes)",
              "Define Pydantic request models for POST/PUT operations with validation rules",
              "Define Pydantic response models for consistent API responses",
              "Implement conversation endpoints: POST /conversations, GET /conversations, GET /conversations/{id}, DELETE /conversations/{id}",
              "Implement message endpoints: POST /conversations/{id}/messages, GET /conversations/{id}/messages",
              "Implement project endpoints: POST /projects, GET /projects, GET /projects/{id}",
              "Add proper HTTP status code responses for each endpoint",
              "Include response_model parameter in route decorators for automatic serialization",
              "Add OpenAPI tags, summaries, and descriptions to all routes",
              "Register all routers with the main FastAPI application with /api/v1 prefix"
            ],
            "middleware": [
              "Request validation middleware using Pydantic models",
              "Response serialization middleware for consistent formatting"
            ],
            "shared": [
              "Pydantic BaseModel classes for all request payloads",
              "Pydantic BaseModel classes for all response payloads",
              "Enum classes for status codes and entity types",
              "Generic response wrapper model (e.g., APIResponse with data, error, metadata)",
              "Validation utility functions for common patterns",
              "Constants for API version prefix and route paths"
            ]
          },
          "testable_properties": [],
          "function_id": "APIEndpoints.create_rest_endpoints",
          "related_concepts": [
            "REST",
            "HTTP_methods",
            "request_validation",
            "response_serialization",
            "API_versioning",
            "route_organization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_010.3",
          "description": "Implement secure file upload handling with validation, storage, and metadata management for attachments in conversations",
          "type": "sub_process",
          "parent_id": "REQ_010",
          "children": [],
          "acceptance_criteria": [
            "POST /api/v1/files/upload endpoint accepts multipart/form-data requests",
            "File size is validated against configurable maximum (e.g., 50MB)",
            "File types are validated against allowed MIME types (text, pdf, audio, images)",
            "Uploaded files are scanned for malicious content before processing",
            "Files are stored with unique identifiers (UUID-based filenames)",
            "File metadata (name, size, MIME type, upload time) is persisted to database",
            "Files are associated with conversations or messages through foreign keys",
            "Temporary files are cleaned up after processing or on error",
            "Endpoint returns file metadata including storage URL or ID",
            "Concurrent uploads are handled without race conditions",
            "Storage location is configurable (local filesystem, S3, cloud storage)",
            "Uploaded files can be retrieved via GET /api/v1/files/{file_id} endpoint",
            "DELETE /api/v1/files/{file_id} removes both file and metadata"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create POST /api/v1/files/upload endpoint accepting UploadFile parameter",
              "Implement file size validation before reading full content",
              "Implement MIME type validation using python-magic or similar library",
              "Generate unique file identifiers using UUID",
              "Create file storage service abstraction (interface for local/cloud storage)",
              "Implement local filesystem storage with configurable upload directory",
              "Create database model/table for file metadata (id, filename, size, mime_type, storage_path, created_at)",
              "Implement file metadata persistence after successful upload",
              "Add association table linking files to conversations or messages",
              "Implement temporary file cleanup in try-finally or context manager",
              "Create GET /api/v1/files/{file_id} endpoint for file retrieval",
              "Create GET /api/v1/files/{file_id}/metadata endpoint for metadata only",
              "Create DELETE /api/v1/files/{file_id} endpoint for file deletion",
              "Implement streaming response for large file downloads"
            ],
            "middleware": [
              "File upload size limit middleware to reject oversized requests early",
              "Content-type validation middleware for multipart requests"
            ],
            "shared": [
              "File metadata Pydantic model (FileMetadata with id, filename, size, mime_type, url)",
              "File upload request model (FileUploadRequest with optional conversation_id, message_id)",
              "File upload response model (FileUploadResponse with file metadata)",
              "Storage service interface (abstract base class with save, retrieve, delete methods)",
              "Local filesystem storage implementation",
              "File validation utilities (size check, MIME type check, filename sanitization)",
              "Constants for allowed MIME types, max file size, upload directory path",
              "File type enum (TEXT, AUDIO, IMAGE, PDF, OTHER)"
            ]
          },
          "testable_properties": [],
          "function_id": "FileUpload.handle_requests",
          "related_concepts": [
            "file_upload",
            "multipart_form_data",
            "file_validation",
            "storage",
            "security",
            "MIME_types"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_010.4",
          "description": "Implement audio transcription pipeline integrating with Whisper API or similar service to convert audio files to text",
          "type": "sub_process",
          "parent_id": "REQ_010",
          "children": [],
          "acceptance_criteria": [
            "POST /api/v1/transcribe endpoint accepts audio file uploads",
            "Supported audio formats are validated (mp3, wav, m4a, webm)",
            "Audio files are passed to OpenAI Whisper API or alternative transcription service",
            "Transcription requests are processed asynchronously for long audio files",
            "Job status endpoint GET /api/v1/transcribe/{job_id} returns progress",
            "Completed transcriptions are stored in database with reference to original file",
            "Transcription results include text, timestamps, and confidence scores when available",
            "Failed transcription attempts are retried with exponential backoff",
            "Transcription job results are cached to avoid duplicate processing",
            "Webhook or callback mechanism notifies frontend when transcription completes",
            "Transcription text is automatically added to conversation context",
            "Language detection is performed if not specified in request"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create POST /api/v1/transcribe endpoint accepting audio file and optional parameters",
              "Implement audio format validation (check MIME type and file extension)",
              "Create async transcription service integrating with OpenAI Whisper API",
              "Implement job queue system using Celery, RQ, or similar for async processing",
              "Create transcription job database model (id, file_id, status, result, created_at, completed_at)",
              "Implement GET /api/v1/transcribe/{job_id} endpoint for job status polling",
              "Create transcription result model in database with text, timestamps, metadata",
              "Implement retry logic with exponential backoff for failed API calls",
              "Add caching layer to check if file was previously transcribed",
              "Create webhook endpoint POST /api/webhooks/transcription for async notifications",
              "Implement automatic conversation context update with transcribed text",
              "Add language detection using Whisper's built-in language identification"
            ],
            "middleware": [
              "Audio file validation middleware checking format and duration limits"
            ],
            "shared": [
              "Transcription request Pydantic model (TranscriptionRequest with file_id, language, callback_url)",
              "Transcription response Pydantic model (TranscriptionResponse with job_id, status, estimated_time)",
              "Transcription result Pydantic model (TranscriptionResult with text, segments, language, duration)",
              "Transcription job status enum (PENDING, PROCESSING, COMPLETED, FAILED)",
              "Whisper API client wrapper with authentication and error handling",
              "Transcription service interface for swappable implementations",
              "Job queue utility functions for enqueueing and status checking",
              "Constants for supported audio formats, max audio duration, API keys"
            ]
          },
          "testable_properties": [],
          "function_id": "Transcription.process_requests",
          "related_concepts": [
            "audio_transcription",
            "Whisper_API",
            "async_processing",
            "job_queue",
            "speech_to_text"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_010.5",
          "description": "Create theme extraction endpoint that leverages existing decomposition pipeline to identify key themes from user input text or transcriptions",
          "type": "sub_process",
          "parent_id": "REQ_010",
          "children": [],
          "acceptance_criteria": [
            "POST /api/v1/themes/extract endpoint accepts text input",
            "Endpoint integrates with existing planning_pipeline/decomposition.py module",
            "Request includes text content and optional context (conversation history)",
            "Response includes list of identified themes with categories and priorities",
            "Themes are extracted using BAML-based requirement decomposition",
            "Each theme includes description, category, and confidence score",
            "Themes are persisted to database associated with conversation or message",
            "Endpoint supports both synchronous and asynchronous processing for large texts",
            "GET /api/v1/conversations/{id}/themes returns all themes for a conversation",
            "Themes are used to guide subsequent content generation prompts",
            "Duplicate or similar themes are merged using semantic similarity",
            "Theme extraction results are cached for identical inputs"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create POST /api/v1/themes/extract endpoint accepting text and optional conversation_id",
              "Import and adapt decompose_requirements from planning_pipeline/decomposition.py",
              "Create theme extraction service wrapping decomposition pipeline",
              "Implement text preprocessing (cleaning, normalization) before extraction",
              "Configure DecompositionConfig for theme extraction context",
              "Parse RequirementHierarchy output to extract theme categories",
              "Create database model for themes (id, text, category, priority, confidence, conversation_id)",
              "Implement theme persistence after successful extraction",
              "Create GET /api/v1/conversations/{id}/themes endpoint",
              "Implement semantic similarity checking for theme deduplication using TF-IDF",
              "Add caching layer using Redis or in-memory cache for theme extraction results",
              "Integrate extracted themes into content generation prompts"
            ],
            "middleware": [
              "Text length validation middleware to handle overly long inputs"
            ],
            "shared": [
              "Theme extraction request model (ThemeExtractionRequest with text, conversation_id, context)",
              "Theme response model (Theme with id, text, category, priority, confidence)",
              "Theme extraction response model (ThemeExtractionResponse with themes list, processing_time)",
              "Theme category enum matching decomposition categories (FUNCTIONAL, NON_FUNCTIONAL, etc.)",
              "Priority enum (HIGH, MEDIUM, LOW)",
              "Decomposition service adapter wrapping planning_pipeline functions",
              "Theme similarity utility using cosine similarity or Jaccard index",
              "Cache utility for theme extraction results",
              "Constants for theme extraction configuration, similarity thresholds"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtraction.implement_endpoint",
          "related_concepts": [
            "theme_identification",
            "NLP",
            "decomposition_pipeline",
            "BAML_integration",
            "context_analysis"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_011",
      "description": "The system must integrate with OpenAI Whisper API for audio transcription",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_011.1",
          "description": "Configure OpenAI Whisper API client with authentication, endpoint settings, model selection, and request parameters for audio transcription service",
          "type": "sub_process",
          "parent_id": "REQ_011",
          "children": [],
          "acceptance_criteria": [
            "Whisper API client is initialized with valid OpenAI API key from environment variables",
            "Client configuration includes model selection (whisper-1 or specific version)",
            "Request timeout settings are configurable (default 120 seconds for large files)",
            "API base URL is configurable to support different OpenAI endpoints",
            "Client supports connection pooling for efficient API usage",
            "Configuration validates API key format before initialization",
            "Client configuration includes retry policy settings (max retries, backoff strategy)",
            "Language and prompt parameters are configurable for transcription customization",
            "Temperature parameter (0-1) is configurable for transcription determinism",
            "Client supports both synchronous and asynchronous invocation modes"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create WhisperClient class with initialization method",
              "Implement configuration loading from environment variables (OPENAI_API_KEY)",
              "Add model parameter configuration (default: whisper-1)",
              "Implement timeout configuration with reasonable defaults",
              "Add connection pool management for HTTP client",
              "Create configuration validation logic for API credentials",
              "Implement retry policy configuration (max_retries, backoff_ms)",
              "Add optional language hint configuration",
              "Add optional prompt parameter for context",
              "Implement temperature parameter configuration"
            ],
            "middleware": [
              "Validate API key format and presence before requests",
              "Add request header injection for authentication",
              "Implement rate limiting checks before API calls"
            ],
            "shared": [
              "WhisperConfig data model with all configuration parameters",
              "ApiCredentials model for secure credential storage",
              "RetryPolicy model (strategy, max_retries, backoff_ms)",
              "WhisperModelEnum defining available models",
              "Configuration validation utility functions"
            ]
          },
          "testable_properties": [],
          "function_id": "WhisperClient.configure",
          "related_concepts": [
            "API authentication",
            "configuration management",
            "environment variables",
            "API client initialization",
            "connection pooling",
            "timeout configuration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_011.2",
          "description": "Send audio files to OpenAI Whisper API with proper formatting, multipart upload handling, and support for various audio formats (mp3, wav, m4a, webm)",
          "type": "sub_process",
          "parent_id": "REQ_011",
          "children": [],
          "acceptance_criteria": [
            "Audio files are uploaded using multipart/form-data encoding",
            "Supports multiple audio formats: mp3, mp4, mpeg, mpga, m4a, wav, webm",
            "File size validation enforces Whisper API limit (25 MB maximum)",
            "Audio file MIME type is correctly set in upload headers",
            "Optional parameters (language, prompt, temperature) are included in request",
            "Large files support streaming upload to minimize memory usage",
            "Request includes proper Content-Type headers for multipart upload",
            "File handle is properly closed after upload completes or fails",
            "Request payload includes model selection parameter",
            "API endpoint is correctly formatted: https://api.openai.com/v1/audio/transcriptions"
          ],
          "implementation": {
            "frontend": [
              "File upload component with audio format validation",
              "Audio format indicator showing supported types",
              "File size validation (max 25 MB) with user feedback",
              "Upload progress indicator for large files",
              "Audio preview player before submission"
            ],
            "backend": [
              "Implement transcribe() method accepting file path or file handle",
              "Add audio format validation logic checking file extensions and MIME types",
              "Implement file size validation (max 25 MB)",
              "Create multipart/form-data payload builder",
              "Add streaming file upload for large files",
              "Implement proper file handle management with context managers",
              "Add optional parameter passing (language, prompt, temperature, model)",
              "Construct API request to /v1/audio/transcriptions endpoint",
              "Set proper HTTP headers (Authorization, Content-Type)",
              "Implement file cleanup after upload completion"
            ],
            "middleware": [
              "File type validation middleware checking allowed audio formats",
              "File size validation middleware enforcing 25 MB limit",
              "Content-Type header injection for multipart uploads",
              "Authorization header injection with API key"
            ],
            "shared": [
              "AudioFile data model with file metadata (path, size, format, duration)",
              "SupportedAudioFormats enum listing valid formats",
              "TranscriptionRequest model with all API parameters",
              "FileValidator utility for format and size validation",
              "MultipartPayloadBuilder utility for request formatting",
              "FILE_SIZE_LIMIT constant (25 * 1024 * 1024 bytes)"
            ]
          },
          "testable_properties": [],
          "function_id": "WhisperClient.transcribe",
          "related_concepts": [
            "multipart file upload",
            "audio format validation",
            "file size limits",
            "streaming uploads",
            "request payload formatting",
            "HTTP client operations"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_011.3",
          "description": "Receive transcription response from Whisper API, parse JSON response structure, extract transcribed text, and handle different response formats including verbose JSON mode",
          "type": "sub_process",
          "parent_id": "REQ_011",
          "children": [],
          "acceptance_criteria": [
            "Successfully parses standard response format containing 'text' field",
            "Extracts transcribed text from response JSON",
            "Handles verbose_json response format with segments, timestamps, and confidence scores",
            "Parses optional language detection result from response",
            "Extracts duration information when available",
            "Validates response structure before parsing",
            "Handles empty or null transcription results gracefully",
            "Preserves word-level timestamps when available in verbose mode",
            "Extracts segment-level information (start, end, text) in verbose mode",
            "Returns structured TranscriptionResult object with all parsed data"
          ],
          "implementation": {
            "frontend": [
              "Display transcribed text in formatted text area",
              "Show confidence scores if available in verbose mode",
              "Display detected language indicator",
              "Render timestamp annotations for segments in verbose mode",
              "Provide segment navigation UI for long transcriptions"
            ],
            "backend": [
              "Implement parseResponse() method accepting raw API response",
              "Add JSON validation logic checking required fields",
              "Extract 'text' field from standard response format",
              "Parse verbose_json format with segments array",
              "Extract timestamp data (start, end) for each segment",
              "Parse confidence scores when available",
              "Extract detected language from response",
              "Parse duration field if present",
              "Handle missing optional fields gracefully",
              "Create TranscriptionResult object with all extracted data"
            ],
            "middleware": [
              "Response validation middleware checking JSON structure",
              "Content-Type validation ensuring application/json response"
            ],
            "shared": [
              "TranscriptionResult model with text, language, duration, segments",
              "TranscriptionSegment model with start, end, text, confidence",
              "ResponseFormat enum (json, text, srt, verbose_json, vtt)",
              "LanguageCode enum with ISO 639-1 language codes",
              "JSON schema validator for response structure",
              "ResponseParser utility with format-specific parsing methods"
            ]
          },
          "testable_properties": [],
          "function_id": "WhisperClient.parseResponse",
          "related_concepts": [
            "JSON parsing",
            "response validation",
            "data extraction",
            "timestamp parsing",
            "confidence scores",
            "response format handling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_011.4",
          "description": "Implement comprehensive error handling for Whisper API failures including network errors, authentication failures, rate limiting, invalid audio formats, and implement exponential backoff retry logic",
          "type": "sub_process",
          "parent_id": "REQ_011",
          "children": [],
          "acceptance_criteria": [
            "Catches and classifies HTTP error codes (400, 401, 403, 429, 500, 503)",
            "Implements exponential backoff retry strategy for transient errors (429, 500, 503)",
            "Retries failed requests up to configured maximum (default 3 retries)",
            "Calculates backoff delay using exponential formula: delay = base_delay * (2 ^ retry_count)",
            "Does not retry on permanent failures (400 Bad Request, 401 Unauthorized, 403 Forbidden)",
            "Handles network timeout errors with retry logic",
            "Handles connection errors (DNS failure, network unreachable) with retry",
            "Provides descriptive error messages for each failure type",
            "Logs all retry attempts with attempt number and delay duration",
            "Raises appropriate exception after max retries exhausted",
            "Implements rate limit detection from 429 responses and Retry-After headers",
            "Handles file-specific errors (unsupported format, file too large, corrupted audio)",
            "Implements circuit breaker to prevent cascading failures after repeated errors"
          ],
          "implementation": {
            "frontend": [
              "Display user-friendly error messages for different error types",
              "Show retry progress indicator with attempt count",
              "Display rate limit warnings with suggested wait time",
              "Provide error recovery options (retry manually, use different file)",
              "Show validation errors for unsupported audio formats or file size"
            ],
            "backend": [
              "Implement handleErrors() method with error classification logic",
              "Create error type detection based on HTTP status codes",
              "Implement exponential backoff calculation: base_delay * (2 ** attempt)",
              "Add retry loop with max_retries limit and backoff delays",
              "Implement retryable error detection (429, 500, 503, timeouts, connection errors)",
              "Add non-retryable error detection (400, 401, 403)",
              "Parse Retry-After header from 429 responses for rate limit handling",
              "Implement structured error logging with context (attempt, delay, error type)",
              "Create custom exception classes for different error categories",
              "Add circuit breaker logic tracking failure rates",
              "Implement file validation error handling (format, size, corruption)",
              "Add timeout error handling with connection and read timeouts"
            ],
            "middleware": [
              "Error response interceptor for consistent error formatting",
              "Rate limit detection middleware checking response headers",
              "Circuit breaker middleware preventing requests when circuit is open"
            ],
            "shared": [
              "WhisperApiError base exception class",
              "AuthenticationError exception for 401/403 errors",
              "RateLimitError exception for 429 errors with retry_after field",
              "InvalidAudioError exception for format/size validation failures",
              "TransientError exception for retryable errors (500, 503, timeouts)",
              "RetryPolicy model with max_retries, base_delay, max_delay",
              "ErrorClassifier utility determining error category and retry eligibility",
              "BackoffCalculator utility implementing exponential backoff formula",
              "CircuitBreaker utility tracking failure rates and state (open/closed/half-open)",
              "ERROR_MESSAGES constant mapping error codes to user-friendly messages"
            ]
          },
          "testable_properties": [],
          "function_id": "WhisperClient.handleErrors",
          "related_concepts": [
            "error handling",
            "retry logic",
            "exponential backoff",
            "rate limiting",
            "error classification",
            "circuit breaker pattern",
            "error recovery"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_012",
      "description": "The system must leverage the Context Window Array (CWA) for conversation storage",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_012.1",
          "description": "Store individual conversation turns (user messages and agent responses) in the Context Window Array with appropriate metadata, type classification, and TTL settings",
          "type": "sub_process",
          "parent_id": "REQ_012",
          "children": [],
          "acceptance_criteria": [
            "User messages are stored as EntryType.TASK with complete content and summary",
            "Agent responses are stored as EntryType.TASK_RESULT linked to corresponding user messages",
            "Each entry includes unique ID (ctx_XXXXXX format), timestamp, source identifier, and conversation_id",
            "Entries include summary field for working context views (max 200 characters)",
            "TTL is set based on conversation importance (default: 10 turns for active conversations)",
            "Attachments are referenced with file paths or content hashes in entry metadata",
            "Audio transcriptions are stored with original audio reference and transcription confidence score",
            "Entry metadata includes turn_number, conversation_id, user_id, and agent_version",
            "Store operation returns entry ID for reference tracking",
            "Entries are immediately searchable after storage"
          ],
          "implementation": {
            "frontend": [
              "Message component that captures user input with metadata (timestamp, attachments)",
              "Agent response rendering component that displays generated content",
              "Attachment display component showing linked files/audio",
              "Conversation thread view showing chronological turn order"
            ],
            "backend": [
              "POST /api/conversations/{conversation_id}/turns endpoint accepting message content, type, and metadata",
              "CWAService.addEntry() method wrapping CentralContextStore.add()",
              "Entry ID generation service using ctx_ prefix format",
              "Summary generation service extracting first N chars or using LLM summarization",
              "File attachment handler storing references in entry metadata",
              "Audio transcription result storage with confidence scores",
              "Turn number auto-increment logic per conversation"
            ],
            "middleware": [
              "Authentication check ensuring user owns the conversation",
              "Request validation for required fields (content, type, conversation_id)",
              "Rate limiting for message creation (prevent spam)",
              "Content sanitization for XSS prevention",
              "File size validation for attachments (max 10MB per file)"
            ],
            "shared": [
              "ConversationTurn model with fields: id, conversation_id, type, content, summary, timestamp, ttl, metadata",
              "EntryType enum mapping conversation concepts to CWA types",
              "TTLConfig constants defining default lifecycle values",
              "MessageMetadata interface with attachment_refs, turn_number, user_id fields",
              "Entry ID generator utility function"
            ]
          },
          "testable_properties": [],
          "function_id": "CWAService.storeConversationTurn",
          "related_concepts": [
            "ContextEntry",
            "EntryType.TASK",
            "EntryType.TASK_RESULT",
            "CentralContextStore",
            "TTL lifecycle",
            "conversation threading",
            "message ordering"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_012.2",
          "description": "Retrieve full conversation history or working context view (summary-only) with support for pagination, filtering by conversation ID, and different detail levels for different audiences (orchestrator vs implementation agents)",
          "type": "sub_process",
          "parent_id": "REQ_012",
          "children": [],
          "acceptance_criteria": [
            "Retrieve entries filtered by conversation_id with chronological ordering",
            "Support two retrieval modes: full_content (implementation) and summary_only (orchestrator)",
            "Summary-only mode returns only entry IDs, timestamps, types, and summaries (no full content)",
            "Full-content mode includes complete message content and all metadata",
            "Pagination support with configurable page size (default 50 entries per page)",
            "Filter expired entries (TTL exceeded) unless explicitly requested",
            "Support offset-based retrieval for loading conversation history in chunks",
            "Include entry_count and has_more metadata in response",
            "Respect entry lifecycle state (active vs compressed vs expired)",
            "Return entries in ascending chronological order (oldest first) for history display"
          ],
          "implementation": {
            "frontend": [
              "ConversationHistory component displaying paginated message list",
              "Infinite scroll or 'Load More' button for pagination",
              "Toggle view for summary vs full content display (developer mode)",
              "Conversation list sidebar showing recent conversations with last message preview",
              "Loading states and skeleton screens during fetch operations"
            ],
            "backend": [
              "GET /api/conversations/{conversation_id}/history endpoint with query params (page, limit, mode)",
              "CWAService.getConversationEntries() method wrapping store queries",
              "WorkingContext.from_store() integration for summary-only views",
              "Entry filtering logic excluding expired entries by default",
              "Pagination calculator determining offset and limit values",
              "Entry transformation service converting full entries to summary views",
              "Conversation list service aggregating last N conversations per user"
            ],
            "middleware": [
              "Authentication check ensuring user can access conversation",
              "Query parameter validation (page >= 1, limit between 1-100)",
              "Authorization check for conversation ownership or sharing permissions",
              "Cache-Control headers for frequently accessed conversations",
              "ETag support for conditional requests (prevent unnecessary data transfer)"
            ],
            "shared": [
              "ConversationHistoryResponse model with entries[], total_count, has_more, page_info",
              "RetrievalMode enum with values FULL_CONTENT and SUMMARY_ONLY",
              "PaginationParams interface with page, limit, offset fields",
              "EntrySummary model with id, type, summary, timestamp (no content field)",
              "ConversationPreview model for sidebar list with conversation_id, title, last_message, updated_at"
            ]
          },
          "testable_properties": [],
          "function_id": "CWAService.retrieveConversationHistory",
          "related_concepts": [
            "WorkingLLMContext",
            "CentralContextStore.get_entries()",
            "context tiering",
            "pagination",
            "entry filtering",
            "conversation threading",
            "summary vs full content views"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_012.3",
          "description": "Perform semantic search across conversation entries using TF-IDF vector similarity to find relevant historical context based on query text, with support for filtering by conversation, entry type, and result limits",
          "type": "sub_process",
          "parent_id": "REQ_012",
          "children": [],
          "acceptance_criteria": [
            "Accept natural language query text and return ranked search results",
            "Use TF-IDF vectorization with cosine similarity for semantic matching",
            "Return results with relevance scores (0.0 to 1.0) sorted descending",
            "Support filtering by conversation_id to search within specific conversations",
            "Support filtering by entry types (e.g., only TASK or TASK_RESULT entries)",
            "Configurable result limit (default 10, max 50 results)",
            "Exclude expired entries from search results by default",
            "Search results include entry summary, not full content, for efficiency",
            "Return search result metadata including query, filters applied, and result count",
            "Search operation completes within 500ms for typical conversation sizes (<1000 entries)"
          ],
          "implementation": {
            "frontend": [
              "Search input component with autocomplete suggestions",
              "Search results display showing ranked relevant messages with snippets",
              "Filter controls for conversation scope and entry types",
              "Result preview cards showing relevance score, timestamp, and excerpt",
              "Click-to-navigate functionality jumping to full message in conversation view"
            ],
            "backend": [
              "GET /api/conversations/search endpoint with query params (q, conversation_id, types, limit)",
              "VectorSearchIndex.search() integration from context_window_array module",
              "Query preprocessing service for tokenization and normalization",
              "Result ranking service applying additional business rules (recency boost, user preference)",
              "Search result caching with 5-minute TTL for frequently repeated queries",
              "Search analytics service logging queries for improving search quality"
            ],
            "middleware": [
              "Authentication check for search access",
              "Query validation ensuring non-empty search text (min 3 characters)",
              "Rate limiting on search endpoint (max 20 searches per minute per user)",
              "Authorization filtering restricting results to user's accessible conversations",
              "Search query sanitization preventing injection attacks"
            ],
            "shared": [
              "SearchRequest model with query, conversation_id, entry_types[], limit fields",
              "SearchResult model with entry_id, summary, score, timestamp, metadata fields",
              "SearchResponse model with results[], query, total_matches, filters_applied fields",
              "EntryTypeFilter enum for specifying searchable entry types",
              "SearchConfig constants defining default limits, score thresholds, and performance targets"
            ]
          },
          "testable_properties": [],
          "function_id": "CWAService.searchRelevantContext",
          "related_concepts": [
            "VectorSearchIndex",
            "TF-IDF vectors",
            "cosine similarity",
            "semantic search",
            "context retrieval",
            "search_result entry type",
            "relevance scoring"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_012.4",
          "description": "Manage Context Window Array entry lifecycle including TTL-based expiration, compression (keeping summary while discarding full content), manual deletion, and periodic cleanup operations to maintain optimal context window size",
          "type": "sub_process",
          "parent_id": "REQ_012",
          "children": [],
          "acceptance_criteria": [
            "Each entry has TTL value representing turns until expiration (not wall-clock time)",
            "TTL decrements on each new conversation turn (not on time elapsed)",
            "Entries with TTL=0 are marked as expired but not immediately deleted",
            "Compression operation preserves entry ID, type, summary, and metadata while removing full content",
            "Compressed entries are flagged and excluded from full-content retrieval",
            "Manual delete operation removes entry completely from store with cascade to search index",
            "Periodic cleanup job (scheduled or manual) removes expired entries older than retention window (default 7 days)",
            "Cleanup respects minimum retention policy (never delete entries from active conversations)",
            "Lifecycle transitions logged for audit trail (created -> active -> compressed -> expired -> deleted)",
            "Entry count and storage size metrics exposed for monitoring",
            "Support manual TTL adjustment for important entries (extend or reduce lifespan)"
          ],
          "implementation": {
            "frontend": [
              "Conversation settings panel allowing TTL configuration per conversation",
              "Entry detail view showing lifecycle state (active/compressed/expired)",
              "Manual archive/delete actions on individual messages",
              "Storage usage dashboard showing entry counts by state",
              "Cleanup status indicator showing last cleanup time and next scheduled run"
            ],
            "backend": [
              "TTL decrement service triggered on each new conversation turn",
              "POST /api/admin/cleanup endpoint triggering manual cleanup operation",
              "CWAService.compressEntry() method removing content while preserving summary",
              "CWAService.deleteEntry() method with cascade to search index",
              "Scheduled cleanup job (cron or task queue) running every 6 hours",
              "Entry lifecycle state machine tracking transitions",
              "Metrics collector exposing entry counts, storage size, and cleanup stats",
              "TTL adjustment endpoint PATCH /api/conversations/{id}/entries/{entry_id}/ttl"
            ],
            "middleware": [
              "Admin authentication for manual cleanup endpoint",
              "Transaction management ensuring atomic lifecycle transitions",
              "Lock mechanism preventing concurrent cleanup operations",
              "Audit logging for all lifecycle state changes",
              "Error handling with rollback on failed deletions"
            ],
            "shared": [
              "EntryLifecycleState enum with values ACTIVE, COMPRESSED, EXPIRED, DELETED",
              "TTLConfig model defining default TTL values by entry type",
              "CleanupPolicy model specifying retention windows and deletion rules",
              "LifecycleTransition model for audit logging with from_state, to_state, timestamp, reason",
              "StorageMetrics model with active_count, compressed_count, expired_count, total_size_bytes",
              "CleanupResult model reporting deleted_count, compressed_count, errors[] from cleanup operations"
            ]
          },
          "testable_properties": [],
          "function_id": "CWAService.manageEntryLifecycle",
          "related_concepts": [
            "TTL (Time To Live)",
            "entry compression",
            "context pruning",
            "lifecycle states",
            "storage optimization",
            "working context limits",
            "cleanup operations"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_013",
      "description": "The system must use BAML for type-safe LLM integration",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_013.1",
          "description": "Define BAML function templates for theme extraction, content generation, transcription processing, and conversation analysis with proper prompt engineering and parameter handling",
          "type": "sub_process",
          "parent_id": "REQ_013",
          "children": [],
          "acceptance_criteria": [
            "BAML functions exist in baml_src/functions.baml for theme extraction, content generation, transcription analysis, and conversation summarization",
            "Each function template includes clear system instructions, user prompt injection points, and expected output format specifications",
            "Function templates support variable parameter passing for context, user input, conversation history, and preferences",
            "Templates include examples demonstrating expected input-output pairs for LLM understanding",
            "Audio and file attachment handling is defined using BAML's multimodal type system (audio, image types)",
            "Streaming function variants are defined for real-time content generation in the conversation UI",
            "Function templates include temperature, max_tokens, and other provider-specific parameters",
            "Documentation exists for each function template explaining usage, parameters, and expected outputs",
            "Templates are versioned and backward compatible with existing Context Engine functions"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create baml_src/writing_agent/theme_extraction.baml with ExtractThemes function",
              "Create baml_src/writing_agent/content_generation.baml with GenerateContent and GenerateContentStreaming functions",
              "Create baml_src/writing_agent/transcription.baml with AnalyzeTranscript function",
              "Create baml_src/writing_agent/conversation.baml with SummarizeConversation function",
              "Define prompt templates with {{variable}} injection syntax for dynamic content",
              "Add system instructions optimized for writing assistant context",
              "Include few-shot examples in prompts for consistent output formatting"
            ],
            "middleware": [],
            "shared": [
              "Define common prompt fragments in baml_src/shared/prompts.baml for reuse",
              "Create parameter type definitions for conversation context, user preferences, and theme lists"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLTemplates.defineFunctionTemplates",
          "related_concepts": [
            "prompt engineering",
            "function composition",
            "parameter passing",
            "context injection",
            "multimodal inputs",
            "streaming responses"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_013.2",
          "description": "Configure LLM client providers including OpenAI, Anthropic, and fallback strategies with retry policies, timeout handling, and cost optimization",
          "type": "sub_process",
          "parent_id": "REQ_013",
          "children": [],
          "acceptance_criteria": [
            "baml_src/clients.baml contains client configurations for OpenAI GPT-4o, Claude Sonnet, and Claude Haiku",
            "Environment variables are used for API key configuration (OPENAI_API_KEY, ANTHROPIC_API_KEY)",
            "Retry policies are configured with exponential backoff (3 max retries, 1000ms initial delay)",
            "Timeout settings are appropriate for writing tasks (60s for generation, 30s for theme extraction)",
            "Fallback strategy exists: GPT-4o primary, Claude Sonnet secondary, Claude Haiku tertiary",
            "Round-robin strategy is configured for load distribution across multiple API keys if available",
            "Client configurations specify model versions explicitly to prevent unexpected upgrades",
            "Cost-optimized routing uses cheaper models (Haiku) for simple tasks and expensive models (GPT-4o) for complex generation",
            "Streaming is enabled for clients used in real-time conversation responses",
            "Client configuration validation prevents application startup with missing API keys"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Configure OpenAI client in baml_src/clients.baml with model gpt-4o and streaming support",
              "Configure Anthropic Claude Sonnet client with model claude-sonnet-4-20250514",
              "Configure Anthropic Claude Haiku client with model claude-3-5-haiku-20241022",
              "Define ExponentialBackoffRetry policy with max_retries: 3, strategy: exponential, backoff_ms: 1000",
              "Define ConstantRetry policy for transcription tasks with max_retries: 2, backoff_ms: 500",
              "Create FallbackStrategy combining GPT4o -> ClaudeSonnet -> ClaudeHaiku",
              "Set timeout values per client: 60000ms for generation, 30000ms for analysis",
              "Add temperature settings: 0.7 for content generation, 0.3 for theme extraction"
            ],
            "middleware": [
              "Implement API key validation middleware checking for required environment variables on application startup",
              "Add rate limiting middleware to prevent exceeding provider quotas"
            ],
            "shared": [
              "Create shared configuration loader in planning_pipeline/baml_config.py for reading client settings",
              "Define ClientConfig data model with fields for provider, model, timeout, retry_policy"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLClients.configureLLMProviders",
          "related_concepts": [
            "provider configuration",
            "fallback strategies",
            "retry policies",
            "rate limiting",
            "cost optimization",
            "environment configuration",
            "API key management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_013.3",
          "description": "Create response type schemas defining structured outputs for theme extraction results, generated content, transcription metadata, and conversation summaries with proper validation",
          "type": "sub_process",
          "parent_id": "REQ_013",
          "children": [],
          "acceptance_criteria": [
            "baml_src/types.baml contains ThemeExtractionResult type with fields for themes array, key_points array, categories, and confidence scores",
            "GeneratedContent type exists with fields for content string, word_count int, tone enum, and metadata object",
            "TranscriptionResult type includes transcript string, language string, confidence float, and timestamps array",
            "ConversationSummary type has fields for summary string, participant_count int, main_topics array, and action_items array",
            "WritingTone enum defines values: professional, casual, creative, academic, persuasive",
            "ThemeCategory enum includes values from existing CategoryAnalysisSchema: functional, non_functional, integration, performance, security, usability",
            "All types include optional fields with ? syntax for nullable/optional data",
            "Nested types are properly defined (e.g., Theme type with name, description, priority fields)",
            "Array types specify element types using [] syntax",
            "Response schemas align with existing Context Engine schemas in baml_src/schema/",
            "Each type includes JSDoc-style comments documenting field purposes and constraints"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create baml_src/writing_agent/types.baml with all response type definitions",
              "Define ThemeExtractionResult class with themes: Theme[], key_points: string[], categories: ThemeCategory[]",
              "Define Theme class with name: string, description: string, priority: string, confidence: float?",
              "Define GeneratedContent class with content: string, word_count: int, tone: WritingTone, metadata: map<string, string>",
              "Define TranscriptionResult class with transcript: string, language: string, confidence: float, timestamps: Timestamp[]",
              "Define ConversationSummary class with summary: string, main_topics: string[], action_items: string[], created_at: string",
              "Define WritingTone enum with PROFESSIONAL, CASUAL, CREATIVE, ACADEMIC, PERSUASIVE values",
              "Define ThemeCategory enum reusing values from existing CategoryAnalysisSchema",
              "Define Timestamp class with start_ms: int, end_ms: int, text: string for transcription segments"
            ],
            "middleware": [],
            "shared": [
              "Generate Python type stubs from BAML schemas using baml-cli for use in backend code",
              "Create TypeScript interfaces from BAML schemas for use in API contracts",
              "Add validation utilities in shared/validation.py to validate BAML response conformance"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLSchemas.createResponseTypeSchemas",
          "related_concepts": [
            "type safety",
            "schema validation",
            "structured outputs",
            "data modeling",
            "enum definitions",
            "nested types",
            "optional fields"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_013.4",
          "description": "Implement runtime handling of structured LLM outputs including parsing, validation, error handling, retry logic, and integration with the writing agent pipeline",
          "type": "sub_process",
          "parent_id": "REQ_013",
          "children": [],
          "acceptance_criteria": [
            "BAML client wrapper service exists in planning_pipeline/baml_client.py for executing BAML functions",
            "Service automatically parses BAML responses into typed Python objects using generated code",
            "Validation logic checks response completeness and field constraints before returning to caller",
            "Malformed responses trigger automatic retry with the same or fallback LLM provider",
            "After max retries, graceful degradation returns partial results with error flags rather than crashing",
            "Streaming response handler accumulates partial outputs and yields structured events",
            "Error handling distinguishes between provider errors (retry), parsing errors (fallback), and validation errors (return with warnings)",
            "Telemetry captures token usage, latency, retry counts, and success rates for each BAML function call",
            "Integration exists with Context Window Array to store LLM responses as context entries",
            "Response caching prevents duplicate calls for identical inputs within same conversation session",
            "Structured outputs are serializable to JSON for storage in conversation database"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create planning_pipeline/baml_client.py with BAMLClientService class",
              "Implement extract_themes() method wrapping ExtractThemes BAML function with response validation",
              "Implement generate_content() method wrapping GenerateContent function with streaming support",
              "Implement analyze_transcript() method wrapping AnalyzeTranscript function",
              "Implement summarize_conversation() method wrapping SummarizeConversation function",
              "Add _validate_response() private method checking field presence and type constraints",
              "Add _handle_baml_error() method with retry logic using configured retry policies",
              "Implement streaming handler using async generators for real-time content generation",
              "Add telemetry logging capturing token counts, latency, and provider used per call",
              "Integrate with CentralContextStore to save LLM responses as SUMMARY or TASK_RESULT entries",
              "Implement response caching using in-memory cache with conversation ID as key",
              "Add serialization methods converting BAML types to JSON-compatible dicts"
            ],
            "middleware": [
              "Create middleware in api/middleware/baml_telemetry.py to capture metrics on all BAML calls",
              "Add error transformation middleware converting BAML exceptions to API error responses"
            ],
            "shared": [
              "Create shared/baml_types.py with Python type definitions matching BAML schemas",
              "Add validation functions in shared/validators.py for complex field constraints",
              "Create shared/errors.py defining BAMLParsingError, BAMLValidationError, BAMLProviderError exception classes"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLRuntime.handleStructuredOutputs",
          "related_concepts": [
            "response parsing",
            "validation",
            "error handling",
            "retry logic",
            "type coercion",
            "fallback handling",
            "logging",
            "telemetry"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_014",
      "description": "The system must support multiple LLM providers with fallback strategies",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_014.1",
          "description": "Configure OpenAI GPT-4 client with API key, model selection, temperature settings, and request timeout configuration",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "OpenAI API key is loaded securely from environment variables",
            "GPT-4o and GPT-4o-mini model endpoints are configured correctly",
            "Temperature parameter is configurable (default 0.7)",
            "Request timeout is set appropriately (e.g., 120 seconds)",
            "API base URL is configurable for different environments",
            "Client successfully authenticates and returns valid responses",
            "Error handling captures authentication failures and invalid API keys",
            "Client configuration is validated on initialization",
            "Token limit constraints are enforced per model"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend implementation required",
              "Admin UI for viewing client configuration status (optional)",
              "Error display for API key configuration issues"
            ],
            "backend": [
              "Create OpenAI client initialization service",
              "Implement API key validation endpoint",
              "Add configuration loader for OpenAI settings",
              "Create model selection service (GPT-4o, GPT-4o-mini)",
              "Implement request builder with timeout handling",
              "Add health check endpoint for OpenAI connectivity"
            ],
            "middleware": [
              "Validate API key format before requests",
              "Add request interceptor for authentication headers",
              "Implement timeout middleware for long-running requests"
            ],
            "shared": [
              "OpenAIClientConfig data model with fields: api_key, model, temperature, timeout, base_url",
              "OpenAIModelEnum with supported model versions",
              "Environment variable schema definition",
              "Configuration validation utility functions"
            ]
          },
          "testable_properties": [],
          "function_id": "LLMProviderConfig.configureOpenAIClient",
          "related_concepts": [
            "API authentication",
            "environment variable management",
            "model versioning",
            "rate limiting",
            "request configuration",
            "token limits"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.2",
          "description": "Configure Anthropic Claude client with API key, model selection (Sonnet, Haiku), temperature settings, and request timeout configuration",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "Anthropic API key is loaded securely from environment variables",
            "Claude Sonnet and Claude Haiku model endpoints are configured correctly",
            "Temperature parameter is configurable (default 0.7)",
            "Request timeout is set appropriately (e.g., 120 seconds)",
            "API base URL is configurable for different environments",
            "Client successfully authenticates and returns valid responses",
            "Error handling captures authentication failures and invalid API keys",
            "Client configuration is validated on initialization",
            "Context window limits are enforced per model (Sonnet: 200k, Haiku: 200k)"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend implementation required",
              "Admin UI for viewing client configuration status (optional)",
              "Error display for API key configuration issues"
            ],
            "backend": [
              "Create Anthropic client initialization service",
              "Implement API key validation endpoint",
              "Add configuration loader for Anthropic settings",
              "Create model selection service (Claude Sonnet, Claude Haiku)",
              "Implement request builder with timeout handling",
              "Add health check endpoint for Anthropic connectivity"
            ],
            "middleware": [
              "Validate API key format before requests",
              "Add request interceptor for authentication headers",
              "Implement timeout middleware for long-running requests",
              "Add context window size validator"
            ],
            "shared": [
              "AnthropicClientConfig data model with fields: api_key, model, temperature, timeout, base_url",
              "ClaudeModelEnum with supported model versions (Sonnet, Haiku)",
              "Environment variable schema definition",
              "Configuration validation utility functions"
            ]
          },
          "testable_properties": [],
          "function_id": "LLMProviderConfig.configureAnthropicClient",
          "related_concepts": [
            "API authentication",
            "environment variable management",
            "model versioning",
            "rate limiting",
            "request configuration",
            "context window management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.3",
          "description": "Configure Ollama client for local model execution with host URL, port, model selection, and connection settings",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "Ollama host URL is configurable (default: http://localhost:11434)",
            "Port number is configurable via environment variable",
            "Client can detect available local models",
            "Connection health check validates Ollama service is running",
            "Model selection supports any Ollama-compatible model",
            "Client handles model not found errors gracefully",
            "Timeout configuration for local model inference",
            "Client validates model compatibility before requests",
            "Error messages distinguish between connection issues and model issues"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend implementation required",
              "Admin UI for viewing available local models (optional)",
              "Status indicator for Ollama service connectivity"
            ],
            "backend": [
              "Create Ollama client initialization service",
              "Implement service health check endpoint",
              "Add model discovery service to list available models",
              "Create connection validator for localhost:11434",
              "Implement model download trigger (if model not available)",
              "Add inference request builder",
              "Create fallback handler when Ollama is unavailable"
            ],
            "middleware": [
              "Validate Ollama service is reachable before requests",
              "Add request interceptor for local API format",
              "Implement connection retry logic for transient failures"
            ],
            "shared": [
              "OllamaClientConfig data model with fields: host_url, port, model_name, timeout",
              "OllamaModelInfo data model with fields: name, size, modified_date",
              "Connection status enum (Connected, Unreachable, ServiceDown)",
              "Configuration validation utility functions"
            ]
          },
          "testable_properties": [],
          "function_id": "LLMProviderConfig.configureOllamaClient",
          "related_concepts": [
            "local model execution",
            "self-hosted infrastructure",
            "model download management",
            "localhost connectivity",
            "port configuration",
            "model availability checking"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.4",
          "description": "Implement round-robin fallback strategy that cycles through available LLM providers when primary provider fails or is unavailable",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "Provider list is configurable with priority order",
            "System cycles to next provider when current provider fails",
            "Provider rotation state persists across requests",
            "Failed providers are temporarily marked as unavailable",
            "System retries original provider after cooldown period",
            "All providers are attempted before returning final error",
            "Provider selection is deterministic and predictable",
            "Fallback strategy logs provider switches for monitoring",
            "Round-robin state resets after successful request",
            "Strategy handles case where all providers are unavailable"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend implementation required",
              "Admin dashboard showing provider rotation status (optional)",
              "Visual indicator when fallback providers are used"
            ],
            "backend": [
              "Create RoundRobinStrategy service class",
              "Implement provider rotation logic",
              "Add provider health tracking service",
              "Create provider availability cache",
              "Implement cooldown timer for failed providers",
              "Add fallback orchestrator that manages provider switching",
              "Create logging service for fallback events",
              "Implement provider selection algorithm"
            ],
            "middleware": [
              "Add request interceptor to invoke fallback strategy",
              "Implement error handler that triggers provider switch",
              "Add middleware to track provider usage statistics"
            ],
            "shared": [
              "RoundRobinConfig data model with fields: provider_order, cooldown_period",
              "ProviderStatus data model with fields: provider_name, is_available, last_failure_time, failure_count",
              "FallbackEvent data model for logging provider switches",
              "Provider selection utility functions",
              "Circular queue implementation for provider rotation"
            ]
          },
          "testable_properties": [],
          "function_id": "FallbackStrategy.implementRoundRobin",
          "related_concepts": [
            "load balancing",
            "fault tolerance",
            "provider rotation",
            "circuit breaker pattern",
            "provider health tracking",
            "request distribution"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.5",
          "description": "Implement exponential backoff retry policy with configurable max retries, initial delay, and backoff multiplier for handling transient failures",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "Max retry count is configurable (default: 3)",
            "Initial backoff delay is configurable (default: 1000ms)",
            "Backoff multiplier is configurable (default: 2x)",
            "Retry policy applies exponential increase: 1s, 2s, 4s, 8s, etc.",
            "Optional jitter is added to prevent thundering herd",
            "Retry policy only applies to retryable errors (5xx, timeouts, rate limits)",
            "Non-retryable errors (4xx client errors) fail immediately",
            "Retry attempts are logged with delay duration",
            "Final failure includes all retry attempt details",
            "Retry policy respects max timeout constraint"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend implementation required",
              "Loading indicator shows retry attempts in progress (optional)",
              "Error message indicates if request failed after retries"
            ],
            "backend": [
              "Create ExponentialBackoffPolicy service class",
              "Implement delay calculation algorithm",
              "Add jitter calculation utility",
              "Create retry orchestrator that wraps LLM client calls",
              "Implement error classifier (retryable vs non-retryable)",
              "Add retry attempt logger",
              "Create timeout enforcement service",
              "Implement retry statistics collector"
            ],
            "middleware": [
              "Add retry middleware wrapper for all LLM requests",
              "Implement error inspection to determine retryability",
              "Add request/response interceptor for retry logging"
            ],
            "shared": [
              "ExponentialBackoffConfig data model with fields: max_retries, initial_delay_ms, multiplier, max_delay_ms, add_jitter",
              "RetryAttempt data model with fields: attempt_number, delay_ms, error_type, timestamp",
              "ErrorClassification enum (Retryable, NonRetryable, RateLimited)",
              "Backoff calculation utility functions",
              "Jitter generation utility (random 0-100ms)"
            ]
          },
          "testable_properties": [],
          "function_id": "RetryPolicy.implementExponentialBackoff",
          "related_concepts": [
            "transient fault handling",
            "rate limit management",
            "backoff algorithms",
            "retry logic",
            "idempotency",
            "jitter addition"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.6",
          "description": "Integrate all configured LLM providers (OpenAI, Anthropic, Ollama) with fallback and retry strategies into a unified orchestration layer",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "Unified interface for invoking any LLM provider",
            "Provider selection can be explicit or automatic (via fallback)",
            "Retry policy is applied consistently across all providers",
            "Fallback strategy is invoked when provider fails",
            "Provider-specific features are accessible through unified interface",
            "Configuration changes can be applied without code changes",
            "Orchestrator logs all provider interactions",
            "Health check endpoint validates all provider configurations",
            "Orchestrator handles concurrent requests efficiently",
            "Provider statistics are collected and exposed (success rate, latency, error count)"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend implementation required",
              "Admin dashboard showing provider health and statistics",
              "Configuration UI for provider settings (optional)",
              "Real-time monitoring of provider usage"
            ],
            "backend": [
              "Create LLMProviderOrchestrator service class",
              "Implement unified LLM invocation interface",
              "Add provider registry that manages all configured providers",
              "Create strategy injector for fallback and retry policies",
              "Implement health check aggregator",
              "Add statistics collector service",
              "Create configuration loader from BAML files",
              "Implement request routing logic",
              "Add provider-specific adapter classes"
            ],
            "middleware": [
              "Add orchestrator middleware to route requests",
              "Implement monitoring middleware for metrics collection",
              "Add logging middleware for all provider interactions"
            ],
            "shared": [
              "LLMProviderInterface abstract class/interface",
              "OrchestratorConfig data model with all provider and strategy settings",
              "ProviderStatistics data model with fields: provider_name, request_count, success_count, failure_count, avg_latency_ms",
              "HealthCheckResult data model for provider status",
              "Request/Response wrapper models",
              "Provider factory utility for instantiation"
            ]
          },
          "testable_properties": [],
          "function_id": "LLMProviderOrchestrator.integrateAllProviders",
          "related_concepts": [
            "service orchestration",
            "provider abstraction",
            "unified interface",
            "strategy pattern",
            "dependency injection",
            "configuration management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.7",
          "description": "Define all LLM client configurations in BAML format with proper syntax for providers, retry policies, and fallback strategies",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "BAML clients.baml file contains all three provider definitions",
            "Each client specifies provider, model, api_key source, and options",
            "Retry policy is defined with correct BAML syntax",
            "Fallback strategy is defined with provider ordering",
            "Configuration is validated by BAML compiler",
            "Environment variables are correctly referenced (env.OPENAI_API_KEY)",
            "Temperature and other model parameters are configurable",
            "BAML client names match usage in functions.baml",
            "Comments document each configuration option"
          ],
          "implementation": {
            "frontend": [
              "No frontend implementation required"
            ],
            "backend": [
              "Create/update baml_src/clients.baml file",
              "Define OpenAI client block with GPT-4o configuration",
              "Define Anthropic client block with Claude configuration",
              "Define Ollama client block with local model configuration",
              "Define ExponentialBackoff retry policy block",
              "Define RoundRobin fallback strategy block",
              "Run BAML compiler to generate Python client code",
              "Verify generated client code matches expectations"
            ],
            "middleware": [
              "No middleware implementation required"
            ],
            "shared": [
              "BAML client definitions in baml_src/clients.baml",
              "BAML retry policy definitions",
              "BAML fallback strategy definitions",
              "Generated Python client code in baml_client/",
              "Configuration schema documentation"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLIntegration.defineClientConfigurations",
          "related_concepts": [
            "BAML syntax",
            "declarative configuration",
            "client definitions",
            "strategy definitions",
            "configuration validation",
            "type safety"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_014.8",
          "description": "Create comprehensive tests to validate each LLM provider integration, fallback behavior, and retry policies work correctly",
          "type": "sub_process",
          "parent_id": "REQ_014",
          "children": [],
          "acceptance_criteria": [
            "Unit tests validate each provider client initialization",
            "Integration tests validate successful requests to each provider",
            "Tests verify fallback triggers when primary provider fails",
            "Tests verify round-robin cycles through all providers",
            "Tests verify exponential backoff delays are correct",
            "Tests verify retry policy stops after max attempts",
            "Tests verify non-retryable errors fail immediately",
            "Tests simulate rate limit errors and verify backoff",
            "Tests validate health check endpoints",
            "Tests achieve >80% code coverage for provider orchestration code",
            "Mock tests allow testing without actual API keys"
          ],
          "implementation": {
            "frontend": [
              "No frontend testing required for this component"
            ],
            "backend": [
              "Create test_openai_client.py with provider-specific tests",
              "Create test_anthropic_client.py with provider-specific tests",
              "Create test_ollama_client.py with provider-specific tests",
              "Create test_round_robin_fallback.py",
              "Create test_exponential_backoff.py",
              "Create test_orchestrator.py for integration tests",
              "Implement mock LLM providers for testing",
              "Create failure injection utilities for chaos testing",
              "Add pytest fixtures for provider setup/teardown",
              "Create test configuration files separate from production"
            ],
            "middleware": [
              "Test middleware correctly applies retry logic",
              "Test middleware correctly invokes fallback strategy",
              "Test middleware logging captures all events"
            ],
            "shared": [
              "Mock provider implementations",
              "Test fixtures for provider configurations",
              "Test utilities for delay measurement",
              "Test data models for expected responses",
              "Test assertion helpers for retry/fallback verification"
            ]
          },
          "testable_properties": [],
          "function_id": "Testing.validateProviderIntegration",
          "related_concepts": [
            "integration testing",
            "unit testing",
            "mocking",
            "test coverage",
            "failure simulation",
            "chaos engineering"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_015",
      "description": "The system must implement phase-based workflow orchestration",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_015.1",
          "description": "Create ingest phase to accept and validate raw text input, file attachments, and audio recordings from users",
          "type": "sub_process",
          "parent_id": "REQ_015",
          "children": [],
          "acceptance_criteria": [
            "System accepts text input up to 50,000 characters",
            "System accepts file attachments in formats: .txt, .doc, .docx, .pdf up to 10MB",
            "System accepts audio recordings in formats: .mp3, .wav, .m4a, .ogg up to 25MB",
            "File validation rejects unsupported formats with clear error messages",
            "Multiple files can be attached to a single submission (up to 5 files)",
            "Input is sanitized to prevent XSS and injection attacks",
            "User receives immediate feedback on file upload progress",
            "Failed uploads display specific error messages (file too large, unsupported format, etc.)",
            "Uploaded files are stored with unique identifiers and associated with conversation session",
            "Text input preserves formatting (line breaks, paragraphs) from user submission"
          ],
          "implementation": {
            "frontend": [
              "MessageInput.svelte component with textarea for text input",
              "FileUpload.svelte component with drag-and-drop zone",
              "AudioRecorder.svelte component with MediaRecorder API integration",
              "File preview component showing uploaded file names and sizes",
              "Progress indicator for file upload status",
              "Validation error display for rejected files",
              "File size and format validation on client side before upload",
              "Multi-file selection UI with individual remove buttons"
            ],
            "backend": [
              "POST /api/ingest endpoint accepting multipart/form-data",
              "File validation service checking MIME types and sizes",
              "File storage service saving to local filesystem or S3",
              "Input sanitization service for text content",
              "Session management to associate uploads with conversation ID",
              "Database entries for file metadata (filename, size, type, path, upload timestamp)",
              "Error handling for storage failures and quota exceeded scenarios"
            ],
            "middleware": [
              "File upload size limit enforcement (10MB for docs, 25MB for audio)",
              "MIME type validation middleware",
              "Request authentication to ensure user owns the conversation",
              "Rate limiting for upload endpoints to prevent abuse",
              "CSRF token validation for file upload requests"
            ],
            "shared": [
              "FileMetadata model (id, filename, size, mimeType, storageKey, conversationId, uploadedAt)",
              "IngestRequest model (text, files[], audioFile, conversationId, userId)",
              "IngestResponse model (ingestId, processedFiles[], status, errors[])",
              "File validation utilities (isValidFileType, isWithinSizeLimit)",
              "Constants for supported file types and size limits",
              "StorageConfig interface for file storage paths and bucket names"
            ]
          },
          "testable_properties": [],
          "function_id": "IngestPhase.processUserInput",
          "related_concepts": [
            "file upload validation",
            "audio file format detection",
            "input sanitization",
            "multipart form data handling",
            "file size limits",
            "MIME type validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_015.2",
          "description": "Implement transcribe phase to convert audio recordings to text using speech-to-text service (Whisper API)",
          "type": "sub_process",
          "parent_id": "REQ_015",
          "children": [],
          "acceptance_criteria": [
            "Audio files are successfully sent to OpenAI Whisper API for transcription",
            "Transcription completes within 60 seconds for files up to 25MB",
            "Transcribed text is stored with reference to original audio file",
            "System detects audio language automatically (supports 50+ languages)",
            "Transcription accuracy is validated with confidence scores above 0.8",
            "Failed transcriptions are retried up to 3 times with exponential backoff",
            "User is notified when transcription is in progress, completed, or failed",
            "Transcribed text is formatted with proper punctuation and capitalization",
            "System handles audio files with poor quality gracefully with warning messages",
            "Transcription results are cached to avoid re-processing same audio"
          ],
          "implementation": {
            "frontend": [
              "TranscriptionStatus.svelte component showing real-time progress",
              "Audio player component for reviewing original recording",
              "Transcription result display with original audio side-by-side",
              "Edit transcription UI for manual corrections",
              "Language selection dropdown (optional override)",
              "Retry button for failed transcriptions",
              "Confidence score indicator (visual: high/medium/low)"
            ],
            "backend": [
              "POST /api/transcribe endpoint accepting audio file reference",
              "OpenAI Whisper API client service",
              "Audio format conversion service (convert to Whisper-compatible formats)",
              "Transcription result storage in database",
              "Retry logic with exponential backoff (1s, 2s, 4s delays)",
              "Background job queue for long-running transcriptions",
              "Webhook/polling mechanism for async transcription status updates",
              "Caching layer for completed transcriptions (Redis or in-memory)",
              "Error classification service (API error vs audio quality issue)"
            ],
            "middleware": [
              "Authentication to verify user owns the audio file",
              "Rate limiting for transcription requests (10 per hour per user)",
              "Request validation for audio file reference existence",
              "Timeout handling for API calls (60 second limit)",
              "API key rotation for Whisper API quota management"
            ],
            "shared": [
              "TranscriptionRequest model (audioFileId, language, conversationId)",
              "TranscriptionResult model (id, audioFileId, text, language, confidence, duration, status, createdAt)",
              "TranscriptionStatus enum (pending, processing, completed, failed)",
              "AudioMetadata model (format, duration, sampleRate, channels)",
              "WhisperConfig interface (apiKey, model, temperature, responseFormat)",
              "RetryPolicy utility (maxRetries, backoffStrategy)",
              "Constants for supported audio languages and format conversions"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscribePhase.convertAudioToText",
          "related_concepts": [
            "audio format conversion",
            "speech-to-text API integration",
            "language detection",
            "timestamp alignment",
            "transcription confidence scores",
            "speaker diarization",
            "error handling for API failures"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_015.3",
          "description": "Build analyze phase to identify key themes, topics, and structure from transcribed or raw text using LLM-based decomposition",
          "type": "sub_process",
          "parent_id": "REQ_015",
          "children": [],
          "acceptance_criteria": [
            "System extracts 3-7 primary themes from input text",
            "Each theme includes a category label and descriptive summary",
            "Themes are ranked by relevance/importance with scores 0.0-1.0",
            "System identifies hierarchical relationships between themes (parent-child)",
            "Key entities (people, places, concepts) are extracted per theme",
            "Analysis completes within 30 seconds for texts up to 10,000 words",
            "Results are stored in Context Window Array for conversation history",
            "User can view, accept, modify, or reject extracted themes",
            "System provides confidence scores for each extracted theme",
            "Analysis handles multiple input sources (original text + transcriptions) combined"
          ],
          "implementation": {
            "frontend": [
              "ThemeDisplay.svelte component showing extracted themes as cards",
              "Theme hierarchy visualization (tree or nested list)",
              "Theme editing interface (rename, merge, split themes)",
              "Relevance score indicators (progress bars or stars)",
              "Key entity tags for each theme",
              "Accept/reject buttons for theme suggestions",
              "Filter and search themes by category or keyword",
              "Theme history showing previous analyses for conversation"
            ],
            "backend": [
              "POST /api/analyze endpoint accepting text and conversationId",
              "Integration with decompose_requirements() from planning_pipeline/decomposition.py",
              "BAML function call for theme extraction using Claude/GPT-4",
              "Semantic similarity calculation for theme deduplication",
              "Theme categorization using CategoryAnalysisSchema.baml",
              "Storage of analysis results in Context Window Array (CWA)",
              "Theme ranking algorithm based on frequency, position, and semantic weight",
              "Entity extraction service using NER or LLM-based extraction",
              "Combination logic for merging themes from multiple input sources"
            ],
            "middleware": [
              "Authentication to verify conversation ownership",
              "Rate limiting for analysis requests (20 per day per user)",
              "Input text size validation (max 50,000 characters)",
              "Request deduplication to prevent re-analyzing same content",
              "Timeout handling for LLM API calls (30 second limit)"
            ],
            "shared": [
              "ThemeAnalysisRequest model (text, transcriptions[], conversationId)",
              "Theme model (id, label, category, description, relevanceScore, confidence, entities[], parentThemeId)",
              "ThemeHierarchy model (rootThemes[], relationships[])",
              "AnalysisResult model (themes[], entities[], status, metadata)",
              "CategoryType enum (content_generation, structure, style, tone, audience)",
              "ContextEntry integration for storing themes in CWA",
              "ThemeRankingConfig (weightFrequency, weightPosition, weightSemanticDensity)",
              "Utility functions for theme similarity calculation and merging"
            ]
          },
          "testable_properties": [],
          "function_id": "AnalyzePhase.extractThemes",
          "related_concepts": [
            "requirement decomposition",
            "theme categorization",
            "semantic analysis",
            "hierarchical structure extraction",
            "context window management",
            "relevance scoring",
            "named entity recognition"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_015.4",
          "description": "Execute generate phase to produce written content based on user prompt, extracted themes, and conversation context using LLM generation",
          "type": "sub_process",
          "parent_id": "REQ_015",
          "children": [],
          "acceptance_criteria": [
            "System generates content incorporating all approved themes from analysis phase",
            "User prompt is combined with theme context to create comprehensive LLM prompt",
            "Content generation uses appropriate LLM model (Claude Sonnet or GPT-4)",
            "Generated content streams to UI in real-time (chunk-by-chunk)",
            "Generation completes within 60 seconds for 2000-word outputs",
            "Generated content follows user-specified style (formal, casual, academic, creative)",
            "System maintains conversation context from previous turns (stored in CWA)",
            "User can specify content length (short/medium/long or word count range)",
            "Failed generations are retried with adjusted parameters",
            "Generated content is stored as conversation turn with metadata"
          ],
          "implementation": {
            "frontend": [
              "GenerationPrompt.svelte component for user to specify writing instructions",
              "StyleSelector.svelte dropdown for content style selection",
              "LengthSelector.svelte for target word count or length",
              "StreamingMessage.svelte component displaying real-time generation",
              "Stop generation button to cancel in-progress generation",
              "Regenerate button with option to adjust parameters",
              "Copy to clipboard and export options for generated content",
              "Version history showing multiple generation attempts"
            ],
            "backend": [
              "POST /api/generate endpoint accepting prompt, themes, and conversation context",
              "Integration with BAML functions for structured LLM calls",
              "Claude SDK or OpenAI API client with streaming support",
              "Prompt builder combining user input + themes + context from CWA",
              "Context retrieval from CWA using semantic search for relevant history",
              "Streaming response handler using Server-Sent Events (SSE)",
              "Generation result storage in database and CWA",
              "Retry logic with temperature adjustment for failed generations",
              "Token usage tracking and cost estimation per generation"
            ],
            "middleware": [
              "Authentication to verify conversation ownership",
              "Rate limiting for generation requests (50 per day per user)",
              "Request validation for prompt and theme references",
              "Streaming connection timeout handling (60 seconds)",
              "Token limit enforcement based on user tier/quota"
            ],
            "shared": [
              "GenerationRequest model (prompt, themeIds[], style, targetLength, conversationId)",
              "GenerationResponse model (content, metadata, tokenUsage, model, status)",
              "ContentStyle enum (formal, casual, academic, creative, technical, narrative)",
              "ContentLength enum (short: 200-500, medium: 500-1500, long: 1500-3000 words)",
              "StreamChunk model (content, isComplete, metadata)",
              "PromptTemplate utility for building context-aware prompts",
              "GenerationConfig (model, temperature, maxTokens, stopSequences)",
              "ContextEntry for storing generation results in CWA"
            ]
          },
          "testable_properties": [],
          "function_id": "GeneratePhase.createContent",
          "related_concepts": [
            "prompt engineering",
            "context window optimization",
            "streaming responses",
            "content structuring",
            "style adaptation",
            "iterative refinement",
            "multi-turn generation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_015.5",
          "description": "Add review phase allowing user to evaluate generated content, provide feedback, request revisions, and iterate until satisfied",
          "type": "sub_process",
          "parent_id": "REQ_015",
          "children": [],
          "acceptance_criteria": [
            "Generated content is displayed in reviewable format with clear formatting",
            "User can accept, reject, or request revisions on generated content",
            "Feedback form allows specific comments on sections or overall content",
            "System tracks revision history with timestamps and change summaries",
            "User can compare different versions side-by-side",
            "Revision requests are categorized (tone, length, accuracy, structure)",
            "Approved content can be exported in multiple formats (Markdown, PDF, DOCX)",
            "User can mark content as final and archive conversation",
            "System learns from feedback to improve future generations (optional)",
            "Review phase integrates with checkpoint system for resumable workflows"
          ],
          "implementation": {
            "frontend": [
              "ReviewPanel.svelte component displaying generated content with annotations",
              "FeedbackForm.svelte with text input and revision category checkboxes",
              "VersionComparison.svelte showing diff view between versions",
              "ApprovalButtons.svelte (Accept, Request Revision, Reject)",
              "RevisionHistory.svelte list showing all versions with timestamps",
              "ExportOptions.svelte dropdown for format selection (MD, PDF, DOCX)",
              "ContentAnnotation tool for highlighting specific sections",
              "FinalizeWorkflow modal for marking conversation as complete"
            ],
            "backend": [
              "POST /api/review/feedback endpoint accepting feedback and revision requests",
              "GET /api/review/versions endpoint retrieving version history",
              "POST /api/review/approve endpoint marking content as final",
              "POST /api/review/export endpoint generating downloadable files",
              "Version storage service maintaining content snapshots",
              "Feedback processing service categorizing and storing user comments",
              "Revision generation endpoint (calls GeneratePhase with feedback context)",
              "Export service using libraries (markdown-pdf, docx generator)",
              "Checkpoint integration for saving review state"
            ],
            "middleware": [
              "Authentication to verify conversation ownership",
              "Content version validation ensuring version exists",
              "Export format validation and rate limiting (10 exports per hour)",
              "Request sanitization for feedback text input"
            ],
            "shared": [
              "ReviewFeedback model (contentVersionId, overallRating, comments, revisionCategories[], timestamp)",
              "RevisionCategory enum (tone, length, accuracy, structure, style, detail)",
              "ContentVersion model (id, content, versionNumber, generationMetadata, createdAt)",
              "ApprovalStatus enum (pending, approved, rejected, revision_requested)",
              "ExportFormat enum (markdown, pdf, docx, html)",
              "VersionDiff utility for comparing content versions",
              "ExportConfig interface (format, includeMetadata, pageSize)",
              "CheckpointState integration for review phase persistence"
            ]
          },
          "testable_properties": [],
          "function_id": "ReviewPhase.presentForFeedback",
          "related_concepts": [
            "user feedback collection",
            "revision tracking",
            "version comparison",
            "feedback categorization",
            "iterative refinement",
            "content approval workflow",
            "export formats"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_016",
      "description": "The system must provide state persistence through checkpointing",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_016.1",
          "description": "Save conversation state to checkpoints",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.save",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_016.2",
          "description": "The `orchestrator.py` file implements an autonomous project builder leveraging Claude Code to initiate and manage the entire writing agent workflow, from initial prompt generation to content refinement.",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [
            "The orchestrator.py script successfully initiates a new project based on a user-provided prompt.",
            "The script correctly invokes Claude Code to generate an initial draft.",
            "The script manages the subsequent steps of the workflow (theme extraction, content generation, etc.)",
            "The script logs all actions and decisions taken during the workflow.",
            "The script handles errors gracefully and provides informative error messages."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "orchestrator.py"
            ],
            "middleware": [
              "Claude Code API integration"
            ],
            "shared": [
              "Prompt templates",
              "Workflow definitions"
            ]
          },
          "testable_properties": [],
          "function_id": "Orchestrator-1: Autonomous Project Builder",
          "related_concepts": [
            "Claude Code",
            "Workflow Automation",
            "Prompt Engineering"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_016.2.1",
          "description": "The `loop-runner.py` file establishes a continuous feature implementation loop, ensuring that the writing agent remains up-to-date with the latest features and improvements.",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [
            "The loop-runner.py script automatically triggers the execution of the workflow for each new feature.",
            "The script monitors the performance of the workflow and identifies areas for optimization.",
            "The script automatically deploys the updated workflow to the production environment.",
            "The script provides a mechanism for manually triggering the workflow execution."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "loop-runner.py"
            ],
            "middleware": [
              "Deployment pipeline integration"
            ],
            "shared": [
              "Feature flags",
              "Deployment scripts"
            ]
          },
          "testable_properties": [],
          "function_id": "LoopRunner-1: Continuous Feature Implementation Loop",
          "related_concepts": [
            "Continuous Integration",
            "DevOps",
            "Feature Flags"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_016.2.2",
          "description": "This process enables the system to resume a partially completed writing agent workflow from a previous checkpoint, preserving user progress.",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [
            "The system correctly loads the state data from the checkpoint file.",
            "The system resumes the workflow execution from the saved state.",
            "The system handles corrupted or invalid checkpoint files gracefully.",
            "The system provides a mechanism for creating new checkpoints."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "checkpointing_utils.py"
            ],
            "middleware": [
              "Database integration (for checkpoint storage)"
            ],
            "shared": [
              "Checkpoint data format",
              "Serialization/deserialization libraries"
            ]
          },
          "testable_properties": [],
          "function_id": "Checkpointing-1: Load Checkpoint Data for Resume",
          "related_concepts": [
            "State Persistence",
            "Resume Functionality",
            "Workflow State Management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_016.2.3",
          "description": "The backend file I/O components facilitate the reading of files from the file system, a necessary step for processing attachments.",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [
            "The `extract_file_paths` function correctly identifies and extracts file paths from text output.",
            "The `read_file_content` function successfully reads the content of a specified file.",
            "The file I/O operations are secure and prevent unauthorized access to files."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "planning_pipeline/helpers.py"
            ],
            "middleware": [],
            "shared": [
              "File system libraries",
              "Security protocols"
            ]
          },
          "testable_properties": [],
          "function_id": "FileAttachment-1: Backend File I/O",
          "related_concepts": [
            "File System Access",
            "Data Ingestion",
            "File Handling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_016.2.4",
          "description": "The BAML system supports an 'audio' type, but this functionality is currently not implemented or utilized within the writing agent.",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [
            "The BAML system correctly defines the 'audio' type.",
            "The system provides a mechanism for associating audio data with the 'audio' type."
          ],
          "implementation": {
            "frontend": [],
            "backend": [],
            "middleware": [],
            "shared": [
              "BAML data model",
              "Audio type definitions"
            ]
          },
          "testable_properties": [],
          "function_id": "Transcription-1: BAML Audio Type (Unused)",
          "related_concepts": [
            "BAML Types",
            "Multimodal Data",
            "Audio Processing"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_016.3",
          "description": "Track Git commits in checkpoints",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.track",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_016.4",
          "description": "Store phase results",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.store",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_016.5",
          "description": "Enable cleanup operations",
          "type": "sub_process",
          "parent_id": "REQ_016",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.enable",
          "related_concepts": [],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_017",
      "description": "The system must support semantic search for context retrieval using TF-IDF",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_017.1",
          "description": "Tokenize search queries by splitting text into normalized tokens, removing stop words, and applying stemming/lemmatization for consistent matching",
          "type": "sub_process",
          "parent_id": "REQ_017",
          "children": [],
          "acceptance_criteria": [
            "Query text must be split into individual tokens (words)",
            "All tokens must be converted to lowercase for case-insensitive matching",
            "Common stop words (e.g., 'the', 'is', 'at', 'which') must be removed from token list",
            "Tokens must be stemmed or lemmatized to base form (e.g., 'running' \u2192 'run')",
            "Special characters and punctuation must be handled appropriately (removed or tokenized)",
            "Empty or whitespace-only queries must return empty token list",
            "Tokenization must handle multi-language text if applicable",
            "Token list must maintain order for phrase-based searches if needed",
            "Function must return List[str] of normalized tokens"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create tokenizeQuery() method in SearchIndex class",
              "Integrate NLP library (e.g., NLTK, spaCy, or custom tokenizer)",
              "Load stop words list from configuration or library",
              "Implement text normalization (lowercase, whitespace trimming)",
              "Apply stemming/lemmatization algorithm",
              "Handle edge cases (empty strings, special characters, numbers)"
            ],
            "middleware": [],
            "shared": [
              "Define TokenizerConfig model with stop_words, stemming_enabled, case_sensitive flags",
              "Create reusable text normalization utility functions",
              "Store stop words list as shared constant or configuration file"
            ]
          },
          "testable_properties": [],
          "function_id": "SearchIndex.tokenizeQuery",
          "related_concepts": [
            "text_preprocessing",
            "natural_language_processing",
            "stop_words",
            "stemming",
            "lemmatization",
            "tokenization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_017.2",
          "description": "Compute TF-IDF (Term Frequency-Inverse Document Frequency) vectors for tokenized queries and indexed documents to enable semantic similarity calculations",
          "type": "sub_process",
          "parent_id": "REQ_017",
          "children": [],
          "acceptance_criteria": [
            "Term Frequency (TF) must be calculated as count of term occurrences in document/query",
            "Inverse Document Frequency (IDF) must be calculated as log(total_documents / documents_containing_term)",
            "TF-IDF score for each term must be computed as TF * IDF",
            "Vector must represent all terms in the vocabulary with their TF-IDF scores",
            "Vectors must be normalized (L2 normalization) for cosine similarity calculations",
            "Zero vectors must be handled for documents/queries with no matching terms",
            "Vocabulary index must be consistent across all documents and queries",
            "IDF values must be pre-computed and cached for all indexed documents",
            "Function must return sparse or dense vector representation (numpy array or similar)",
            "Vector dimensions must match the vocabulary size"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create computeTfIdfVector() method in VectorSearchIndex class",
              "Build vocabulary index from all indexed documents during indexing phase",
              "Calculate and store IDF values for each term in vocabulary",
              "Implement TF calculation for input token list",
              "Compute TF-IDF scores by multiplying TF and IDF values",
              "Apply L2 normalization to resulting vector",
              "Use sparse matrix representation for memory efficiency",
              "Cache IDF values to avoid recalculation on every query"
            ],
            "middleware": [],
            "shared": [
              "Define TfIdfVector model/type with vector data and metadata",
              "Create VocabularyIndex model mapping terms to vector indices",
              "Implement vector normalization utility function",
              "Define IdfCache model for storing pre-computed IDF values",
              "Create sparse vector utility functions for efficient storage"
            ]
          },
          "testable_properties": [],
          "function_id": "VectorSearchIndex.computeTfIdfVector",
          "related_concepts": [
            "term_frequency",
            "inverse_document_frequency",
            "vector_space_model",
            "document_vectorization",
            "sparse_matrices",
            "vocabulary_index"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_017.3",
          "description": "Calculate cosine similarity between query vector and all document vectors to measure semantic relevance, returning similarity scores for ranking",
          "type": "sub_process",
          "parent_id": "REQ_017",
          "children": [],
          "acceptance_criteria": [
            "Cosine similarity must be calculated as dot(query_vector, doc_vector) / (||query_vector|| * ||doc_vector||)",
            "Similarity scores must range from 0 (no similarity) to 1 (identical)",
            "Function must compute similarity against all indexed document vectors",
            "Zero vectors must return similarity score of 0",
            "Normalized vectors must use optimized dot product (since magnitudes are 1)",
            "Computation must be efficient for large document collections (vectorized operations)",
            "Function must return list of (document_id, similarity_score) tuples",
            "Scores must be accurate to at least 4 decimal places",
            "Calculation must handle sparse vectors efficiently"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create calculateCosineSimilarity() method in VectorSearchIndex class",
              "Implement dot product calculation between query and document vectors",
              "Use vectorized operations (numpy/scipy) for batch similarity computation",
              "Optimize for sparse vectors using sparse matrix operations",
              "Handle edge cases (zero vectors, single document, empty index)",
              "Return list of document IDs with corresponding similarity scores",
              "Ensure numerical stability in calculations"
            ],
            "middleware": [],
            "shared": [
              "Define SimilarityScore model with document_id and score fields",
              "Create vector operation utility functions (dot_product, magnitude)",
              "Implement batch similarity calculation utilities for performance",
              "Define constants for similarity thresholds if needed"
            ]
          },
          "testable_properties": [],
          "function_id": "VectorSearchIndex.calculateCosineSimilarity",
          "related_concepts": [
            "cosine_similarity",
            "dot_product",
            "vector_magnitude",
            "similarity_scoring",
            "vector_comparison",
            "angular_distance"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_017.4",
          "description": "Rank documents by cosine similarity scores in descending order, apply limit parameter, and return top N results with metadata for search response",
          "type": "sub_process",
          "parent_id": "REQ_017",
          "children": [],
          "acceptance_criteria": [
            "Results must be sorted by similarity score in descending order (highest first)",
            "Function must accept 'limit' parameter to control number of results returned",
            "Default limit must be 10 results if not specified",
            "Maximum limit must be enforced (e.g., 100 results) to prevent performance issues",
            "Each result must include document_id, similarity_score, and entry metadata",
            "Results with similarity score of 0 must be excluded from output",
            "Optional minimum similarity threshold must be configurable",
            "Function must return empty list if no documents match above threshold",
            "Result format must match SearchResult model defined in context_window_array",
            "Results must include entry content or summary based on configuration",
            "Response time must be optimized using heap-based top-k selection for large result sets"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create rankAndReturnResults() method in VectorSearchIndex class",
              "Sort similarity scores in descending order",
              "Apply limit parameter to select top N results",
              "Implement heap-based selection for large result sets (heapq.nlargest)",
              "Filter out results below minimum similarity threshold",
              "Retrieve full entry data for top results from CentralContextStore",
              "Format results according to SearchResult model",
              "Add pagination support if needed (offset + limit)",
              "Log search performance metrics (query time, result count)"
            ],
            "middleware": [],
            "shared": [
              "Define SearchResult model with entry_id, score, entry, and metadata fields",
              "Create SearchConfig model with limit, min_threshold, include_content flags",
              "Implement result formatting utilities",
              "Define default constants for limit (10) and max_limit (100)",
              "Create SearchResponse model wrapping results list with query metadata"
            ]
          },
          "testable_properties": [],
          "function_id": "VectorSearchIndex.rankAndReturnResults",
          "related_concepts": [
            "result_ranking",
            "top_k_selection",
            "search_results",
            "pagination",
            "result_formatting",
            "score_thresholding"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_017.5",
          "description": "Build initial TF-IDF index from existing context entries, maintain vocabulary consistency, and provide incremental update capability when new entries are added",
          "type": "sub_process",
          "parent_id": "REQ_017",
          "children": [],
          "acceptance_criteria": [
            "Index must be built from all entries in CentralContextStore on initialization",
            "Vocabulary must be constructed from all unique tokens across all documents",
            "IDF values must be calculated based on entire document corpus",
            "Index must support incremental updates when new entries are added",
            "Adding new entries must update vocabulary and recalculate IDF values",
            "Index must be persisted to disk for fast startup (optional but recommended)",
            "Index rebuilding must be triggered when corpus changes significantly",
            "Memory usage must be optimized using sparse matrix storage",
            "Index build time must be logged and monitored",
            "Concurrent reads must be supported during index updates"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create buildIndex() method to initialize index from CentralContextStore",
              "Iterate through all context entries and tokenize content",
              "Build vocabulary index mapping terms to vector positions",
              "Calculate IDF values for all terms in vocabulary",
              "Store document vectors in sparse matrix format",
              "Implement addToIndex() method for incremental updates",
              "Implement rebuildIndex() method for full reindexing",
              "Add index persistence using pickle or joblib for caching",
              "Implement thread-safe read/write locks for concurrent access",
              "Monitor index size and performance metrics"
            ],
            "middleware": [],
            "shared": [
              "Define IndexMetadata model with vocabulary_size, document_count, last_updated fields",
              "Create IndexConfig model with persistence_path, auto_rebuild_threshold settings",
              "Implement index serialization/deserialization utilities",
              "Define IndexStats model for monitoring index health and performance"
            ]
          },
          "testable_properties": [],
          "function_id": "VectorSearchIndex.buildAndMaintainIndex",
          "related_concepts": [
            "index_building",
            "incremental_indexing",
            "vocabulary_management",
            "index_persistence",
            "document_corpus",
            "index_optimization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_017.6",
          "description": "Main search method that orchestrates the complete TF-IDF semantic search pipeline by accepting query string, tokenizing, vectorizing, computing similarities, and returning ranked results",
          "type": "sub_process",
          "parent_id": "REQ_017",
          "children": [],
          "acceptance_criteria": [
            "Method must accept query string and optional SearchConfig parameters",
            "Query must be tokenized using tokenizeQuery()",
            "Query vector must be computed using computeTfIdfVector()",
            "Similarities must be calculated using calculateCosineSimilarity()",
            "Results must be ranked and limited using rankAndReturnResults()",
            "Method must handle empty query strings gracefully (return empty results)",
            "Method must handle queries with no matching terms (return empty results)",
            "Search must complete within reasonable time (< 1 second for 1000 documents)",
            "Method must return List[SearchResult] matching the defined model",
            "Errors during search must be logged and return empty results or raise appropriate exceptions",
            "Method must be the primary public API for semantic search functionality"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create search() method as main entry point in VectorSearchIndex class",
              "Accept query: str and config: SearchConfig parameters",
              "Call tokenizeQuery() to process input query",
              "Call computeTfIdfVector() to generate query vector",
              "Call calculateCosineSimilarity() to score all documents",
              "Call rankAndReturnResults() to get top N results",
              "Add error handling and logging throughout pipeline",
              "Implement query performance timing and logging",
              "Return formatted List[SearchResult]",
              "Add input validation for query string"
            ],
            "middleware": [
              "Add request validation for search API endpoint",
              "Implement rate limiting for search requests if exposed via API",
              "Add logging middleware to track search queries and performance"
            ],
            "shared": [
              "Define SearchRequest model if exposing via API",
              "Create SearchResponse wrapper with results, query_time, total_matches",
              "Implement search result caching utilities for repeated queries",
              "Define SearchError exception types for specific failure modes"
            ]
          },
          "testable_properties": [],
          "function_id": "VectorSearchIndex.search",
          "related_concepts": [
            "search_orchestration",
            "query_processing",
            "end_to_end_search",
            "search_api",
            "result_delivery"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_018",
      "description": "The system must implement addressable context storage with unique IDs",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_018.1",
          "description": "Generate unique ctx_XXXXXX identifiers for all context entries using a consistent format with collision detection",
          "type": "sub_process",
          "parent_id": "REQ_018",
          "children": [],
          "acceptance_criteria": [
            "All generated IDs must follow the exact format ctx_XXXXXX where X is alphanumeric",
            "ID generation must guarantee uniqueness across the entire system",
            "ID generation must detect and handle collisions by regenerating",
            "ID generation must complete in under 10ms for 99% of requests",
            "Generated IDs must be URL-safe and filesystem-safe",
            "IDs must be sortable chronologically if using sequential generation",
            "ID generation must work correctly in concurrent/parallel execution scenarios",
            "System must log collision events for monitoring",
            "ID format must support at least 1 billion unique entries (6 alphanumeric characters = 36^6 = 2.1B combinations)"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - ID generation happens server-side",
              "Display ctx_XXXXXX IDs in UI components as read-only text",
              "Add copy-to-clipboard functionality for context IDs in conversation views"
            ],
            "backend": [
              "Create ContextIdGenerator service with generateId() method",
              "Implement collision detection by checking existing IDs before returning",
              "Add configurable ID format (prefix + length + character set)",
              "Create retry logic for collision scenarios (max 3 attempts)",
              "Implement thread-safe ID generation using locks or atomic operations",
              "Add ID generation metrics/logging for monitoring",
              "Create utility function to validate ID format: validateContextId(id: string): boolean"
            ],
            "middleware": [
              "No middleware requirements - ID generation is a pure service function"
            ],
            "shared": [
              "Define ContextId type/interface with format validation",
              "Create ID_FORMAT constant defining regex pattern: /^ctx_[A-Za-z0-9]{6}$/",
              "Define ID_PREFIX constant = 'ctx_'",
              "Define ID_LENGTH constant = 10 (including prefix)",
              "Create utility function: isValidContextId(id: string): boolean",
              "Define CollisionError exception class for ID generation failures"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextStore.generateContextId",
          "related_concepts": [
            "UUID generation",
            "ID format standardization",
            "Collision detection",
            "ID uniqueness guarantees",
            "Sequential vs random IDs",
            "ID prefix conventions"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_018.2",
          "description": "Store context entries with unique IDs in persistent storage with atomic operations and validation",
          "type": "sub_process",
          "parent_id": "REQ_018",
          "children": [],
          "acceptance_criteria": [
            "Each entry must be stored with its unique ctx_XXXXXX ID as the primary key",
            "Storage operation must be atomic - either fully succeeds or fully fails",
            "System must prevent duplicate IDs from being stored",
            "Storage must validate entry structure before persisting",
            "Storage operation must complete in under 100ms for 95% of requests",
            "System must return the stored entry with confirmation of successful storage",
            "Failed storage operations must throw specific error types (DuplicateIdError, ValidationError, StorageError)",
            "Storage must support concurrent writes from multiple processes/threads safely",
            "All stored entries must include metadata: timestamp, entry_type, source",
            "Storage must maintain referential integrity for entries with relationships"
          ],
          "implementation": {
            "frontend": [
              "Create ContextEntryForm component for creating new entries",
              "Add form validation for required fields before submission",
              "Display loading state during storage operations",
              "Show success/error notifications after storage attempts",
              "Add retry button for failed storage operations",
              "Display stored entry ID after successful creation"
            ],
            "backend": [
              "Create ContextStore.storeEntry(entry: ContextEntry): StoredEntry method",
              "Implement database transaction wrapping for atomic operations",
              "Add unique constraint on ctx_id column in database schema",
              "Create entry validation service: validateEntry(entry: ContextEntry): ValidationResult",
              "Implement duplicate detection check before insertion",
              "Add database indexes on ctx_id and entry_type columns for performance",
              "Create error handling for database constraint violations",
              "Implement retry logic with exponential backoff for transient failures",
              "Add audit logging for all storage operations",
              "Create batch storage method: storeEntries(entries: ContextEntry[]): StoredEntry[]"
            ],
            "middleware": [
              "Add request validation middleware to ensure required fields are present",
              "Implement authorization middleware to verify user can create entries",
              "Add rate limiting middleware to prevent storage abuse (max 100 entries/minute per user)",
              "Create request sanitization middleware to clean input data"
            ],
            "shared": [
              "Define ContextEntry interface with all required fields (id, type, content, metadata)",
              "Define StoredEntry interface extending ContextEntry with storage metadata",
              "Create ValidationResult type with success flag and error messages",
              "Define EntryType enum with all valid entry types",
              "Create StorageError exception hierarchy (DuplicateIdError, ValidationError, TransactionError)",
              "Define EntryMetadata interface (timestamp, source, version, created_by)",
              "Create entry validation rules as JSON schema or type guards"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextStore.storeEntry",
          "related_concepts": [
            "Data persistence",
            "ACID transactions",
            "Entry validation",
            "Duplicate prevention",
            "Storage indexing",
            "Entry versioning",
            "Concurrent writes"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_018.3",
          "description": "Enable fast ID-based retrieval of context entries with caching and error handling",
          "type": "sub_process",
          "parent_id": "REQ_018",
          "children": [],
          "acceptance_criteria": [
            "System must retrieve entries by exact ctx_XXXXXX ID match",
            "Retrieval must return null or throw NotFoundError if ID doesn't exist",
            "Retrieval must complete in under 50ms for 99% of requests (cached)",
            "Retrieval must complete in under 200ms for 95% of requests (uncached)",
            "System must validate ID format before querying database",
            "Retrieved entries must include all stored fields and metadata",
            "System must support batch retrieval: getByIds(ids: string[]): Map<string, ContextEntry>",
            "Retrieval must handle corrupted or incomplete data gracefully",
            "System must implement read-through caching for frequently accessed entries",
            "Cache must invalidate when entries are updated or deleted"
          ],
          "implementation": {
            "frontend": [
              "Create ContextEntryViewer component to display retrieved entries",
              "Add search/lookup interface for finding entries by ID",
              "Display loading skeleton while retrieving entries",
              "Show 404-style message when entry not found",
              "Add breadcrumb navigation showing entry ID",
              "Create entry detail page with deep linking support (/context/:id)",
              "Add refresh button to reload entry data"
            ],
            "backend": [
              "Create ContextStore.getById(id: string): ContextEntry | null method",
              "Implement database query with indexed lookup on ctx_id column",
              "Add Redis/in-memory caching layer with 5-minute TTL",
              "Create cache key format: 'ctx:entry:{id}'",
              "Implement cache-aside pattern: check cache, then database, then populate cache",
              "Add batch retrieval method: getByIds(ids: string[]): Map<string, ContextEntry>",
              "Optimize batch retrieval with single SELECT IN query",
              "Create query performance monitoring and logging",
              "Implement entry deserialization from database format",
              "Add database connection pooling for concurrent reads"
            ],
            "middleware": [
              "Add ID format validation middleware before query execution",
              "Implement response compression for large entries",
              "Add ETag support for client-side caching",
              "Create request tracing middleware to track retrieval performance"
            ],
            "shared": [
              "Define RetrievalOptions interface (include_deleted, include_metadata, cache_ttl)",
              "Create NotFoundError exception class with helpful error messages",
              "Define CacheKey utility functions for consistent key generation",
              "Create entry serialization/deserialization utilities",
              "Define ContextEntryDTO (Data Transfer Object) for API responses",
              "Create type guard: isContextEntry(data: unknown): data is ContextEntry"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextStore.retrieveById",
          "related_concepts": [
            "Data retrieval",
            "Query optimization",
            "Caching strategies",
            "Not found handling",
            "Query performance",
            "Cache invalidation",
            "Lazy loading"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_018.4",
          "description": "Support filtering and querying context entries by entry type with pagination and sorting",
          "type": "sub_process",
          "parent_id": "REQ_018",
          "children": [],
          "acceptance_criteria": [
            "System must filter entries by EntryType enum values (FILE, COMMAND, TASK, etc.)",
            "Filtering must support multiple entry types in a single query (OR logic)",
            "Query must support pagination with configurable page size (default 50, max 500)",
            "Results must support sorting by: timestamp (desc/asc), id, entry_type",
            "Filtering query must complete in under 500ms for 95% of requests",
            "System must return total count of matching entries for pagination UI",
            "Empty result sets must return empty array, not null or error",
            "Filtering must support combining with other criteria (date range, source, search terms)",
            "System must validate entry type values before querying",
            "Results must include pagination metadata (page, total_pages, total_count, has_next)"
          ],
          "implementation": {
            "frontend": [
              "Create EntryTypeFilter component with checkboxes for each entry type",
              "Add pagination controls (previous, next, page numbers)",
              "Create sort dropdown (newest first, oldest first, alphabetical)",
              "Display filtered results in scrollable list or table view",
              "Show result count and active filters",
              "Add 'Clear filters' button to reset all filters",
              "Implement URL query parameter sync for shareable filtered views",
              "Add loading state during filter operations",
              "Create EntryTypeSelector multi-select dropdown component"
            ],
            "backend": [
              "Create ContextStore.filterByType(types: EntryType[], options: FilterOptions): PaginatedResult method",
              "Implement SQL query with WHERE entry_type IN (...) clause",
              "Add database index on (entry_type, timestamp) for optimized filtering",
              "Create QueryBuilder class for composing complex filter queries",
              "Implement pagination logic with LIMIT and OFFSET",
              "Add total count query: SELECT COUNT(*) FROM entries WHERE ...",
              "Create sorting logic with ORDER BY clause generation",
              "Implement query result caching for common filter combinations",
              "Add query parameter validation and sanitization",
              "Create method: filterByTypeAndDateRange(types, start_date, end_date, options)"
            ],
            "middleware": [
              "Add query parameter parsing middleware",
              "Implement pagination parameter validation (page >= 1, limit <= 500)",
              "Add default values middleware for missing parameters",
              "Create query complexity analysis to prevent expensive operations"
            ],
            "shared": [
              "Define EntryType enum with all valid types (FILE, COMMAND, COMMAND_RESULT, TASK, TASK_RESULT, SEARCH_RESULT, SUMMARY, CONTEXT_REQUEST)",
              "Create FilterOptions interface (page, limit, sort_by, sort_order, include_metadata)",
              "Define PaginatedResult<T> interface (data: T[], pagination: PaginationMeta)",
              "Create PaginationMeta interface (page, total_pages, total_count, has_next, has_prev)",
              "Define SortOrder enum (ASC, DESC)",
              "Create validation utility: validateEntryTypes(types: string[]): EntryType[]",
              "Define QueryOptions interface for advanced filtering"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextStore.filterByType",
          "related_concepts": [
            "Query filtering",
            "Entry categorization",
            "Pagination",
            "Result sorting",
            "Query building",
            "Index optimization",
            "Multi-criteria filtering"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_019",
      "description": "The system must extract hierarchical requirements with parent-child relationships",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_019.1",
          "description": "Identify parent requirements",
          "type": "sub_process",
          "parent_id": "REQ_019",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.identify",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_019.2",
          "description": "Extract sub-processes",
          "type": "sub_process",
          "parent_id": "REQ_019",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.process",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_019.3",
          "description": "Define implementation details",
          "type": "sub_process",
          "parent_id": "REQ_019",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.define",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_019.4",
          "description": "Build requirement tree structure",
          "type": "sub_process",
          "parent_id": "REQ_019",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.build",
          "related_concepts": [],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_020",
      "description": "The system must categorize requirements by theme and type",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_020.1",
          "description": "Assign category labels",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.assign",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_020.2",
          "description": "The core orchestrator responsible for initiating and managing the entire writing agent workflow, including theme extraction, content generation, and multi-step workflow execution.",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [
            "The orchestrator successfully initiates the entire writing agent pipeline.",
            "The orchestrator correctly identifies and extracts themes from the input text/audio.",
            "The orchestrator accurately triggers the multi-step workflow pipeline.",
            "The orchestrator successfully integrates with the Claude/GPT-4 LLM for content generation.",
            "The orchestrator correctly utilizes the Context Window Array (CWA) for managing context."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "orchestrator.py"
            ],
            "middleware": [
              "authentication",
              "authorization"
            ],
            "shared": [
              "BAML definitions",
              "CWA schema"
            ]
          },
          "testable_properties": [],
          "function_id": "Orchestrator - Project Builder",
          "related_concepts": [
            "BAML",
            "Claude/GPT-4",
            "Multi-Step Workflows",
            "Context Management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_020.2.1",
          "description": "A continuously running process that executes the multi-step workflow pipeline, monitoring for completion and triggering the next step.",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [
            "The workflow runner continuously monitors the status of the writing agent pipeline.",
            "The workflow runner correctly resumes execution from checkpoints in case of interruption.",
            "The workflow runner accurately triggers the next step in the multi-step workflow pipeline based on the current state."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "loop-runner.py"
            ],
            "middleware": [
              "checkpointing",
              "error handling"
            ],
            "shared": [
              "Multi-Step Workflow Definitions"
            ]
          },
          "testable_properties": [],
          "function_id": "Workflow Runner - Continuous Execution",
          "related_concepts": [
            "Multi-Step Workflows",
            "Checkpoint & Resume System"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_020.2.2",
          "description": "Manages the context window array (CWA) to store and retrieve relevant information during the writing agent process.",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [
            "The CWA is correctly populated with relevant information extracted from the input text/audio.",
            "The CWA is correctly utilized by the theme extraction module.",
            "The CWA is correctly utilized by the content generation module.",
            "The CWA supports efficient storage and retrieval of context data."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "orchestrator.py",
              "loop-runner.py"
            ],
            "middleware": [
              "data caching",
              "memory management"
            ],
            "shared": [
              "CWA schema",
              "Theme Extraction BAML"
            ]
          },
          "testable_properties": [],
          "function_id": "Context Management - CWA Integration",
          "related_concepts": [
            "Context Window Array (CWA)",
            "Theme Extraction"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_020.2.3",
          "description": "Decomposes the input text/audio into key themes using the BAML-based requirement decomposition process.",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [
            "The BAML definitions correctly map the input text/audio to relevant themes.",
            "The theme extraction process accurately identifies and categorizes themes.",
            "The theme extraction process is efficient and scalable."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "orchestrator.py"
            ],
            "middleware": [
              "BAML processing",
              "LLM integration"
            ],
            "shared": [
              "BAML definitions",
              "Claude/GPT-4 integration"
            ]
          },
          "testable_properties": [],
          "function_id": "Theme Extraction - BAML-Based Decomposition",
          "related_concepts": [
            "BAML",
            "Theme Extraction"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_020.2.4",
          "description": "Generates content based on the extracted themes and user prompts using the Claude/GPT-4 LLM.",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [
            "The LLM correctly generates content based on the extracted themes and user prompts.",
            "The generated content is coherent and relevant to the input text/audio.",
            "The LLM integration is efficient and scalable."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "orchestrator.py"
            ],
            "middleware": [
              "LLM API calls",
              "Rate limiting"
            ],
            "shared": [
              "BAML definitions",
              "Claude/GPT-4 integration"
            ]
          },
          "testable_properties": [],
          "function_id": "Content Generation - LLM Integration",
          "related_concepts": [
            "BAML",
            "Claude/GPT-4",
            "Text Generation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_020.2.5",
          "description": "Manages the conversation state, allowing for resuming the writing agent process from a checkpoint in case of interruption.",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [
            "The conversation state is correctly saved and restored.",
            "The conversation state is correctly utilized by the writing agent process.",
            "The checkpointing and resume system is reliable and efficient."
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "orchestrator.py",
              "loop-runner.py"
            ],
            "middleware": [
              "state persistence",
              "error handling"
            ],
            "shared": [
              "Conversation State Schema"
            ]
          },
          "testable_properties": [],
          "function_id": "Conversation State - Checkpoint & Resume",
          "related_concepts": [
            "Checkpoint & Resume System"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_020.3",
          "description": "Identify non-functional attributes",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.identify",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_020.4",
          "description": "Tag integration patterns",
          "type": "sub_process",
          "parent_id": "REQ_020",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.tag",
          "related_concepts": [],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_021",
      "description": "The system must support streaming LLM responses to the UI",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_021.1",
          "description": "Implement server-sent events (SSE) infrastructure to enable continuous data streaming from backend to frontend for LLM responses",
          "type": "sub_process",
          "parent_id": "REQ_021",
          "children": [],
          "acceptance_criteria": [
            "Backend establishes SSE endpoint with proper Content-Type: text/event-stream headers",
            "Backend maintains persistent connection with client during streaming",
            "Frontend EventSource client successfully connects to SSE endpoint",
            "SSE connection supports automatic reconnection with exponential backoff on disconnect",
            "Server sends proper SSE message format with 'data:' prefix and double newline delimiter",
            "Connection properly closes when streaming completes",
            "Server handles multiple concurrent SSE connections without resource leaks",
            "SSE endpoint returns appropriate CORS headers for cross-origin requests",
            "Connection timeout is configurable (default 120 seconds)",
            "Server sends periodic heartbeat/keep-alive messages to prevent timeout"
          ],
          "implementation": {
            "frontend": [
              "Create EventSource client wrapper component/service",
              "Implement connection state management (connecting, open, closed, error)",
              "Add automatic reconnection logic with exponential backoff",
              "Handle onopen, onmessage, onerror event listeners",
              "Display connection status indicator in UI",
              "Implement graceful connection cleanup on component unmount",
              "Add loading/connecting state UI feedback"
            ],
            "backend": [
              "Create SSE endpoint (e.g., /api/stream/generate)",
              "Set response headers: Content-Type: text/event-stream, Cache-Control: no-cache, Connection: keep-alive",
              "Implement streaming response writer that formats messages as SSE events",
              "Add connection management to track active SSE connections",
              "Implement heartbeat/keep-alive mechanism (ping every 30 seconds)",
              "Handle client disconnect detection and cleanup",
              "Add error handling and logging for streaming failures",
              "Implement connection timeout configuration"
            ],
            "middleware": [
              "Configure CORS to allow EventSource requests with credentials",
              "Add authentication middleware to validate SSE connection requests",
              "Implement rate limiting for SSE endpoint to prevent abuse",
              "Add request validation for streaming parameters",
              "Configure reverse proxy (if used) to support SSE passthrough"
            ],
            "shared": [
              "Define SSE message format interface/type",
              "Create StreamingConnectionState enum (CONNECTING, OPEN, CLOSED, ERROR)",
              "Define streaming configuration constants (timeouts, retry intervals)",
              "Create SSE event types enum (MESSAGE, COMPLETE, ERROR, HEARTBEAT)",
              "Define error code constants for streaming failures"
            ]
          },
          "testable_properties": [],
          "function_id": "StreamingService.implementServerSentEvents",
          "related_concepts": [
            "HTTP streaming",
            "EventSource API",
            "Content-Type: text/event-stream",
            "Keep-alive connections",
            "Connection timeout handling",
            "Reconnection logic",
            "CORS configuration for SSE"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_021.2",
          "description": "Stream LLM-generated tokens individually as they are produced, enabling real-time display of content generation",
          "type": "sub_process",
          "parent_id": "REQ_021",
          "children": [],
          "acceptance_criteria": [
            "Backend integrates with LLM provider's streaming API (OpenAI, Anthropic, etc.)",
            "Each token is sent immediately as it's received from LLM, without batching",
            "SSE messages contain individual tokens with proper UTF-8 encoding",
            "Token streaming handles multi-byte Unicode characters correctly",
            "Backend implements backpressure handling if client cannot keep up",
            "Streaming continues until LLM completes generation or max token limit reached",
            "Token metadata (e.g., finish_reason, token_count) is included in final message",
            "Streaming handles LLM API rate limits and retries gracefully",
            "Tokens are sent in order without duplication or loss",
            "Streaming performance delivers tokens with <100ms latency from LLM receipt"
          ],
          "implementation": {
            "frontend": [
              "Create token accumulation buffer in UI state",
              "Implement token append function that updates display incrementally",
              "Add typing animation or cursor effect to show active generation",
              "Handle token rendering without causing UI flicker or reflow",
              "Implement efficient DOM update strategy (virtual scrolling if needed)",
              "Display token count and generation progress indicator",
              "Add stop generation button to cancel streaming"
            ],
            "backend": [
              "Integrate LLM provider SDK with streaming support (OpenAI client, Anthropic SDK)",
              "Implement async generator function to yield tokens from LLM stream",
              "Create SSE writer that sends each token as separate event",
              "Add token encoding/escaping for SSE format",
              "Implement backpressure detection and buffering strategy",
              "Handle LLM streaming errors and API failures gracefully",
              "Add token counting and usage tracking",
              "Implement stop/cancel endpoint to abort streaming",
              "Log streaming metrics (latency, throughput, errors)",
              "Add token filtering/sanitization if needed"
            ],
            "middleware": [
              "Validate LLM request parameters before starting stream",
              "Check user permissions and quota before initiating streaming",
              "Add request context propagation for tracing streaming requests",
              "Implement timeout middleware for maximum streaming duration"
            ],
            "shared": [
              "Define StreamToken interface with token text and metadata",
              "Create StreamingMessage type with role, content, and metadata",
              "Define LLM provider configuration types",
              "Create token usage tracking types (prompt_tokens, completion_tokens, total_tokens)",
              "Define streaming event payload types for different message types"
            ]
          },
          "testable_properties": [],
          "function_id": "StreamingService.streamTokenByToken",
          "related_concepts": [
            "Token streaming",
            "LLM streaming APIs",
            "Buffer management",
            "Backpressure handling",
            "Token decoding",
            "Chunked encoding",
            "Generator functions",
            "Async iterators"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_021.3",
          "description": "Update the user interface incrementally as streaming tokens arrive, providing real-time visual feedback of content generation",
          "type": "sub_process",
          "parent_id": "REQ_021",
          "children": [],
          "acceptance_criteria": [
            "UI updates smoothly as each token arrives without full re-render",
            "Message container auto-scrolls to show latest content while streaming",
            "Auto-scroll respects user scroll position (doesn't force scroll if user scrolled up)",
            "Cursor or typing indicator shows active generation location",
            "Token rendering maintains text formatting (markdown, code blocks, etc.)",
            "UI remains responsive during streaming (no blocking or lag)",
            "Streaming message is distinguishable from completed messages",
            "Token accumulation doesn't cause memory leaks for long generations",
            "UI handles rapid token arrival (100+ tokens/second) without performance degradation",
            "Completed streaming message transitions smoothly to final state"
          ],
          "implementation": {
            "frontend": [
              "Create StreamingMessage component with incremental update logic",
              "Implement token accumulation in component state using useRef or similar",
              "Add efficient text append mechanism (avoid string concatenation in tight loop)",
              "Implement smart scroll detection (check if user is near bottom before auto-scrolling)",
              "Create typing cursor or pulse animation component",
              "Add markdown/syntax highlighting renderer that updates incrementally",
              "Implement render throttling (requestAnimationFrame) for high-frequency updates",
              "Create message completion animation/transition",
              "Add stop generation UI control that calls cancel endpoint",
              "Implement copy-to-clipboard for streaming (in-progress) messages",
              "Display generation speed (tokens/second) and estimated completion time"
            ],
            "backend": [
              "Send periodic metadata updates (token_count, elapsed_time) during stream",
              "Implement streaming completion event with final metadata",
              "Add SSE event for streaming start to trigger UI initialization",
              "Include message ID in all streaming events for correlation",
              "Send formatted content markers (e.g., code block boundaries) as metadata"
            ],
            "middleware": [
              "Add response compression configuration for SSE (if supported by client)",
              "Configure buffer size for optimal streaming performance"
            ],
            "shared": [
              "Define StreamingState enum (IDLE, STREAMING, COMPLETED, CANCELLED, ERROR)",
              "Create StreamingMetadata interface (token_count, elapsed_ms, tokens_per_second)",
              "Define UI animation constants (cursor blink rate, scroll threshold)",
              "Create message formatting types (plain text, markdown, code)",
              "Define scroll behavior configuration type"
            ]
          },
          "testable_properties": [],
          "function_id": "UIRenderer.updateIncrementally",
          "related_concepts": [
            "Incremental rendering",
            "DOM diffing",
            "Virtual DOM updates",
            "Scroll management",
            "Text cursor positioning",
            "Animation frames",
            "Render throttling",
            "Memory management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_021.4",
          "description": "Implement comprehensive error handling for streaming scenarios including connection failures, LLM API errors, and timeout conditions",
          "type": "sub_process",
          "parent_id": "REQ_021",
          "children": [],
          "acceptance_criteria": [
            "Connection errors are detected and reported to user within 5 seconds",
            "LLM API errors (rate limits, authentication, etc.) display user-friendly messages",
            "Network interruptions trigger automatic reconnection with exponential backoff",
            "Partial streaming content is preserved and displayed on error",
            "Streaming timeout errors show appropriate message with retry option",
            "Max retry attempts are configurable (default 3 attempts)",
            "Critical errors prevent retry attempts and show actionable error messages",
            "Error events are logged with full context (request ID, user ID, timestamp, error details)",
            "User can manually retry failed streaming requests",
            "Streaming errors don't crash or freeze the UI"
          ],
          "implementation": {
            "frontend": [
              "Create error boundary component wrapping streaming UI",
              "Implement error state management with error type categorization",
              "Display error messages inline in conversation (not just console)",
              "Add retry button for recoverable errors",
              "Show different error UI for network vs API vs timeout errors",
              "Preserve partial message content on error with visual indicator",
              "Implement exponential backoff timer display for retry countdown",
              "Add error reporting mechanism (send error details to backend)",
              "Create error notification/toast component for non-critical errors",
              "Implement graceful degradation (show cached/partial content if available)"
            ],
            "backend": [
              "Implement comprehensive try-catch around streaming logic",
              "Send SSE error event with error code and user-friendly message",
              "Log all streaming errors with request context and stack traces",
              "Implement circuit breaker for repeated LLM API failures",
              "Add health check endpoint for streaming service status",
              "Create error classification system (transient vs permanent errors)",
              "Implement graceful shutdown that closes active streams properly",
              "Add monitoring/alerting for high error rates",
              "Send final SSE event on error before closing connection",
              "Implement cleanup for resources on error (close LLM connections, release buffers)"
            ],
            "middleware": [
              "Add global error handler for uncaught streaming exceptions",
              "Implement error transformation middleware (convert technical errors to user messages)",
              "Add error rate limiting to prevent error spam",
              "Configure error logging middleware with structured logging"
            ],
            "shared": [
              "Define StreamingError interface with code, message, isRetryable, metadata",
              "Create error code enum (NETWORK_ERROR, API_ERROR, TIMEOUT, AUTH_ERROR, RATE_LIMIT, etc.)",
              "Define retry configuration type (max_attempts, backoff_multiplier, max_delay)",
              "Create error message templates for common errors",
              "Define error logging payload type with all required context fields"
            ]
          },
          "testable_properties": [],
          "function_id": "StreamingService.handleErrors",
          "related_concepts": [
            "Error recovery",
            "Retry strategies",
            "Circuit breaker pattern",
            "Graceful degradation",
            "Error boundaries",
            "Fallback mechanisms",
            "Error logging",
            "User error messaging"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_022",
      "description": "The system must provide conversation CRUD endpoints",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_022.1",
          "description": "Create new conversation endpoint that accepts conversation metadata and returns a conversation ID with initial state",
          "type": "sub_process",
          "parent_id": "REQ_022",
          "children": [],
          "acceptance_criteria": [
            "POST /api/conversations endpoint accepts title, description, and optional metadata",
            "Endpoint generates unique conversation ID (UUID format)",
            "Response returns conversation object with id, title, description, created_at, updated_at, and status fields",
            "Conversation is persisted to database with initial state",
            "Endpoint returns 201 Created status code on success",
            "Endpoint returns 400 Bad Request for invalid input with error details",
            "Endpoint returns 401 Unauthorized if user is not authenticated",
            "Maximum title length is validated (255 characters)",
            "Created conversation is associated with authenticated user",
            "Initial conversation entry is created in Context Window Array",
            "Endpoint responds within 500ms under normal load",
            "Transaction is rolled back if any database operation fails",
            "Audit log entry is created for conversation creation",
            "Integration test verifies full create workflow",
            "Unit tests cover validation logic and error cases"
          ],
          "implementation": {
            "frontend": [
              "NewConversationModal component with form inputs for title and description",
              "Form validation for required fields and length constraints",
              "Loading state during API call with spinner",
              "Success notification on conversation creation",
              "Error handling UI with specific error messages",
              "Redirect to new conversation view on success",
              "Keyboard shortcuts (Ctrl+N) to open new conversation modal"
            ],
            "backend": [
              "POST /api/conversations endpoint handler in FastAPI",
              "ConversationService.create_conversation() business logic method",
              "Database INSERT operation via SQLAlchemy/Prisma ORM",
              "UUID generation for conversation ID",
              "Timestamp generation for created_at and updated_at",
              "Transaction management with rollback on failure",
              "Integration with CentralContextStore to create initial entry",
              "Error handling for database constraints and validation",
              "Logging of conversation creation events"
            ],
            "middleware": [
              "Authentication middleware to verify user session/token",
              "Request body validation using Pydantic models",
              "Authorization check to verify user can create conversations",
              "Rate limiting to prevent conversation spam (max 10 per minute)",
              "CORS headers for cross-origin requests",
              "Content-Type validation (application/json required)"
            ],
            "shared": [
              "ConversationCreateRequest model with title, description, metadata fields",
              "ConversationResponse model with id, title, description, created_at, updated_at, status",
              "ConversationStatus enum (active, archived, deleted)",
              "ValidationError types for field validation",
              "Database schema/migration for conversations table",
              "Constants for max title length (255), max description length (1000)"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationController.createConversation",
          "related_concepts": [
            "REST API design",
            "UUID generation",
            "conversation initialization",
            "database transactions",
            "context window array integration",
            "authentication middleware",
            "request validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_022.2",
          "description": "Read conversation history endpoint that retrieves conversation metadata and all associated messages with pagination support",
          "type": "sub_process",
          "parent_id": "REQ_022",
          "children": [],
          "acceptance_criteria": [
            "GET /api/conversations/{id} endpoint retrieves conversation by ID",
            "Endpoint returns conversation metadata (id, title, description, timestamps)",
            "Response includes paginated message history (default 50 messages per page)",
            "Messages are ordered chronologically (oldest to newest by default)",
            "Query parameters support pagination (offset, limit, cursor-based)",
            "Query parameter allows reverse ordering (newest first)",
            "Endpoint returns 200 OK with conversation data on success",
            "Endpoint returns 404 Not Found if conversation doesn't exist",
            "Endpoint returns 401 Unauthorized if user is not authenticated",
            "Endpoint returns 403 Forbidden if user doesn't own the conversation",
            "Response includes total message count and pagination metadata",
            "Endpoint retrieves messages from Context Window Array",
            "Endpoint responds within 200ms for conversations with <1000 messages",
            "Endpoint supports filtering messages by type (user, assistant, system)",
            "Integration test verifies retrieval with pagination",
            "Unit tests cover authorization and edge cases"
          ],
          "implementation": {
            "frontend": [
              "ConversationView component displaying conversation metadata and messages",
              "MessageList component with infinite scroll or pagination controls",
              "Message component with proper rendering for user/assistant/system types",
              "Loading skeleton for initial conversation load",
              "Loading spinner for pagination requests",
              "Error state UI for failed conversation retrieval",
              "Empty state UI for conversations with no messages",
              "Scroll-to-bottom button for long conversations",
              "Message filtering controls (show all, user only, assistant only)"
            ],
            "backend": [
              "GET /api/conversations/{id} endpoint handler in FastAPI",
              "ConversationService.get_conversation() method with message retrieval",
              "Database SELECT query with JOIN to messages table",
              "Pagination logic using OFFSET/LIMIT or cursor-based pagination",
              "Integration with CentralContextStore.search() for message retrieval",
              "Query optimization with proper indexes on conversation_id and created_at",
              "Message serialization with type-specific formatting",
              "Aggregate query for total message count",
              "Caching layer for frequently accessed conversations (Redis optional)"
            ],
            "middleware": [
              "Authentication middleware to verify user session/token",
              "Authorization middleware to verify user owns conversation",
              "Query parameter validation for pagination (limit max 100)",
              "Response compression for large message payloads",
              "Cache headers for client-side caching (ETag support)",
              "Rate limiting to prevent excessive conversation queries"
            ],
            "shared": [
              "ConversationDetailResponse model with metadata and messages array",
              "MessageResponse model with id, type, content, timestamp, metadata",
              "PaginationMetadata model with total, offset, limit, has_more",
              "MessageType enum (user, assistant, system, error)",
              "QueryParameters model for pagination and filtering",
              "Database indexes on (conversation_id, created_at) for performance"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationController.getConversation",
          "related_concepts": [
            "REST API design",
            "pagination strategies",
            "lazy loading",
            "context window retrieval",
            "message ordering",
            "authorization checks",
            "query optimization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_022.3",
          "description": "Update conversation metadata endpoint that allows modification of title, description, and status without affecting message history",
          "type": "sub_process",
          "parent_id": "REQ_022",
          "children": [],
          "acceptance_criteria": [
            "PATCH /api/conversations/{id} endpoint accepts partial updates",
            "Endpoint allows updating title, description, and status fields",
            "Endpoint validates that at least one field is provided for update",
            "Updated_at timestamp is automatically refreshed on successful update",
            "Endpoint returns 200 OK with updated conversation object",
            "Endpoint returns 400 Bad Request for invalid field values",
            "Endpoint returns 404 Not Found if conversation doesn't exist",
            "Endpoint returns 401 Unauthorized if user is not authenticated",
            "Endpoint returns 403 Forbidden if user doesn't own the conversation",
            "Title length validation enforced (1-255 characters)",
            "Status can only transition to valid states (active, archived, deleted)",
            "Database update is atomic with transaction support",
            "Audit log entry records what fields were changed and by whom",
            "Endpoint supports optimistic locking with version field",
            "Integration test verifies update workflow and validation",
            "Unit tests cover partial updates and conflict scenarios"
          ],
          "implementation": {
            "frontend": [
              "ConversationSettingsModal component with editable fields",
              "Inline editing for conversation title in header",
              "Form validation with real-time feedback",
              "Save/Cancel buttons with confirmation on unsaved changes",
              "Loading state during update request",
              "Success notification on successful update",
              "Error handling UI with specific field-level errors",
              "Optimistic UI update with rollback on failure",
              "Archive/Restore conversation button with confirmation dialog"
            ],
            "backend": [
              "PATCH /api/conversations/{id} endpoint handler in FastAPI",
              "ConversationService.update_conversation() method with partial update logic",
              "Database UPDATE query with WHERE clause on id and user_id",
              "Validation of allowed field updates (title, description, status)",
              "Timestamp refresh for updated_at field",
              "Optimistic locking check using version field",
              "Audit log creation with change tracking",
              "Transaction management with rollback on failure",
              "Cache invalidation for updated conversation"
            ],
            "middleware": [
              "Authentication middleware to verify user session/token",
              "Authorization middleware to verify user owns conversation",
              "Request body validation using Pydantic models with partial updates",
              "Content-Type validation (application/json required)",
              "Idempotency key support for safe retries",
              "Rate limiting to prevent excessive update requests"
            ],
            "shared": [
              "ConversationUpdateRequest model with optional title, description, status, version",
              "ConversationResponse model with updated fields",
              "ConversationStatus enum with allowed transitions",
              "ValidationError types for field-specific errors",
              "AuditLogEntry model for change tracking",
              "Database migration for version field (optimistic locking)"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationController.updateConversation",
          "related_concepts": [
            "REST API design",
            "partial updates",
            "PATCH vs PUT semantics",
            "optimistic locking",
            "audit trails",
            "validation rules",
            "idempotency"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_022.4",
          "description": "Delete conversation endpoint that supports both soft delete (archive) and hard delete with cascading message deletion",
          "type": "sub_process",
          "parent_id": "REQ_022",
          "children": [],
          "acceptance_criteria": [
            "DELETE /api/conversations/{id} endpoint supports query parameter for hard delete",
            "Default behavior is soft delete (sets status to 'deleted', preserves data)",
            "Query parameter ?hard=true triggers hard delete with cascade",
            "Soft delete updates status field and sets deleted_at timestamp",
            "Hard delete removes conversation and all associated messages from database",
            "Hard delete removes all conversation entries from Context Window Array",
            "Endpoint returns 204 No Content on successful deletion",
            "Endpoint returns 404 Not Found if conversation doesn't exist",
            "Endpoint returns 401 Unauthorized if user is not authenticated",
            "Endpoint returns 403 Forbidden if user doesn't own the conversation",
            "Soft deleted conversations can be restored within 30 days",
            "Audit log entry records deletion event with user and timestamp",
            "Database transaction ensures atomic deletion of conversation and messages",
            "Background job permanently deletes soft-deleted conversations after 30 days",
            "Integration test verifies both soft and hard delete workflows",
            "Unit tests cover authorization and cascade deletion logic"
          ],
          "implementation": {
            "frontend": [
              "Delete conversation button in conversation settings",
              "Confirmation dialog with warning about data loss",
              "Toggle option for permanent deletion (hard delete)",
              "Loading state during deletion request",
              "Success notification with undo option (soft delete only)",
              "Error handling UI for failed deletion",
              "Remove conversation from sidebar immediately on success",
              "Undo notification banner for 10 seconds after soft delete",
              "Redirect to conversations list after deletion"
            ],
            "backend": [
              "DELETE /api/conversations/{id} endpoint handler in FastAPI",
              "Query parameter parsing for hard delete flag",
              "ConversationService.soft_delete() method for status update",
              "ConversationService.hard_delete() method for cascading deletion",
              "Database UPDATE for soft delete (status = deleted, deleted_at = now)",
              "Database DELETE with CASCADE for hard delete",
              "CentralContextStore.delete_all_by_conversation() for context cleanup",
              "Audit log creation for deletion event",
              "Background task scheduling for permanent deletion (Celery/RQ)",
              "Transaction management with rollback on failure"
            ],
            "middleware": [
              "Authentication middleware to verify user session/token",
              "Authorization middleware to verify user owns conversation",
              "Query parameter validation for hard delete flag",
              "Rate limiting to prevent deletion spam",
              "Additional confirmation required for hard delete (require confirmation token)",
              "GDPR compliance check for hard delete eligibility"
            ],
            "shared": [
              "ConversationDeleteRequest model with hard delete flag",
              "ConversationStatus enum including 'deleted' state",
              "AuditLogEntry model with deletion metadata",
              "Database schema with deleted_at nullable timestamp field",
              "Database CASCADE constraint for hard delete on messages table",
              "Constants for soft delete retention period (30 days)",
              "Background task definition for permanent deletion job"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationController.deleteConversation",
          "related_concepts": [
            "REST API design",
            "soft delete patterns",
            "hard delete with cascade",
            "data retention policies",
            "authorization checks",
            "undo functionality",
            "GDPR compliance"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_023",
      "description": "The system must implement a collapsible sidebar for navigation",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_023.1",
          "description": "Create a toggle button that controls the sidebar's collapsed/expanded state with visual feedback and accessibility support",
          "type": "sub_process",
          "parent_id": "REQ_023",
          "children": [],
          "acceptance_criteria": [
            "Toggle button must be visible in both collapsed and expanded states",
            "Button must have clear visual indicator (icon) showing current state (e.g., chevron left when expanded, chevron right when collapsed)",
            "Button must include proper ARIA labels (aria-label='Collapse sidebar' or 'Expand sidebar')",
            "Button must be keyboard accessible (Space and Enter keys trigger toggle)",
            "Button must have focus styles that meet WCAG 2.1 Level AA contrast requirements",
            "Button click must trigger state change within 16ms for responsive feel",
            "Button must have hover state with visual feedback",
            "Button position must remain fixed relative to sidebar (e.g., top-right corner or dedicated toggle area)"
          ],
          "implementation": {
            "frontend": [
              "Svelte component: ToggleButton.svelte with props: isCollapsed, onToggle, ariaLabel",
              "Icon component integration (chevron-left, chevron-right, or hamburger menu icons)",
              "CSS transitions for button rotation/transformation on state change",
              "Focus trap management when sidebar is expanded on mobile",
              "Touch event handlers for mobile tap gestures (minimum 44x44px touch target)",
              "Keyboard event listeners (Space, Enter keys) on button element",
              "Visual state indicators (active, hover, focus, disabled states)"
            ],
            "backend": [
              "No backend API endpoints required for toggle button functionality",
              "Sidebar state is client-side only at this stage"
            ],
            "middleware": [
              "No middleware required for toggle button functionality"
            ],
            "shared": [
              "TypeScript interface: SidebarToggleProps { isCollapsed: boolean; onToggle: () => void; ariaLabel?: string; }",
              "Constants file: SIDEBAR_TOGGLE_ANIMATION_DURATION = 300ms",
              "Icon library imports (lucide-svelte, svelte-icons, or custom SVG icons)"
            ]
          },
          "testable_properties": [],
          "function_id": "Sidebar.toggleCollapse",
          "related_concepts": [
            "user interaction",
            "accessibility",
            "button component",
            "state management",
            "keyboard navigation",
            "ARIA attributes"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_023.2",
          "description": "Implement smooth CSS/JavaScript animations for sidebar collapse and expand transitions with proper timing and easing functions",
          "type": "sub_process",
          "parent_id": "REQ_023",
          "children": [],
          "acceptance_criteria": [
            "Sidebar width must animate smoothly from expanded width (e.g., 280px) to collapsed width (e.g., 60px) over 300ms",
            "Animation must use CSS transform or width properties with cubic-bezier easing (e.g., cubic-bezier(0.4, 0, 0.2, 1))",
            "Sidebar content must fade out during collapse and fade in during expand using opacity transitions",
            "Animation must respect user's prefers-reduced-motion media query setting",
            "No layout thrashing or forced reflows during animation (use transform: translateX instead of width when possible)",
            "Animation must maintain 60fps performance on devices with GPU acceleration",
            "Text and icons inside sidebar must hide/show appropriately during transition (no text overflow or clipping)",
            "Animation must complete before allowing subsequent toggle actions (debounce rapid clicks)"
          ],
          "implementation": {
            "frontend": [
              "Svelte component: Sidebar.svelte with reactive $: style statements for dynamic width",
              "CSS classes: .sidebar-expanded, .sidebar-collapsed with transition properties",
              "CSS transitions: transition: width 300ms cubic-bezier(0.4, 0, 0.2, 1), opacity 200ms ease-in-out",
              "JavaScript animation coordination: use Svelte's transition:slide or custom transition directives",
              "Media query detector for prefers-reduced-motion to disable/reduce animations",
              "Debounce function to prevent animation queueing from rapid toggle clicks",
              "Conditional rendering logic for sidebar content based on collapsed state",
              "Overflow handling: overflow: hidden during transition, overflow: auto when expanded"
            ],
            "backend": [
              "No backend API required for animation functionality"
            ],
            "middleware": [
              "No middleware required for animation functionality"
            ],
            "shared": [
              "Constants: SIDEBAR_EXPANDED_WIDTH = 280, SIDEBAR_COLLAPSED_WIDTH = 60 (in pixels)",
              "Constants: ANIMATION_DURATION_MS = 300, ANIMATION_EASING = 'cubic-bezier(0.4, 0, 0.2, 1)'",
              "Utility function: getReducedMotionPreference() => boolean",
              "Utility function: debounce(callback: Function, delay: number) for toggle debouncing",
              "TypeScript type: SidebarAnimationConfig { duration: number; easing: string; reducedMotion: boolean; }"
            ]
          },
          "testable_properties": [],
          "function_id": "Sidebar.animateTransition",
          "related_concepts": [
            "CSS transitions",
            "animation performance",
            "requestAnimationFrame",
            "transform properties",
            "GPU acceleration",
            "reduced motion preference"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_023.3",
          "description": "Persist sidebar collapsed/expanded state to browser localStorage and restore on page load/refresh for consistent user experience",
          "type": "sub_process",
          "parent_id": "REQ_023",
          "children": [],
          "acceptance_criteria": [
            "Sidebar state must be saved to localStorage immediately after toggle action (within 50ms)",
            "LocalStorage key must be namespaced to avoid conflicts (e.g., 'writingAgent.sidebar.collapsed')",
            "State must be stored as boolean value (true for collapsed, false for expanded)",
            "State must be retrieved on component mount/initialization before first render to prevent flash of wrong state",
            "Fallback to default state (expanded) if localStorage is unavailable or disabled",
            "State must persist across browser sessions and page refreshes",
            "Error handling for localStorage quota exceeded or SecurityError (private browsing)",
            "State must be user-specific if authentication is implemented (include user ID in key)"
          ],
          "implementation": {
            "frontend": [
              "Svelte store: writable store in sidebar.store.ts to manage sidebar state",
              "onMount lifecycle hook to read localStorage on component initialization",
              "Reactive statement to watch sidebar state changes and trigger localStorage save",
              "Error boundary/try-catch for localStorage operations (quota, security errors)",
              "SSR compatibility check (localStorage only available in browser, not during SSR)",
              "State initialization logic: const initialState = getSavedSidebarState() ?? false"
            ],
            "backend": [
              "Optional: API endpoint POST /api/user/preferences to save sidebar state server-side for cross-device sync",
              "Optional: GET /api/user/preferences to retrieve saved preferences on login",
              "Optional: Database schema extension: user_preferences table with sidebar_collapsed column"
            ],
            "middleware": [
              "Optional: Authentication middleware to associate preferences with user accounts",
              "Optional: Request validation middleware for preference update requests"
            ],
            "shared": [
              "Constants: STORAGE_KEYS = { SIDEBAR_COLLAPSED: 'writingAgent.sidebar.collapsed' }",
              "Utility function: saveToLocalStorage<T>(key: string, value: T): void with error handling",
              "Utility function: loadFromLocalStorage<T>(key: string, defaultValue: T): T with error handling",
              "Utility function: isLocalStorageAvailable(): boolean for feature detection",
              "TypeScript interface: UserPreferences { sidebarCollapsed: boolean; theme?: string; otherPrefs?: object; }"
            ]
          },
          "testable_properties": [],
          "function_id": "LocalStorage.saveSidebarState",
          "related_concepts": [
            "browser storage",
            "state persistence",
            "user preferences",
            "localStorage API",
            "state hydration",
            "session management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_023.4",
          "description": "Dynamically adjust main content area width and positioning in response to sidebar state changes to maintain responsive layout",
          "type": "sub_process",
          "parent_id": "REQ_023",
          "children": [],
          "acceptance_criteria": [
            "Main content area width must automatically adjust when sidebar collapses/expands",
            "Main content must occupy remaining viewport width after accounting for sidebar width",
            "Layout calculation must use CSS Grid or Flexbox for automatic reflow (avoid manual JS calculations)",
            "Main content must not shift horizontally during sidebar animation (smooth transition)",
            "Layout must remain responsive across different viewport sizes (mobile, tablet, desktop)",
            "On mobile (<768px), sidebar should overlay content rather than pushing it (different behavior)",
            "Main content padding/margins must adjust to maintain consistent visual spacing",
            "No horizontal scrollbar should appear during sidebar transitions"
          ],
          "implementation": {
            "frontend": [
              "Svelte component: AppLayout.svelte as parent container with CSS Grid layout",
              "CSS Grid template: grid-template-columns: {sidebarWidth}px 1fr for automatic content sizing",
              "Reactive CSS custom properties: --sidebar-width bound to Svelte variable",
              "Media queries for responsive behavior: @media (max-width: 768px) for mobile overlay mode",
              "Main content component: MainContent.svelte with dynamic margin-left or grid positioning",
              "CSS transitions for main content repositioning synchronized with sidebar animation",
              "Mobile overlay logic: position: fixed for sidebar on small screens with backdrop",
              "Z-index management to ensure proper layering (sidebar overlay, backdrop, main content)"
            ],
            "backend": [
              "No backend API required for layout adjustment"
            ],
            "middleware": [
              "No middleware required for layout adjustment"
            ],
            "shared": [
              "Constants: BREAKPOINTS = { mobile: 768, tablet: 1024, desktop: 1280 } (in pixels)",
              "Constants: MOBILE_SIDEBAR_BEHAVIOR = 'overlay', DESKTOP_SIDEBAR_BEHAVIOR = 'push'",
              "Utility function: getCurrentBreakpoint(width: number): 'mobile' | 'tablet' | 'desktop'",
              "CSS custom properties: --sidebar-width, --content-max-width, --app-padding",
              "TypeScript type: LayoutMode = 'overlay' | 'push' for sidebar behavior modes"
            ]
          },
          "testable_properties": [],
          "function_id": "MainContent.adjustWidth",
          "related_concepts": [
            "responsive layout",
            "CSS Grid",
            "Flexbox",
            "dynamic sizing",
            "layout reflow",
            "viewport calculations"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_023.5",
          "description": "Initialize sidebar component with proper state management, event listeners, and integration with the conversation UI context",
          "type": "sub_process",
          "parent_id": "REQ_023",
          "children": [],
          "acceptance_criteria": [
            "Sidebar must initialize with correct state from localStorage or default value on mount",
            "Component must register all event listeners (click, keyboard, resize) during initialization",
            "Component must clean up event listeners and subscriptions on unmount to prevent memory leaks",
            "Sidebar must integrate with application store/context to share state with other components",
            "Component must handle edge cases: rapid mounting/unmounting, SSR hydration mismatch",
            "Initial render must not show flash of incorrect state (FOUC - Flash of Unstyled Content)",
            "Component must be fully accessible from keyboard navigation on first load",
            "Sidebar must contain navigation items for projects and conversations as per requirements"
          ],
          "implementation": {
            "frontend": [
              "Svelte component: Sidebar.svelte with onMount and onDestroy lifecycle hooks",
              "Svelte store subscription: const unsubscribe = sidebarStore.subscribe(value => ...)",
              "Event listener setup in onMount: window.addEventListener('resize', handleResize)",
              "Cleanup logic in onDestroy: unsubscribe(); window.removeEventListener('resize', handleResize)",
              "Context integration: setContext('sidebar', { collapsed, toggle }) for child components",
              "SSR-safe initialization: check typeof window !== 'undefined' before browser APIs",
              "Child components: ProjectList.svelte, ConversationList.svelte rendered inside sidebar",
              "Navigation structure: <nav> element with proper semantic HTML and ARIA landmarks"
            ],
            "backend": [
              "API endpoint: GET /api/projects to fetch project list for sidebar",
              "API endpoint: GET /api/conversations?project_id={id} to fetch conversations",
              "Response format: { projects: Project[], conversations: Conversation[] }"
            ],
            "middleware": [
              "Authentication middleware to verify user access to projects and conversations",
              "CORS middleware if frontend and backend are on different domains"
            ],
            "shared": [
              "TypeScript interface: Project { id: string; name: string; icon?: string; updatedAt: Date; }",
              "TypeScript interface: Conversation { id: string; projectId: string; title: string; lastMessage: string; updatedAt: Date; }",
              "TypeScript interface: SidebarContext { collapsed: Readable<boolean>; toggle: () => void; }",
              "Store definition: sidebar.store.ts with writable store and custom methods",
              "Utility function: initializeSidebarState(): { collapsed: boolean; projects: Project[]; conversations: Conversation[]; }"
            ]
          },
          "testable_properties": [],
          "function_id": "Sidebar.initializeComponent",
          "related_concepts": [
            "component lifecycle",
            "event handling",
            "context API",
            "initialization",
            "cleanup",
            "memory management"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_024",
      "description": "The system must display project folders with hierarchical organization",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_024.1",
          "description": "Render hierarchical folder tree structure with visual indicators showing nesting levels, folder icons, and project names",
          "type": "sub_process",
          "parent_id": "REQ_024",
          "children": [],
          "acceptance_criteria": [
            "Folder tree displays all project folders in a hierarchical structure with correct parent-child relationships",
            "Visual indentation shows nesting levels (e.g., 16px per level)",
            "Folder icons appear before folder names to indicate folder type",
            "Root-level folders are clearly distinguished from nested folders",
            "Empty folders display an appropriate indicator (e.g., empty folder icon or placeholder text)",
            "Tree structure matches the data model's folder hierarchy exactly",
            "Performance remains smooth with 1000+ folders using virtualization or pagination",
            "Tree updates reactively when folder data changes"
          ],
          "implementation": {
            "frontend": [
              "Svelte component FolderTree.svelte with recursive child components",
              "FolderTreeItem.svelte component for individual folder rendering",
              "CSS styling for indentation, icons, and visual hierarchy",
              "Virtual scrolling library integration (e.g., svelte-virtual-list) for performance",
              "Reactive state management for folder data using Svelte stores",
              "Icon library integration (e.g., Lucide icons) for folder icons"
            ],
            "backend": [
              "GET /api/projects/folders endpoint returning hierarchical folder structure",
              "FolderService.getFolderHierarchy() method to query and structure folder data",
              "Recursive SQL query or ORM method to build folder tree with parent-child relationships",
              "Folder depth calculation and validation (e.g., max depth of 10 levels)",
              "Caching strategy for frequently accessed folder structures"
            ],
            "middleware": [
              "Authentication middleware to verify user has access to view projects",
              "Authorization check to filter folders based on user permissions",
              "Response pagination middleware for large folder trees",
              "Rate limiting on folder tree endpoint to prevent abuse"
            ],
            "shared": [
              "FolderNode interface/type with id, name, parentId, children, depth properties",
              "ProjectFolder data model with relationships to projects and parent folders",
              "TreeBuilder utility class to convert flat folder list to hierarchical structure",
              "FolderPath utility to generate breadcrumb paths from folder hierarchy"
            ]
          },
          "testable_properties": [],
          "function_id": "FolderTreeComponent.renderFolderStructure",
          "related_concepts": [
            "tree data structure",
            "recursive rendering",
            "virtual scrolling",
            "folder hierarchy",
            "project organization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_024.2",
          "description": "Support folder expansion and collapse interactions with state persistence and smooth animations",
          "type": "sub_process",
          "parent_id": "REQ_024",
          "children": [],
          "acceptance_criteria": [
            "Clicking a folder toggle (e.g., chevron icon) expands or collapses the folder",
            "Expanded folders display all immediate children folders",
            "Collapsed folders hide all descendant folders",
            "Expansion state persists across page refreshes using local storage or user preferences",
            "Visual indicator (e.g., chevron/arrow) shows current expansion state (right=collapsed, down=expanded)",
            "Smooth CSS transition animations occur during expansion/collapse (200-300ms duration)",
            "Keyboard navigation supports expansion/collapse (e.g., arrow keys, Enter key)",
            "Expansion state is tracked per folder, not globally",
            "Lazy loading of folder contents occurs only when folder is expanded for the first time",
            "Expanding parent folder does not auto-expand child folders unless explicitly requested"
          ],
          "implementation": {
            "frontend": [
              "Svelte writable store for tracking expanded folder IDs (Set<string>)",
              "Click handler on folder toggle button to update expansion state",
              "Keyboard event handlers for accessibility (ArrowRight, ArrowLeft, Enter)",
              "CSS transitions for smooth expand/collapse animations",
              "Local storage utility to persist/restore expansion state",
              "Toggle icon component that rotates based on expansion state",
              "Focus management to maintain keyboard navigation context"
            ],
            "backend": [
              "GET /api/projects/folders/:folderId/children endpoint for lazy loading children",
              "FolderService.getFolderChildren(folderId) method to retrieve immediate children",
              "Optional user preference storage for expansion state (if persisting server-side)",
              "PUT /api/users/preferences endpoint to save folder expansion preferences"
            ],
            "middleware": [
              "Authentication middleware for folder children endpoint",
              "Authorization check to verify user can access specific folder children",
              "Response caching for frequently accessed folder children"
            ],
            "shared": [
              "ExpansionState type defining structure for tracking expanded folders",
              "LocalStorageService utility for persisting expansion state client-side",
              "FolderExpansionPreference model if storing preferences server-side",
              "TreeStateManager utility class to manage expansion/collapse operations"
            ]
          },
          "testable_properties": [],
          "function_id": "FolderTreeComponent.handleExpansionCollapse",
          "related_concepts": [
            "UI state management",
            "tree traversal",
            "local storage",
            "user preferences",
            "animation transitions"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_024.3",
          "description": "Display relevant project metadata for each folder including item counts, last modified date, and project status indicators",
          "type": "sub_process",
          "parent_id": "REQ_024",
          "children": [],
          "acceptance_criteria": [
            "Each folder displays the count of projects it contains (including nested projects)",
            "Last modified timestamp shows when folder or its contents were last updated",
            "Project status indicators display (e.g., active, archived, in progress) with appropriate icons/colors",
            "Conversation count badge shows number of conversations within folder",
            "Tooltips provide additional metadata on hover (e.g., created date, folder owner, description)",
            "Metadata updates in real-time when folder contents change",
            "Visual distinction between folders with content vs empty folders",
            "Metadata displays in a compact, non-intrusive format",
            "Loading states show when metadata is being fetched",
            "Metadata respects user's locale for date/time formatting"
          ],
          "implementation": {
            "frontend": [
              "FolderMetadata.svelte component to display metadata badges and information",
              "Tooltip component for detailed metadata on hover",
              "Badge components for counts (projects, conversations) with distinct styling",
              "Status indicator component with icon and color coding",
              "Date formatting utility respecting user locale",
              "Real-time update subscription using WebSocket or polling",
              "Loading skeleton UI for metadata fetch states"
            ],
            "backend": [
              "GET /api/projects/folders/:folderId/metadata endpoint returning aggregated metadata",
              "FolderService.getFolderMetadata(folderId) method to aggregate counts and stats",
              "SQL aggregation queries to count projects, conversations per folder",
              "Recursive query to count nested items across folder hierarchy",
              "Last modified calculation based on max(folder.updated_at, max(projects.updated_at))",
              "WebSocket event emission when folder metadata changes",
              "Caching layer for expensive metadata aggregation queries"
            ],
            "middleware": [
              "Authentication middleware for metadata endpoint",
              "Authorization to ensure user can view folder metadata",
              "Response compression for metadata payloads",
              "Cache-Control headers for appropriate caching strategy"
            ],
            "shared": [
              "FolderMetadata interface with projectCount, conversationCount, lastModified, status properties",
              "ProjectStatus enum defining possible project states",
              "MetadataAggregator utility to calculate folder statistics",
              "DateFormatter utility for consistent date/time display",
              "MetadataCache model for storing computed aggregations"
            ]
          },
          "testable_properties": [],
          "function_id": "FolderMetadataDisplay.showProjectMetadata",
          "related_concepts": [
            "metadata display",
            "aggregation",
            "real-time updates",
            "visual badges",
            "tooltip information"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_024.4",
          "description": "Enable folder selection with single-select or multi-select capabilities, visual feedback, and selection state management",
          "type": "sub_process",
          "parent_id": "REQ_024",
          "children": [],
          "acceptance_criteria": [
            "Clicking a folder selects it and highlights it visually (e.g., background color change)",
            "Single-select mode allows only one folder to be selected at a time",
            "Multi-select mode supports Ctrl/Cmd+click for multiple selections and Shift+click for range selection",
            "Selected folder state updates application context (e.g., displays folder contents in center panel)",
            "Visual feedback clearly indicates selected vs unselected folders",
            "Keyboard navigation allows selection using Enter/Space keys",
            "Selection state persists when navigating away and returning to folder tree",
            "Right-click on selected folder(s) opens context menu with folder operations",
            "Selection count displays when multiple folders selected",
            "Deselection occurs when clicking empty space or pressing Escape key"
          ],
          "implementation": {
            "frontend": [
              "Svelte writable store for tracking selected folder IDs (Set<string> for multi-select)",
              "Click handler with modifier key detection (Ctrl, Shift) for selection logic",
              "CSS classes for selected, hover, and focus states",
              "Keyboard event handlers for selection (Enter, Space, Arrow keys, Escape)",
              "ContextMenu.svelte component triggered on right-click of selected folders",
              "SelectionIndicator component showing count of selected folders",
              "Focus trap and ARIA attributes for accessibility",
              "Selection state persistence using session storage or URL state"
            ],
            "backend": [
              "GET /api/projects/folders/:folderId endpoint to fetch selected folder details",
              "POST /api/projects/folders/bulk-actions endpoint for operations on multiple folders",
              "FolderService.getFolderDetails(folderId) method",
              "FolderService.performBulkAction(folderIds, action) for multi-folder operations"
            ],
            "middleware": [
              "Authentication middleware for folder access endpoints",
              "Authorization validation for bulk folder operations",
              "Request validation to ensure folder IDs exist and user has permissions",
              "Rate limiting on bulk operation endpoints"
            ],
            "shared": [
              "SelectionState interface defining selected folder IDs and selection mode",
              "SelectionMode enum (SINGLE, MULTI)",
              "FolderOperationRequest model for bulk action payloads",
              "SelectionManager utility class handling selection logic (range calculation, modifier keys)",
              "FolderActionType enum defining available operations (move, delete, archive, etc.)"
            ]
          },
          "testable_properties": [],
          "function_id": "FolderSelectionManager.handleFolderSelection",
          "related_concepts": [
            "selection state",
            "keyboard navigation",
            "accessibility",
            "context menus",
            "bulk operations"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_025",
      "description": "The system must support drag-and-drop file uploads",
      "type": "parent",
      "parent_id": null,
      "children": [],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_026",
      "description": "The system must display audio recording controls with start/stop functionality",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_026.1",
          "description": "Display a clearly visible record button that initiates audio capture when clicked, with appropriate visual styling and accessibility attributes",
          "type": "sub_process",
          "parent_id": "REQ_026",
          "children": [],
          "acceptance_criteria": [
            "Record button is visible and clearly labeled (text or icon with tooltip)",
            "Button displays microphone icon or 'Record' text",
            "Button is disabled until microphone permissions are granted",
            "Button shows hover state to indicate interactivity",
            "Button has proper ARIA labels for screen readers (aria-label='Start recording')",
            "Clicking the button requests microphone access if not already granted",
            "Button triggers recording start when clicked and permissions are available",
            "Button state changes to 'recording' visual state after successful start",
            "Button is keyboard accessible (can be triggered with Enter/Space)",
            "Error message displays if microphone access is denied"
          ],
          "implementation": {
            "frontend": [
              "RecordButton component with icon/text",
              "Button state management (idle/requesting-permission/recording/error)",
              "Click handler to initiate recording",
              "Microphone permission request UI",
              "Visual feedback for different button states (colors, icons)",
              "Tooltip or label explaining button function",
              "Error toast/modal for permission denial",
              "Responsive styling for mobile and desktop"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "RecordingState enum (IDLE, REQUESTING_PERMISSION, RECORDING, PAUSED, ERROR)",
              "AudioPermissionStatus type",
              "Button variant types"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.showRecordButton",
          "related_concepts": [
            "MediaRecorder API",
            "user permissions",
            "microphone access",
            "button states",
            "accessibility (ARIA labels)",
            "responsive design"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_026.2",
          "description": "Show real-time visual indicators that inform users recording is actively in progress, including animated elements and status text",
          "type": "sub_process",
          "parent_id": "REQ_026",
          "children": [],
          "acceptance_criteria": [
            "Recording indicator appears immediately when recording starts",
            "Indicator includes animated element (pulsing dot, waveform, or circular progress)",
            "Status text displays 'Recording...' or equivalent message",
            "Indicator uses red color to signify active recording (industry standard)",
            "Animation runs continuously while recording is active",
            "Indicator is prominent and cannot be missed by user",
            "Indicator disappears immediately when recording stops",
            "Optional: Visual audio level meter shows input volume in real-time",
            "Indicator is visible on all screen sizes",
            "Status persists if user scrolls or performs other actions"
          ],
          "implementation": {
            "frontend": [
              "RecordingStatusIndicator component with animation",
              "CSS animations (pulsing effect, rotation, or waveform)",
              "Status text component showing 'Recording...'",
              "Red dot or circle with pulse animation",
              "Optional: Audio visualizer using Web Audio API (AnalyserNode)",
              "Conditional rendering based on recording state",
              "Fixed or sticky positioning to keep visible",
              "Z-index management to stay on top"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "RecordingState enum",
              "Animation keyframe definitions",
              "Color constants (RECORDING_RED, etc.)"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.displayRecordingStatusIndicator",
          "related_concepts": [
            "visual feedback",
            "animation",
            "recording state management",
            "user awareness",
            "audio waveform visualization",
            "pulsing indicators"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_026.3",
          "description": "Provide a stop button that terminates the active recording session, finalizes the audio data, and transitions the UI back to idle state",
          "type": "sub_process",
          "parent_id": "REQ_026",
          "children": [],
          "acceptance_criteria": [
            "Stop button appears only when recording is active",
            "Button is clearly labeled 'Stop' or shows a stop icon (square)",
            "Clicking stop button immediately halts audio capture",
            "MediaRecorder.stop() is called to finalize recording",
            "Audio chunks are combined into a single Blob",
            "Recording state transitions from RECORDING to STOPPED/IDLE",
            "Timer stops updating when recording stops",
            "Microphone access indicator (browser-level) disappears",
            "MediaStream tracks are stopped to release microphone",
            "Recorded audio Blob is prepared for preview or upload",
            "Stop button changes back to record button after stopping",
            "User receives confirmation that recording stopped successfully",
            "Any ongoing audio processing completes gracefully"
          ],
          "implementation": {
            "frontend": [
              "StopButton component visible during recording",
              "Click handler to stop MediaRecorder",
              "State transition from RECORDING to STOPPED",
              "MediaStream track cleanup (track.stop())",
              "Audio Blob assembly from recorded chunks",
              "Button replacement (stop \u2192 record)",
              "Success notification/toast",
              "Optional: Audio preview player with playback controls"
            ],
            "backend": [
              "Endpoint to receive audio upload: POST /api/audio/upload",
              "Multipart form data handling for audio Blob",
              "Audio file storage (filesystem, S3, or database)",
              "Audio metadata extraction (duration, format, size)",
              "Return audio file ID or URL to frontend"
            ],
            "middleware": [
              "File upload size limit validation",
              "Audio MIME type validation (audio/webm, audio/wav, etc.)",
              "Authentication check to ensure user can upload",
              "Rate limiting for upload endpoint"
            ],
            "shared": [
              "AudioBlob type/interface with metadata",
              "RecordingState enum",
              "Audio file format constants (WEBM, WAV, MP3)",
              "Maximum recording duration constant",
              "Utility function to combine audio chunks into Blob"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.implementStopRecording",
          "related_concepts": [
            "MediaRecorder.stop()",
            "audio blob creation",
            "state cleanup",
            "resource release",
            "audio file finalization",
            "upload trigger"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_026.4",
          "description": "Display a running timer showing elapsed recording time in MM:SS format, updating in real-time during active recording",
          "type": "sub_process",
          "parent_id": "REQ_026",
          "children": [],
          "acceptance_criteria": [
            "Timer displays in MM:SS format (e.g., 00:00, 01:23, 10:45)",
            "Timer starts at 00:00 when recording begins",
            "Timer updates every second (1000ms interval)",
            "Timer continues counting while recording is active",
            "Timer stops immediately when recording stops",
            "Timer resets to 00:00 when starting a new recording",
            "Timer is clearly visible near recording controls",
            "Optional: Timer changes color when approaching maximum duration",
            "Optional: Recording auto-stops when maximum duration reached (e.g., 5 minutes)",
            "Timer uses monospace font for consistent digit width",
            "Timer includes leading zeros for single-digit minutes/seconds"
          ],
          "implementation": {
            "frontend": [
              "DurationTimer component displaying formatted time",
              "setInterval to update timer every 1000ms",
              "State variable tracking elapsed seconds",
              "Time formatting utility (seconds \u2192 MM:SS)",
              "Timer start logic triggered on recording start",
              "Timer stop logic triggered on recording stop",
              "Timer reset on new recording",
              "Cleanup of interval on component unmount",
              "Optional: Color change logic for time warnings",
              "Optional: Auto-stop logic at maximum duration",
              "Monospace font styling for timer display"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "formatDuration(seconds: number): string utility function",
              "MAX_RECORDING_DURATION_SECONDS constant",
              "RecordingState enum",
              "Timer interval type definitions"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.showAudioDurationTimer",
          "related_concepts": [
            "elapsed time tracking",
            "time formatting",
            "interval updates",
            "maximum duration enforcement",
            "timer reset",
            "performance optimization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_026.5",
          "description": "Set up MediaRecorder instance with appropriate audio constraints, event handlers, and browser compatibility checks before recording can begin",
          "type": "sub_process",
          "parent_id": "REQ_026",
          "children": [],
          "acceptance_criteria": [
            "Browser compatibility check for MediaRecorder API performed",
            "Fallback message shown if MediaRecorder not supported",
            "getUserMedia() called with audio constraints (echoCancellation, noiseSuppression)",
            "Microphone permission requested from user",
            "MediaRecorder initialized with MediaStream from getUserMedia",
            "Audio MIME type selected based on browser support (prefer audio/webm)",
            "ondataavailable event handler set to collect audio chunks",
            "onstop event handler set to finalize recording",
            "onerror event handler set to handle recording errors",
            "MediaRecorder state checked before operations",
            "Resources cleaned up properly on component unmount"
          ],
          "implementation": {
            "frontend": [
              "Browser API compatibility check (navigator.mediaDevices.getUserMedia)",
              "getUserMedia call with audio constraints object",
              "Permission request handling (granted/denied/prompt)",
              "MediaRecorder instantiation with MIME type options",
              "Event listener setup (dataavailable, stop, error, start)",
              "Audio chunks array to store recorded data",
              "Error boundary for MediaRecorder failures",
              "Cleanup function to stop tracks and clear listeners"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "AudioConstraints interface/type",
              "SUPPORTED_MIME_TYPES array",
              "getMimeType() utility to detect browser support",
              "MediaRecorderState enum",
              "AudioChunk type definition"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.initializeMediaRecorder",
          "related_concepts": [
            "MediaRecorder API",
            "getUserMedia",
            "audio constraints",
            "browser compatibility",
            "codec selection",
            "error handling",
            "permission management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_026.6",
          "description": "Manage the complete recording workflow from initialization through capture to completion, including state transitions, error recovery, and resource management",
          "type": "sub_process",
          "parent_id": "REQ_026",
          "children": [],
          "acceptance_criteria": [
            "State transitions follow valid path: IDLE \u2192 REQUESTING_PERMISSION \u2192 RECORDING \u2192 STOPPED \u2192 IDLE",
            "Invalid state transitions are prevented (e.g., can't start while already recording)",
            "Each state change triggers appropriate UI updates",
            "Errors at any stage transition to ERROR state with user notification",
            "Recording can be restarted after stopping",
            "Resources released properly when recording cancelled or errors occur",
            "User can cancel permission request and return to idle state",
            "Maximum recording duration enforced (auto-stop)",
            "Recorded audio preserved even if UI component remounts",
            "Loading states shown during asynchronous operations"
          ],
          "implementation": {
            "frontend": [
              "State machine implementation for recording lifecycle",
              "State transition validation logic",
              "UI component rendering based on current state",
              "Error state handling with user-friendly messages",
              "Retry logic for failed permission requests",
              "Session ID generation for tracking recordings",
              "Local storage backup of recording state",
              "Loading spinner during permission request",
              "Confirmation dialog before discarding recording"
            ],
            "backend": [
              "Session management endpoint: POST /api/recording-sessions",
              "Session status tracking endpoint: GET /api/recording-sessions/:id",
              "Session cleanup endpoint: DELETE /api/recording-sessions/:id"
            ],
            "middleware": [
              "Session authentication and ownership verification",
              "Rate limiting on session creation"
            ],
            "shared": [
              "RecordingLifecycleState enum with all states",
              "StateTransition validation rules",
              "RecordingSession interface with metadata",
              "Error types for different failure scenarios",
              "generateSessionId() utility function"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.handleRecordingLifecycle",
          "related_concepts": [
            "state machine",
            "lifecycle management",
            "error recovery",
            "resource cleanup",
            "user feedback",
            "recording sessions"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_027",
      "description": "The system must render message components with sender identification",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_027.1",
          "description": "Display user messages with proper styling, avatar, and sender identification in the conversation UI",
          "type": "sub_process",
          "parent_id": "REQ_027",
          "children": [],
          "acceptance_criteria": [
            "User messages are displayed with right-aligned layout",
            "User messages show a distinct visual identifier (avatar or icon)",
            "User messages have a different background color than assistant messages",
            "Sender name or label 'You' is clearly visible",
            "User message bubbles have appropriate padding and border radius",
            "User messages support multi-line text with proper word wrapping",
            "User avatar or identifier appears consistently for all user messages"
          ],
          "implementation": {
            "frontend": [
              "MessageComponent.svelte with conditional rendering for user vs assistant",
              "UserMessage sub-component for user-specific styling",
              "Avatar component for user identification",
              "CSS classes for right-aligned message layout",
              "Flexbox or grid layout for message positioning",
              "User message bubble with distinct background color",
              "Sender label component displaying 'You' or username"
            ],
            "backend": [
              "Message data model includes 'sender' or 'role' field",
              "API returns message objects with sender identification",
              "User profile endpoint to fetch avatar URL if needed"
            ],
            "middleware": [
              "Message validation ensures sender field is present",
              "Authentication context to identify current user"
            ],
            "shared": [
              "Message interface/type with sender: 'user' | 'assistant' | 'system'",
              "User interface/type with id, name, avatar properties",
              "Message styling constants (colors, spacing, alignment)",
              "Utility function to determine if message is from current user"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageComponent.renderUserMessage",
          "related_concepts": [
            "message layout",
            "user avatar display",
            "message alignment",
            "sender label",
            "message bubble styling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_027.2",
          "description": "Display assistant messages with AI/bot identification, distinctive styling, and clear visual separation from user messages",
          "type": "sub_process",
          "parent_id": "REQ_027",
          "children": [],
          "acceptance_criteria": [
            "Assistant messages are displayed with left-aligned layout",
            "Assistant messages show a distinct AI/bot avatar or icon",
            "Assistant messages have a different background color than user messages",
            "Assistant label (e.g., 'Assistant', 'AI', or bot name) is clearly visible",
            "Assistant message bubbles have appropriate padding and border radius",
            "Assistant messages support markdown rendering for rich text content",
            "Assistant avatar or identifier appears consistently for all assistant messages",
            "Assistant messages are visually distinguishable at a glance"
          ],
          "implementation": {
            "frontend": [
              "AssistantMessage sub-component for assistant-specific styling",
              "Bot avatar component with AI icon or custom logo",
              "CSS classes for left-aligned message layout",
              "Markdown renderer integration for assistant message content",
              "Assistant message bubble with distinct background color (different from user)",
              "Sender label component displaying 'Assistant' or bot name",
              "Icon or visual indicator for AI/bot messages"
            ],
            "backend": [
              "Message API returns role='assistant' for AI responses",
              "Assistant configuration endpoint for bot name and avatar",
              "Message content is properly formatted for frontend rendering"
            ],
            "middleware": [
              "Message transformation to ensure assistant messages have correct role",
              "Content sanitization for markdown rendering"
            ],
            "shared": [
              "Message type definition with role: 'assistant'",
              "Assistant configuration interface with name, avatar, color scheme",
              "Styling constants for assistant messages (colors, spacing)",
              "Utility function to identify assistant messages"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageComponent.renderAssistantMessage",
          "related_concepts": [
            "AI avatar display",
            "assistant branding",
            "message differentiation",
            "bot identifier",
            "assistant message layout"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_027.3",
          "description": "Show message timestamps with relative or absolute time formatting for each message in the conversation",
          "type": "sub_process",
          "parent_id": "REQ_027",
          "children": [],
          "acceptance_criteria": [
            "Each message displays a timestamp indicating when it was sent",
            "Timestamps use relative format for recent messages (e.g., 'just now', '5 minutes ago')",
            "Timestamps use absolute format for older messages (e.g., 'Jan 9, 2026 1:30 PM')",
            "Timestamp transitions from relative to absolute after a configurable threshold (e.g., 24 hours)",
            "Timestamps are displayed in the user's local timezone",
            "Timestamps have subtle styling to avoid visual clutter",
            "Hovering over a relative timestamp shows the absolute time in a tooltip",
            "Timestamp format is consistent across all messages",
            "Timestamps update dynamically for relative times without page refresh"
          ],
          "implementation": {
            "frontend": [
              "Timestamp component with conditional formatting logic",
              "Relative time formatter using library (e.g., date-fns, dayjs)",
              "Absolute time formatter with locale support",
              "Tooltip component for showing absolute time on hover",
              "CSS styling for subtle timestamp appearance",
              "Auto-update mechanism for relative timestamps (setInterval or reactive store)",
              "Timestamp positioning below or beside message bubble"
            ],
            "backend": [
              "Message API returns timestamp in ISO 8601 format",
              "Server-side timestamp generation when message is created",
              "Timezone information included in API response if needed"
            ],
            "middleware": [
              "Timestamp validation to ensure proper format",
              "Timestamp normalization to UTC for storage"
            ],
            "shared": [
              "Message interface includes timestamp: Date | string field",
              "Time formatting utility functions (toRelativeTime, toAbsoluteTime)",
              "Constants for time thresholds (e.g., RELATIVE_TIME_THRESHOLD = 86400000)",
              "Locale configuration for time formatting",
              "Timezone utility functions for conversion"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageComponent.renderTimestamp",
          "related_concepts": [
            "time formatting",
            "relative timestamps",
            "absolute timestamps",
            "timezone handling",
            "timestamp positioning"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_027.4",
          "description": "Apply consistent and visually distinct styling to messages based on sender type, message state, and UI theme",
          "type": "sub_process",
          "parent_id": "REQ_027",
          "children": [],
          "acceptance_criteria": [
            "User messages have a distinct background color (e.g., blue or primary color)",
            "Assistant messages have a contrasting background color (e.g., gray or neutral)",
            "Message bubbles have rounded corners with consistent border radius",
            "Message text has sufficient contrast ratio (WCAG AA compliant) for readability",
            "Messages have appropriate padding and margins for visual spacing",
            "Pending/sending messages show a loading indicator or reduced opacity",
            "Error messages have a distinct error state styling (e.g., red border or icon)",
            "Messages adapt to dark mode with appropriate color adjustments",
            "Message styling is responsive and works on mobile and desktop viewports",
            "Animation or transition effects for message appearance are smooth",
            "System messages (if any) have a third distinct styling",
            "Message max-width is constrained for better readability on large screens"
          ],
          "implementation": {
            "frontend": [
              "CSS module or styled-components for message styling",
              "Theme provider integration for color scheme",
              "Conditional CSS classes based on message sender (user/assistant/system)",
              "State-based styling for pending, sent, error states",
              "Loading indicator component for pending messages",
              "Error icon or border for failed messages",
              "Dark mode styles with CSS variables or theme context",
              "Responsive CSS with media queries for different screen sizes",
              "CSS transitions for message appearance animations",
              "Max-width constraint with centered alignment for large screens"
            ],
            "backend": [
              "Message status field in API response (pending, sent, delivered, error)",
              "Error information for failed messages"
            ],
            "middleware": [
              "Message state management to track send status"
            ],
            "shared": [
              "Theme configuration with color palette (primary, secondary, neutral, error)",
              "Message state enum (PENDING, SENT, DELIVERED, ERROR)",
              "Styling constants (border radius, padding, max-width, spacing)",
              "Accessibility constants (minimum contrast ratios)",
              "Animation timing constants for transitions",
              "Utility function to get message styling class based on sender and state"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageComponent.applyMessageStyling",
          "related_concepts": [
            "theme system",
            "CSS styling",
            "message states",
            "visual hierarchy",
            "accessibility",
            "responsive design"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_028",
      "description": "The system must manage conversation state using Zustand or similar state management",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_028.1",
          "description": "Create a Zustand store to manage conversation state including messages, active conversation ID, loading states, and error handling",
          "type": "sub_process",
          "parent_id": "REQ_028",
          "children": [],
          "acceptance_criteria": [
            "Zustand store is created with TypeScript types for conversation state",
            "Store includes state properties: activeConversationId (string | null), conversations (Map or Record), messages (array), isLoading (boolean), error (string | null)",
            "Store includes actions: setActiveConversation, addMessage, updateMessage, deleteMessage, clearError",
            "Store is properly typed with TypeScript interfaces for all state and actions",
            "Store initialization includes sensible default values",
            "Store can be imported and used across components without prop drilling",
            "DevTools middleware is optionally enabled for debugging in development",
            "Store structure supports multiple conversations with unique IDs"
          ],
          "implementation": {
            "frontend": [
              "Create store file at src/lib/stores/conversationStore.ts",
              "Define TypeScript interfaces for Message, Conversation, and ConversationState",
              "Implement Zustand create function with typed state and actions",
              "Add DevTools middleware for development environment",
              "Export typed hooks for component consumption (useConversationStore)"
            ],
            "backend": [
              "No direct backend implementation needed for store creation",
              "Backend API endpoints will be consumed by store actions in subsequent steps"
            ],
            "middleware": [
              "No middleware requirements for store creation",
              "Store will call middleware-protected endpoints in action implementations"
            ],
            "shared": [
              "Define Message interface with id, content, role (user/assistant), timestamp, attachments",
              "Define Conversation interface with id, title, createdAt, updatedAt, messageIds",
              "Define ConversationState interface combining all store state properties",
              "Create utility types for store actions and selectors",
              "Define error types for conversation operations"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationStore.createStore",
          "related_concepts": [
            "State management",
            "Zustand store creation",
            "TypeScript type definitions",
            "Immutable state updates",
            "Store initialization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_028.2",
          "description": "Implement functionality to track which conversation is currently active, including setting, clearing, and switching between conversations",
          "type": "sub_process",
          "parent_id": "REQ_028",
          "children": [],
          "acceptance_criteria": [
            "setActiveConversation action updates activeConversationId in store",
            "Setting active conversation loads corresponding messages for that conversation",
            "Clearing active conversation (null) resets message list to empty array",
            "Switching conversations properly cleans up previous conversation state",
            "Active conversation change triggers any necessary API calls to load conversation data",
            "URL route reflects active conversation ID when conversation is selected",
            "Previous conversation state is preserved when switching between conversations",
            "Loading state is set appropriately during conversation switching",
            "Error state is cleared when successfully switching conversations"
          ],
          "implementation": {
            "frontend": [
              "Implement setActiveConversation(id: string | null) action in store",
              "Create clearActiveConversation() helper action",
              "Add conversation switching logic that saves current state before switching",
              "Implement useEffect hook in ConversationView component to react to active conversation changes",
              "Add loading indicator in UI during conversation switching",
              "Sync active conversation ID with URL parameters using SvelteKit navigation",
              "Display active conversation title in UI header"
            ],
            "backend": [
              "Create GET /api/conversations/:id endpoint to fetch conversation details",
              "Create GET /api/conversations/:id/messages endpoint to fetch messages for a conversation",
              "Implement pagination support for message loading",
              "Add response validation and error handling"
            ],
            "middleware": [
              "Add authentication check to verify user owns the conversation",
              "Implement rate limiting for conversation switching to prevent abuse",
              "Add request logging for conversation access"
            ],
            "shared": [
              "Define ConversationDetailResponse interface",
              "Define MessageListResponse interface with pagination metadata",
              "Create utility function to validate conversation ID format",
              "Define error codes for conversation not found, unauthorized access",
              "Create selector hook useActiveConversation() for components"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationStore.trackActiveConversation",
          "related_concepts": [
            "Active conversation selection",
            "Conversation switching",
            "State updates",
            "Side effects on conversation change",
            "URL synchronization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_028.3",
          "description": "Implement actions to update the message list including adding new messages, updating existing messages (for streaming responses), and handling optimistic updates",
          "type": "sub_process",
          "parent_id": "REQ_028",
          "children": [],
          "acceptance_criteria": [
            "addMessage action appends new message to messages array maintaining chronological order",
            "updateMessage action finds and updates specific message by ID without mutating state",
            "Messages are sorted by timestamp in ascending order",
            "Optimistic updates create temporary message with pending state before API confirmation",
            "Failed message sends are marked with error state and retry option",
            "Streaming messages can be updated incrementally as content arrives",
            "Message list supports infinite scroll or pagination for large conversations",
            "Duplicate messages are prevented using unique message IDs",
            "Message updates trigger minimal re-renders through proper state structure"
          ],
          "implementation": {
            "frontend": [
              "Implement addMessage(message: Message) action with immutable array append",
              "Implement updateMessage(id: string, updates: Partial<Message>) action using array map",
              "Create addOptimisticMessage() helper that generates temporary ID and pending state",
              "Implement confirmOptimisticMessage(tempId: string, confirmedMessage: Message) for API confirmation",
              "Add handleStreamingUpdate(messageId: string, contentChunk: string) for partial updates",
              "Create deleteMessage(id: string) action for message removal",
              "Implement message list virtualization for performance with large lists",
              "Add retry mechanism for failed message sends in UI"
            ],
            "backend": [
              "Create POST /api/conversations/:id/messages endpoint to send new messages",
              "Create PATCH /api/messages/:id endpoint for message updates (if needed)",
              "Implement DELETE /api/messages/:id endpoint for message deletion",
              "Add WebSocket or SSE endpoint for streaming message responses",
              "Return full message object with server-generated ID and timestamp in response",
              "Implement idempotency using client-generated request IDs"
            ],
            "middleware": [
              "Validate message content length and format",
              "Check user authorization to add messages to specific conversation",
              "Implement rate limiting for message sending",
              "Sanitize message content to prevent XSS attacks"
            ],
            "shared": [
              "Define MessageStatus enum (pending, sent, delivered, failed)",
              "Create utility function generateOptimisticId() for temporary message IDs",
              "Define MessageUpdate interface for partial message updates",
              "Create utility function sortMessagesByTimestamp(messages: Message[])",
              "Define StreamingChunk interface for incremental updates",
              "Create utility to merge streaming chunks into message content"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationStore.updateMessageList",
          "related_concepts": [
            "Message list management",
            "Optimistic UI updates",
            "Streaming message updates",
            "Message ordering",
            "Immutable array operations"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_028.4",
          "description": "Implement persistence layer to save conversation state to localStorage for offline access and state recovery across browser sessions",
          "type": "sub_process",
          "parent_id": "REQ_028",
          "children": [],
          "acceptance_criteria": [
            "Conversation state is automatically saved to localStorage on every state change",
            "State is properly serialized to JSON before storing",
            "State is deserialized and validated when loading from localStorage",
            "Store is hydrated with persisted state on application initialization",
            "Storage quota errors are caught and handled gracefully",
            "Sensitive information (if any) is excluded from persisted state",
            "Persisted state includes version number for migration support",
            "Stale persisted data (older than threshold) is cleared automatically",
            "localStorage persistence can be disabled via configuration",
            "State hydration happens before first component render to prevent flash of empty state"
          ],
          "implementation": {
            "frontend": [
              "Implement Zustand persist middleware on conversation store",
              "Configure persist middleware to use localStorage with key 'conversation-state'",
              "Add whitelist of state properties to persist (exclude temporary states)",
              "Create state migration function for version upgrades",
              "Implement error boundary for localStorage failures",
              "Add storage quota check before persisting large states",
              "Create utility to clear stale localStorage data",
              "Add visual indicator during state hydration",
              "Implement manual save/restore functions for debugging"
            ],
            "backend": [
              "No direct backend implementation for localStorage",
              "Consider creating backup sync endpoint POST /api/conversations/sync for cloud backup",
              "Implement endpoint to fetch conversations for comparison with local state"
            ],
            "middleware": [
              "No middleware required for client-side localStorage",
              "If implementing cloud sync, add authentication to sync endpoint"
            ],
            "shared": [
              "Define PersistedState interface with version property",
              "Create STORAGE_VERSION constant for state versioning",
              "Implement serializeState() function to prepare state for storage",
              "Implement deserializeState() function with validation",
              "Create migrateState(oldVersion, newVersion, state) function",
              "Define storage configuration options (enabled, key, whitelist)",
              "Create utility to calculate storage size of serialized state",
              "Define error types for storage failures (QuotaExceeded, SecurityError)"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationStore.persistStateToLocalStorage",
          "related_concepts": [
            "State persistence",
            "localStorage API",
            "Serialization/deserialization",
            "Hydration",
            "Storage quota management",
            "State versioning"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_028.5",
          "description": "Integrate the conversation store with UI components including sidebar, message list, and input components, ensuring proper data flow and reactivity",
          "type": "sub_process",
          "parent_id": "REQ_028",
          "children": [],
          "acceptance_criteria": [
            "Sidebar component displays list of conversations from store",
            "Clicking conversation in sidebar updates activeConversationId in store",
            "MessageList component reactively displays messages for active conversation",
            "MessageInput component dispatches addMessage action on form submit",
            "All components use typed store hooks/subscriptions",
            "Components only re-render when relevant state slices change",
            "Loading and error states are displayed appropriately in UI",
            "Store actions are called with proper error handling in components",
            "Optimistic updates provide immediate UI feedback",
            "Store selectors are used to derive computed state efficiently"
          ],
          "implementation": {
            "frontend": [
              "Create useConversations() selector hook for sidebar",
              "Create useActiveConversation() selector hook for conversation view",
              "Create useMessages() selector hook for message list",
              "Implement Sidebar component with conversation list rendering",
              "Add onClick handler in Sidebar to call setActiveConversation",
              "Implement MessageList component with messages subscription",
              "Create MessageInput component with form handling",
              "Add onSubmit handler in MessageInput to call addMessage with optimistic update",
              "Implement error display component for store errors",
              "Add loading skeletons for async operations",
              "Create custom hooks for common store operations (useSendMessage, useSwitchConversation)"
            ],
            "backend": [
              "Ensure all necessary API endpoints are implemented and documented",
              "Create API client functions for each endpoint",
              "Implement proper error response formats"
            ],
            "middleware": [
              "No additional middleware requirements",
              "Existing authentication and validation middleware applies"
            ],
            "shared": [
              "Create selector utilities to prevent unnecessary re-renders",
              "Define custom hook types for TypeScript support",
              "Create HOC or hook for automatic error handling",
              "Define props interfaces for all conversation-related components",
              "Create utility to format timestamps for display",
              "Define loading state types for different operations"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationStore.setupStoreIntegration",
          "related_concepts": [
            "Store-component integration",
            "React hooks pattern",
            "Svelte stores subscription",
            "Derived state",
            "Selector performance",
            "Component re-render optimization"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_029",
      "description": "The system must integrate with existing agent architecture components",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_029.1",
          "description": "Integrate the existing 6-phase RLM-Act pipeline (Research, Decomposition, TDD Planning, Multi-Doc, Beads Sync, Implementation) to orchestrate the writing agent's workflow from raw input ingestion through content generation",
          "type": "sub_process",
          "parent_id": "REQ_029",
          "children": [],
          "acceptance_criteria": [
            "Writing agent creates custom pipeline with phases: IngestPhase, TranscribePhase, AnalyzePhase, GeneratePhase, ReviewPhase",
            "Pipeline supports CHECKPOINT mode for user review between phases",
            "Pipeline supports FULLY_AUTONOMOUS mode for uninterrupted execution",
            "Each phase inherits from base Phase class with execute() method",
            "Phase results are stored and passed to subsequent phases",
            "Pipeline state is serializable for checkpoint persistence",
            "Error handling propagates from individual phases to pipeline orchestrator",
            "Phase execution logs are captured with timestamps and status",
            "Pipeline supports resume from any phase checkpoint",
            "Integration tests verify end-to-end pipeline execution from raw input to generated content"
          ],
          "implementation": {
            "frontend": [
              "Pipeline status indicator component showing current phase (Ingest \u2192 Transcribe \u2192 Analyze \u2192 Generate \u2192 Review)",
              "Phase progress visualization with completed/in-progress/pending states",
              "Checkpoint review dialog for user approval between phases",
              "Pipeline control buttons (Start, Pause, Resume, Cancel)",
              "Phase error display with retry options"
            ],
            "backend": [
              "WritingAgentPipeline class extending RLM-Act pipeline architecture",
              "POST /api/pipeline/start endpoint accepting input text/audio and configuration",
              "GET /api/pipeline/status/:pipeline_id endpoint for real-time status",
              "POST /api/pipeline/resume/:checkpoint_id endpoint for resuming from checkpoint",
              "Phase executor service managing phase lifecycle (initialize \u2192 execute \u2192 complete)",
              "Pipeline state manager tracking current phase, results, and errors",
              "Phase result aggregator combining outputs across all phases",
              "Pipeline configuration service for autonomy mode selection"
            ],
            "middleware": [
              "Pipeline execution authorization checking user permissions for long-running workflows",
              "Phase timeout enforcement preventing infinite execution",
              "Resource usage monitoring for pipeline operations",
              "Pipeline state validation before phase transitions"
            ],
            "shared": [
              "PipelineState model with fields: pipeline_id, current_phase, phase_results, autonomy_mode, created_at, updated_at",
              "PhaseResult model with fields: phase_name, status (pending/running/completed/failed), output, error, duration",
              "AutonomyMode enum: CHECKPOINT, FULLY_AUTONOMOUS, BATCH",
              "PhaseStatus enum: PENDING, RUNNING, COMPLETED, FAILED, SKIPPED",
              "Pipeline execution events for state transitions"
            ]
          },
          "testable_properties": [],
          "function_id": "AgentIntegration.leverageRLMActPipeline",
          "related_concepts": [
            "silmari_rlm_act/pipeline.py",
            "Phase-based workflow execution",
            "Autonomy modes (CHECKPOINT, FULLY_AUTONOMOUS, BATCH)",
            "Pipeline state management",
            "Phase transitions",
            "Multi-step orchestration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_029.2",
          "description": "Adapt the existing requirement decomposition pipeline (planning_pipeline/decomposition.py) to extract hierarchical themes, key concepts, and writing topics from user input text or transcribed audio",
          "type": "sub_process",
          "parent_id": "REQ_029",
          "children": [],
          "acceptance_criteria": [
            "DecompositionAdapter converts raw text input into WritingTheme objects with hierarchical structure",
            "Themes include category, summary, key_points, and related_themes fields",
            "Integration with existing decompose_requirements() function from planning_pipeline",
            "Theme extraction handles both short-form (notes) and long-form (essays) input",
            "Extracted themes are stored in Context Window Array with EntryType.SUMMARY",
            "Theme similarity search works using existing TF-IDF search index",
            "Themes are prioritized by relevance score (high/medium/low)",
            "Theme extraction includes acceptance criteria for each identified topic",
            "Unit tests verify theme extraction from sample writing inputs with known themes",
            "Performance benchmark: theme extraction completes in <5 seconds for 5000-word input"
          ],
          "implementation": {
            "frontend": [
              "ThemeDisplay component showing extracted themes as hierarchical tree",
              "Theme tag list with color coding by category (Content Generation, Character Development, Plot Structure, etc.)",
              "Theme relevance score indicator (high/medium/low badges)",
              "Interactive theme selection allowing users to approve/reject themes",
              "Theme preview tooltip showing key points on hover",
              "Theme refinement dialog for editing extracted themes"
            ],
            "backend": [
              "POST /api/extract-themes endpoint accepting text input and returning WritingTheme[]",
              "ThemeExtractionService wrapping planning_pipeline decomposition functions",
              "decompose_writing_input() function adapting RequirementNode to WritingTheme",
              "Theme categorization using existing CategoryAnalysisSchema.baml",
              "Theme storage service persisting themes to Context Window Array",
              "GET /api/themes/:conversation_id endpoint retrieving themes for conversation",
              "Theme similarity search service using existing VectorSearchIndex",
              "Theme prioritization algorithm scoring themes by frequency and coherence"
            ],
            "middleware": [
              "Input sanitization for theme extraction (remove PII, profanity filtering)",
              "Theme extraction rate limiting (max 10 requests per minute per user)",
              "Theme extraction timeout (30 seconds max)",
              "Validation that input text is at least 50 characters"
            ],
            "shared": [
              "WritingTheme model with fields: theme_id, category, summary, key_points, relevance_score, parent_theme_id, children",
              "ThemeCategory enum: CONTENT_GENERATION, CHARACTER_DEVELOPMENT, PLOT_STRUCTURE, RESEARCH_TOPICS, STYLE_ELEMENTS",
              "RelevanceScore enum: HIGH, MEDIUM, LOW",
              "ThemeExtractionConfig model for customizing extraction behavior",
              "DecompositionAdapter utility converting RequirementNode to WritingTheme"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtraction.useDecompositionPipeline",
          "related_concepts": [
            "planning_pipeline/decomposition.py",
            "BAML-based requirement extraction",
            "RequirementHierarchy with parent/child relationships",
            "Category analysis schemas",
            "Semantic theme identification",
            "TF-IDF search integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_029.3",
          "description": "Integrate with existing BAML (Boundless AI Markup Language) services for type-safe LLM function calls including content generation, theme analysis, and transcription formatting using configured Claude and GPT-4 clients",
          "type": "sub_process",
          "parent_id": "REQ_029",
          "children": [],
          "acceptance_criteria": [
            "WritingAgent uses BAML function definitions for all LLM interactions",
            "New BAML functions created: GenerateContent, AnalyzeThemes, FormatTranscription",
            "BAML client configuration uses existing GPT4o and Claude Sonnet clients",
            "Fallback strategy implemented: Claude Sonnet \u2192 GPT-4o \u2192 GPT-4o-mini",
            "Retry policy configured with exponential backoff (3 retries, 1000ms initial delay)",
            "BAML audio type configured for transcription inputs",
            "Streaming responses work for content generation (yield partial results)",
            "BAML type schemas defined for WritingRequest, WritingResponse, ThemeAnalysis",
            "Integration tests verify BAML function calls return expected types",
            "Error handling for LLM provider failures with graceful degradation"
          ],
          "implementation": {
            "frontend": [
              "Streaming response display component for real-time content generation",
              "LLM provider selector dropdown (Claude Sonnet, GPT-4o, GPT-4o-mini)",
              "Generation parameters UI (temperature, max_tokens, model selection)",
              "Retry indicator showing fallback provider attempts",
              "Token usage display showing consumption per request",
              "Generation error messages with provider-specific troubleshooting"
            ],
            "backend": [
              "BAML function file: baml_src/writing_agent_functions.baml with GenerateContent, AnalyzeThemes, FormatTranscription",
              "BAML type file: baml_src/writing_agent_types.baml with WritingRequest, WritingResponse, ThemeAnalysis, TranscriptFormat",
              "BAMLWritingService class wrapping BAML client initialization and function calls",
              "generate_content() async function with streaming support",
              "analyze_themes_baml() function for theme extraction via LLM",
              "format_transcription() function for cleaning up audio transcripts",
              "LLM provider health check service monitoring API availability",
              "Token usage tracking and logging per request"
            ],
            "middleware": [
              "BAML API key validation on service initialization",
              "Request timeout enforcement (120 seconds for generation, 30 seconds for analysis)",
              "Token limit validation preventing requests exceeding model context windows",
              "Rate limiting per LLM provider (respect API quotas)"
            ],
            "shared": [
              "WritingRequest model: input_text, themes, style_guide, target_length, temperature",
              "WritingResponse model: generated_content, tokens_used, provider_used, generation_time",
              "ThemeAnalysis model: themes, key_concepts, suggested_structure, tone_analysis",
              "TranscriptFormat model: cleaned_text, speaker_labels, timestamps, confidence_scores",
              "BAMLConfig model: provider_priority, retry_policy, fallback_enabled, streaming_enabled",
              "LLMProvider enum: CLAUDE_SONNET, GPT4O, GPT4O_MINI, OLLAMA"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLIntegration.connectToServices",
          "related_concepts": [
            "baml_src/functions.baml",
            "baml_src/clients.baml",
            "baml_src/types.baml",
            "planning_pipeline/claude_runner.py",
            "Multi-provider LLM support",
            "Retry policies and fallback strategies",
            "Streaming responses"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_029.4",
          "description": "Leverage the existing checkpoint and state persistence system (silmari_rlm_act/checkpoints/) to save conversation state, pipeline progress, and intermediate results with resume capability",
          "type": "sub_process",
          "parent_id": "REQ_029",
          "children": [],
          "acceptance_criteria": [
            "WritingAgentCheckpointManager extends existing CheckpointManager",
            "Checkpoints saved after each pipeline phase completion",
            "Checkpoint files stored in .writing-agent-checkpoints/ directory",
            "Checkpoint structure includes: checkpoint_id, timestamp, phase, conversation_id, pipeline_state, user_inputs, generated_outputs, themes",
            "Resume functionality restores full conversation state from checkpoint_id",
            "Checkpoint list endpoint returns all available checkpoints for a conversation",
            "Checkpoint cleanup removes checkpoints older than 30 days",
            "Git integration tracks commit hash with each checkpoint",
            "Checkpoint validation prevents loading corrupted or incompatible checkpoints",
            "Performance: checkpoint save/load operations complete in <500ms"
          ],
          "implementation": {
            "frontend": [
              "Checkpoint history sidebar showing saved states with timestamps",
              "Resume from checkpoint button with confirmation dialog",
              "Auto-save indicator showing last checkpoint time",
              "Checkpoint comparison view showing differences between states",
              "Checkpoint deletion UI with batch operations",
              "Checkpoint export/import functionality for backup"
            ],
            "backend": [
              "WritingAgentCheckpointManager class extending CheckpointManager",
              "POST /api/checkpoints/save endpoint creating new checkpoint",
              "GET /api/checkpoints/:conversation_id endpoint listing checkpoints",
              "POST /api/checkpoints/resume/:checkpoint_id endpoint restoring state",
              "DELETE /api/checkpoints/:checkpoint_id endpoint removing checkpoint",
              "Checkpoint serialization service converting pipeline state to JSON",
              "Checkpoint validation service verifying checkpoint integrity",
              "Checkpoint cleanup job running daily to remove old checkpoints",
              "Git commit integration storing repository state with checkpoint"
            ],
            "middleware": [
              "Checkpoint access authorization (users can only access own checkpoints)",
              "Checkpoint size validation (max 10MB per checkpoint)",
              "Checkpoint encryption for sensitive conversation data",
              "Concurrent checkpoint access prevention (lock mechanism)"
            ],
            "shared": [
              "ConversationCheckpoint model: checkpoint_id, conversation_id, phase, timestamp, pipeline_state, user_inputs, generated_outputs, themes, git_commit, metadata",
              "CheckpointMetadata model: user_id, agent_version, baml_version, model_providers",
              "CheckpointStatus enum: SAVED, LOADING, LOADED, FAILED, CORRUPTED",
              "CheckpointConfig model: auto_save_enabled, retention_days, compression_enabled",
              "Checkpoint serializer/deserializer utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "StateManagement.utilizeCheckpointSystem",
          "related_concepts": [
            "silmari_rlm_act/checkpoints/manager.py",
            "silmari_rlm_act/checkpoints/interactive.py",
            "Checkpoint serialization",
            "Git commit tracking",
            "Resume point detection",
            "State recovery"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_030",
      "description": "The system must provide theme extraction API endpoint",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_030.1",
          "description": "Accept and validate text input from API request with proper error handling and content validation",
          "type": "sub_process",
          "parent_id": "REQ_030",
          "children": [],
          "acceptance_criteria": [
            "API endpoint accepts POST requests with text payload in request body",
            "Request body validation ensures 'text' field is present and non-empty",
            "Text input length validation enforces minimum (10 characters) and maximum (100,000 characters) limits",
            "Content-Type header validation ensures application/json format",
            "Returns 400 Bad Request with descriptive error message for invalid input",
            "Returns 413 Payload Too Large for text exceeding maximum length",
            "Sanitizes input to prevent injection attacks",
            "Handles UTF-8 encoded text correctly including special characters",
            "Logs incoming requests with sanitized preview (first 100 chars) for debugging"
          ],
          "implementation": {
            "frontend": [
              "Not applicable - this is a backend API endpoint that can be consumed by any client"
            ],
            "backend": [
              "POST /api/extract-themes endpoint in FastAPI or Flask",
              "Request model (Pydantic BaseModel) defining ThemeExtractionRequest with text field",
              "Input validation logic checking text field presence, type, and length constraints",
              "Text sanitization function to remove potentially harmful content",
              "Error response models for validation failures (400, 413 status codes)",
              "Request logging middleware to capture API usage metrics"
            ],
            "middleware": [
              "Request size limit middleware (e.g., 10MB max payload size)",
              "Content-Type validation middleware ensuring application/json",
              "Rate limiting middleware to prevent abuse (e.g., 100 requests per minute per IP)",
              "CORS middleware if frontend needs cross-origin access",
              "Authentication/API key validation if endpoint requires authorization"
            ],
            "shared": [
              "ThemeExtractionRequest model with text: str field and validators",
              "ErrorResponse model with error: str, details: dict fields",
              "ValidationConstants class defining MIN_TEXT_LENGTH=10, MAX_TEXT_LENGTH=100000",
              "sanitize_text() utility function for input cleaning"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtractionAPI.acceptTextInput",
          "related_concepts": [
            "input validation",
            "request parsing",
            "content sanitization",
            "error handling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_030.2",
          "description": "Process accepted text through the existing decomposition pipeline to extract hierarchical requirements and categorize themes",
          "type": "sub_process",
          "parent_id": "REQ_030",
          "children": [],
          "acceptance_criteria": [
            "Invokes decompose_requirements() function from planning_pipeline/decomposition.py with user text",
            "Configures DecompositionConfig with appropriate settings for writing agent context",
            "Passes text through BAML-powered Claude analysis for theme identification",
            "Extracts requirement nodes with category classifications",
            "Builds hierarchical structure of parent requirements and sub-processes",
            "Handles API rate limits and implements exponential backoff retry logic",
            "Catches and handles LLM API errors gracefully (timeout, rate limit, service unavailable)",
            "Returns structured RequirementHierarchy object with categorized themes",
            "Processes requests within 30 seconds timeout limit",
            "Logs decomposition processing time and token usage metrics"
          ],
          "implementation": {
            "frontend": [
              "Not applicable - internal processing logic"
            ],
            "backend": [
              "Integration layer connecting API endpoint to decomposition.py module",
              "Adapter function wrapping decompose_requirements() with writing-agent-specific config",
              "DecompositionConfig initialization with parameters optimized for theme extraction",
              "Error handling wrapper catching LLMError, TimeoutError, and APIError exceptions",
              "Async processing handler to prevent blocking (optional for long texts)",
              "Result transformation logic converting RequirementHierarchy to API response format",
              "Caching layer using Redis or in-memory cache for identical text inputs (TTL: 1 hour)",
              "Background task queue integration (Celery/RQ) for texts over 10,000 characters"
            ],
            "middleware": [
              "Timeout middleware enforcing 30-second processing limit",
              "Circuit breaker pattern for LLM API failures (open after 5 consecutive failures)",
              "Request queuing middleware for high-load scenarios",
              "Metrics collection middleware tracking processing duration and success rate"
            ],
            "shared": [
              "DecompositionAdapter class wrapping decomposition pipeline logic",
              "WritingAgentConfig extending DecompositionConfig with writing-specific settings",
              "RequirementNode to Theme mapping utility function",
              "LLMRetryPolicy class defining backoff strategy (exponential, max 3 retries)",
              "ProcessingMetrics dataclass capturing timing, tokens, and status",
              "CacheKey generator for deterministic cache keys based on text content hash"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtractionAPI.processDecomposition",
          "related_concepts": [
            "decomposition pipeline",
            "BAML integration",
            "Claude API",
            "requirement hierarchy",
            "theme categorization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_030.3",
          "description": "Transform decomposition pipeline results into structured theme list and return as JSON response",
          "type": "sub_process",
          "parent_id": "REQ_030",
          "children": [],
          "acceptance_criteria": [
            "Extracts unique theme categories from RequirementHierarchy nodes",
            "Maps internal category enums to human-readable theme names",
            "Deduplicates themes appearing multiple times in hierarchy",
            "Ranks themes by frequency or importance (most mentioned first)",
            "Returns themes as JSON array of theme objects with name and description",
            "Each theme object includes 'name' (string) and 'theme_description' (string) fields",
            "Response includes total theme count and processing metadata",
            "Returns 200 OK status code on successful extraction",
            "Response time under 100ms for transformation logic (excluding LLM processing)",
            "Handles empty or no-themes-found scenarios gracefully with empty array"
          ],
          "implementation": {
            "frontend": [
              "Not applicable - this is response formatting logic"
            ],
            "backend": [
              "ThemeExtractor class with extract_themes() method processing RequirementHierarchy",
              "Category-to-theme mapping dictionary converting internal codes to display names",
              "Theme ranking algorithm (frequency-based or priority-based)",
              "Deduplication logic using set-based comparison on theme names",
              "ThemeResponse model builder constructing JSON-serializable response object",
              "Response metadata enrichment adding processing_time, theme_count, model_version",
              "Empty result handler returning valid response structure when no themes found",
              "Response serialization using FastAPI/Flask native JSON encoders"
            ],
            "middleware": [
              "Response compression middleware (gzip) for large theme lists",
              "Response header injection adding Cache-Control and ETag headers",
              "CORS headers middleware for cross-origin requests"
            ],
            "shared": [
              "ThemeObject model with name: str, theme_description: str, priority: int",
              "ThemeExtractionResponse model with themes: List[ThemeObject], metadata: dict",
              "CategoryMapper utility class with get_display_name() static method",
              "ThemeRanker utility with rank_by_frequency() and rank_by_priority() methods",
              "ResponseMetadata dataclass with processing_time_ms, theme_count, timestamp fields"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtractionAPI.returnIdentifiedThemes",
          "related_concepts": [
            "response formatting",
            "theme extraction",
            "category mapping",
            "JSON serialization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_030.4",
          "description": "Extract and include key points from decomposition results alongside themes in API response",
          "type": "sub_process",
          "parent_id": "REQ_030",
          "children": [],
          "acceptance_criteria": [
            "Extracts text field from each RequirementNode as key point",
            "Associates each key point with its parent theme category",
            "Includes acceptance_criteria list from nodes as supporting details",
            "Limits key points to top 10 most relevant per theme to prevent response bloat",
            "Ranks key points by relevance score or position in hierarchy",
            "Each key point includes 'text' (string), 'category' (string), and 'acceptance_criteria' (array) fields",
            "Handles hierarchical relationships by flattening parent-child node structures",
            "Returns key points grouped by theme in response",
            "Ensures key point text is truncated to 500 characters max with ellipsis",
            "Empty key points array returned when no specific points identified"
          ],
          "implementation": {
            "frontend": [
              "Not applicable - backend response formatting"
            ],
            "backend": [
              "KeyPointExtractor class with extract_key_points() method traversing RequirementHierarchy",
              "Hierarchy traversal logic using depth-first or breadth-first search",
              "Key point ranking algorithm based on node depth, category importance, or text length",
              "Text truncation utility limiting key point text to 500 characters",
              "Theme-to-key-points grouping logic building nested response structure",
              "Top-N selector limiting key points to 10 per theme",
              "Acceptance criteria extraction mapping from node.acceptance_criteria to response field",
              "Response builder merging themes and key_points into unified ThemeExtractionResponse"
            ],
            "middleware": [
              "Response size monitoring to ensure total payload under 1MB",
              "Streaming response middleware for very large key point sets (>100 items)"
            ],
            "shared": [
              "KeyPoint model with text: str, category: str, acceptance_criteria: List[str], relevance_score: float",
              "KeyPointExtractor utility class with traverse_hierarchy() and extract_node_data() methods",
              "TextTruncator utility with truncate(text: str, max_length: int) -> str method",
              "KeyPointRanker with calculate_relevance_score() method",
              "ThemeWithKeyPoints model combining ThemeObject with key_points: List[KeyPoint] field",
              "Updated ThemeExtractionResponse including key_points: List[KeyPoint] field"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtractionAPI.includeKeyPoints",
          "related_concepts": [
            "requirement extraction",
            "key point identification",
            "content summarization",
            "acceptance criteria mapping"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_030.5",
          "description": "Configure API endpoint routing, documentation, and integration with existing Context Engine components",
          "type": "sub_process",
          "parent_id": "REQ_030",
          "children": [],
          "acceptance_criteria": [
            "POST /api/extract-themes endpoint registered in FastAPI application",
            "OpenAPI/Swagger documentation auto-generated with request/response schemas",
            "Endpoint integrated with existing BAML client configuration from baml_src/clients.baml",
            "Uses Claude Sonnet or GPT-4o as configured LLM provider from existing setup",
            "Implements proper dependency injection for DecompositionConfig and CWA store",
            "Comprehensive error handling returning appropriate HTTP status codes (400, 413, 429, 500, 503)",
            "Request/response logging integrated with existing logging infrastructure",
            "Health check endpoint /api/health includes theme extraction service status",
            "Unit tests covering all endpoint logic paths with mocked LLM responses",
            "Integration tests verifying end-to-end flow with real decomposition pipeline",
            "API versioning support (e.g., /api/v1/extract-themes) for future compatibility",
            "Endpoint performance monitoring with Prometheus metrics or similar"
          ],
          "implementation": {
            "frontend": [
              "Not applicable - backend API infrastructure"
            ],
            "backend": [
              "FastAPI router module (routers/theme_extraction.py) defining endpoint",
              "Endpoint handler function extract_themes(request: ThemeExtractionRequest)",
              "Dependency injection setup providing DecompositionConfig instance",
              "Dependency injection for CentralContextStore if conversation context needed",
              "BAML client initialization using existing clients.baml configuration",
              "Error handler functions for each exception type (LLMError, ValidationError, etc.)",
              "Global exception handler catching unhandled errors and returning 500 responses",
              "Logging decorator capturing request/response data and timing",
              "Health check service checking LLM API connectivity and decomposition pipeline status",
              "API version prefix configuration in main FastAPI app setup"
            ],
            "middleware": [
              "Request ID generation middleware for request tracing",
              "Request timing middleware logging duration for performance monitoring",
              "Error standardization middleware ensuring consistent error response format",
              "Authentication middleware if API requires authorization (API key or JWT)",
              "Rate limiting middleware preventing abuse (100 requests/min per user)"
            ],
            "shared": [
              "APIRouter instance for theme extraction endpoints",
              "Dependency provider functions (get_decomposition_config(), get_context_store())",
              "Standardized ErrorResponse model used across all endpoints",
              "HTTPException factory functions (bad_request(), internal_error(), rate_limited())",
              "LoggingContext dataclass with request_id, endpoint, duration fields",
              "HealthCheckResponse model with status: str, services: Dict[str, bool]",
              "API version constants (API_VERSION = 'v1')",
              "Prometheus metrics collectors (request_duration_histogram, request_count_counter)"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtractionAPI.setupEndpointIntegration",
          "related_concepts": [
            "API routing",
            "OpenAPI documentation",
            "dependency injection",
            "error handling",
            "logging"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_030.6",
          "description": "Implement intelligent caching layer to reduce redundant LLM API calls for identical or similar text inputs",
          "type": "sub_process",
          "parent_id": "REQ_030",
          "children": [],
          "acceptance_criteria": [
            "Generates deterministic cache key from text input using SHA-256 hash",
            "Checks cache before invoking decomposition pipeline",
            "Returns cached response within 50ms if cache hit",
            "Stores successful theme extraction results in cache with 1-hour TTL",
            "Cache key includes model version to invalidate on pipeline updates",
            "Implements cache warming for common writing topics (optional)",
            "Monitors cache hit rate and exposes metric via /metrics endpoint",
            "Configurable cache backend (Redis, in-memory, or disabled for development)",
            "Cache size limits prevent memory exhaustion (max 10,000 entries or 1GB)",
            "Implements cache eviction policy (LRU - Least Recently Used)",
            "Admin endpoint /api/admin/cache/clear for manual cache invalidation",
            "Cache bypass option via request header (X-No-Cache: true) for testing"
          ],
          "implementation": {
            "frontend": [
              "Not applicable - backend caching infrastructure"
            ],
            "backend": [
              "CacheService class with get(key: str) and set(key: str, value: Any, ttl: int) methods",
              "Redis client initialization and connection pool management",
              "In-memory fallback cache using Python LRU cache for local development",
              "Cache key generator function create_cache_key(text: str, model_version: str) -> str",
              "SHA-256 hashing utility for text content",
              "Cache middleware checking cache before endpoint handler execution",
              "Cache writer saving successful responses after decomposition",
              "Cache statistics tracker counting hits, misses, and evictions",
              "Admin cache clearing endpoint with authentication requirement",
              "Cache configuration loader from environment variables (CACHE_ENABLED, CACHE_TTL, CACHE_BACKEND)",
              "Cache health check verifying Redis connectivity"
            ],
            "middleware": [
              "Cache lookup middleware intercepting requests before handler",
              "Cache header middleware adding X-Cache-Status: HIT|MISS to responses",
              "Cache bypass middleware checking X-No-Cache header",
              "Cache statistics middleware updating Prometheus metrics"
            ],
            "shared": [
              "CacheService interface defining get(), set(), delete(), clear() methods",
              "RedisCache implementation of CacheService",
              "InMemoryCache implementation using Python lru_cache or cachetools",
              "CacheKey dataclass with text_hash: str, model_version: str, timestamp: int",
              "CacheConfig dataclass with enabled: bool, ttl_seconds: int, backend: str, max_entries: int",
              "CacheStats dataclass with hits: int, misses: int, evictions: int, hit_rate: float",
              "hash_text() utility function using hashlib.sha256",
              "CacheMetrics class exposing Prometheus counters and histograms"
            ]
          },
          "testable_properties": [],
          "function_id": "ThemeExtractionAPI.implementCachingStrategy",
          "related_concepts": [
            "caching",
            "performance optimization",
            "cache invalidation",
            "content hashing",
            "Redis"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_031",
      "description": "The system must support content generation API endpoint with theme-aware prompting",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_031.1",
          "description": "Accept and validate user text input and optional theme list via HTTP POST request",
          "type": "sub_process",
          "parent_id": "REQ_031",
          "children": [],
          "acceptance_criteria": [
            "API endpoint accepts POST requests at /api/generate with JSON payload",
            "Request body must contain 'text' field (string, required, 1-50000 characters)",
            "Request body may contain 'themes' field (array of strings, optional, max 20 themes)",
            "Each theme in themes array must be 1-200 characters",
            "API returns 400 Bad Request with validation errors if input is invalid",
            "API returns 422 Unprocessable Entity if text is empty or only whitespace",
            "Input text is sanitized to remove potentially harmful content",
            "Request validation completes in <50ms",
            "Validation errors include field name and specific error message"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - this is backend-only",
              "API client function to POST to /api/generate endpoint",
              "TypeScript interface for GenerateRequest model"
            ],
            "backend": [
              "POST /api/generate endpoint in FastAPI router",
              "Pydantic model GenerateRequest with text (str) and themes (Optional[List[str]])",
              "Validation rules: text length 1-50000, themes array max 20 items, theme length 1-200",
              "Input sanitization service to strip malicious content",
              "Error response formatter for validation failures",
              "Logging service to track incoming requests"
            ],
            "middleware": [
              "Request size limit middleware (max 1MB payload)",
              "Rate limiting middleware (max 60 requests per minute per IP)",
              "CORS middleware to allow frontend origin",
              "Request ID generation for tracing"
            ],
            "shared": [
              "GenerateRequest data model with validation rules",
              "ValidationError model for error responses",
              "Constants: MAX_TEXT_LENGTH, MAX_THEMES, MAX_THEME_LENGTH",
              "Utility function sanitize_text_input(text: str) -> str"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentGenerationAPI.acceptUserInput",
          "related_concepts": [
            "Request validation",
            "Input sanitization",
            "Theme list parsing",
            "Error handling",
            "API request model"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_031.2",
          "description": "Construct a context-aware prompt that incorporates user text, theme list, and conversation history to guide LLM generation",
          "type": "sub_process",
          "parent_id": "REQ_031",
          "children": [],
          "acceptance_criteria": [
            "Prompt builder retrieves relevant conversation history from Context Window Array (CWA)",
            "Prompt includes user input text as primary content",
            "Prompt incorporates all provided themes with explicit instructions to address each",
            "Prompt structure follows format: system instructions + conversation context + themes + user text + generation guidelines",
            "System instructions define writing style, tone, and quality expectations",
            "Conversation context limited to most recent 5 turns or 4000 tokens, whichever is smaller",
            "Theme instructions are formatted as numbered list for clarity",
            "Prompt includes guidance on output format (e.g., structured sections, markdown)",
            "Total prompt length does not exceed model's context limit (e.g., 8000 tokens for GPT-4)",
            "Token counting is performed before sending to LLM",
            "If prompt exceeds token limit, conversation context is truncated first, then theme descriptions",
            "Prompt building completes in <200ms"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - this is backend-only"
            ],
            "backend": [
              "PromptBuilder service class with build_generation_prompt() method",
              "Integration with context_window_array.store.CentralContextStore for conversation retrieval",
              "search_conversation_context(conversation_id: str, limit: int) function",
              "Template rendering system using Jinja2 or string formatting",
              "Prompt template file: generation_prompt.jinja2 with placeholders for {{user_text}}, {{themes}}, {{context}}",
              "Token counting service using tiktoken library",
              "Prompt truncation logic: truncate_context(context: str, max_tokens: int) -> str",
              "Theme formatter: format_themes_as_instructions(themes: List[str]) -> str",
              "Logging service to track prompt construction details"
            ],
            "middleware": [
              "No middleware needed for this internal service"
            ],
            "shared": [
              "PromptTemplate data model with template_name and variables",
              "ConversationContext model with turns, tokens, and relevance_score",
              "Constants: MAX_PROMPT_TOKENS, MAX_CONTEXT_TURNS, DEFAULT_GENERATION_STYLE",
              "Utility function count_tokens(text: str, model: str) -> int",
              "Utility function truncate_to_token_limit(text: str, max_tokens: int) -> str"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentGenerationAPI.buildContextPrompt",
          "related_concepts": [
            "Prompt engineering",
            "Theme integration",
            "Context retrieval",
            "Conversation history",
            "Prompt template system",
            "Token counting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_031.3",
          "description": "Send constructed prompt to configured LLM provider (via BAML) and handle streaming or complete response with error handling and retries",
          "type": "sub_process",
          "parent_id": "REQ_031",
          "children": [],
          "acceptance_criteria": [
            "Service uses BAML client configuration from baml_src/clients.baml",
            "Supports both streaming and non-streaming generation modes",
            "Uses exponential backoff retry policy with max 3 retries for transient errors",
            "Falls back to secondary LLM provider if primary provider fails",
            "Invocation includes temperature, max_tokens, and model parameters from configuration",
            "Streaming responses yield content chunks in real-time with <500ms first-token latency",
            "Non-streaming responses return complete content in single response",
            "Handles rate limit errors (429) with exponential backoff (1s, 2s, 4s delays)",
            "Handles timeout errors with appropriate retry logic (max 60s per attempt)",
            "Handles invalid API key errors (401) without retry, returns clear error",
            "Handles content policy violations (e.g., safety filters) and returns user-friendly error",
            "Captures and logs full request/response details for debugging",
            "Returns structured LLMResponse object with content, model_used, tokens_used, finish_reason",
            "Generation completes within 30s for non-streaming, or starts streaming within 2s"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - this is backend-only"
            ],
            "backend": [
              "LLMService class with generate(prompt: str, stream: bool) -> Union[str, AsyncGenerator[str]]",
              "Integration with BAML client via generated Python client code",
              "Async function invoke_baml_generation(prompt: str, config: GenerationConfig) -> LLMResponse",
              "Streaming handler: stream_llm_response(prompt: str) -> AsyncGenerator[str, None]",
              "Retry decorator with exponential backoff: @retry(max_attempts=3, backoff=exponential)",
              "Error handler mapping LLM provider errors to user-friendly messages",
              "Fallback provider logic: try GPT-4 -> fall back to Claude Sonnet -> fall back to GPT-4o-mini",
              "Token usage tracking and logging",
              "Response validation to ensure generated content meets minimum quality",
              "Circuit breaker pattern to disable failing providers temporarily"
            ],
            "middleware": [
              "No middleware needed for this internal service"
            ],
            "shared": [
              "LLMResponse model with content, model_used, tokens_used, finish_reason, latency_ms",
              "GenerationConfig model with temperature, max_tokens, model, stop_sequences",
              "LLMError exception hierarchy: RateLimitError, TimeoutError, AuthError, ContentPolicyError",
              "Constants: DEFAULT_TEMPERATURE=0.7, MAX_TOKENS=2000, DEFAULT_MODEL='gpt-4o'",
              "Utility function parse_streaming_chunk(chunk: str) -> Optional[str]",
              "Utility function validate_generation_quality(content: str) -> bool"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentGenerationAPI.invokeLLM",
          "related_concepts": [
            "BAML integration",
            "LLM invocation",
            "Streaming responses",
            "Error handling",
            "Retry logic",
            "Provider fallback",
            "Rate limiting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_031.4",
          "description": "Format and return generated content to client with metadata, handling both streaming and complete responses",
          "type": "sub_process",
          "parent_id": "REQ_031",
          "children": [],
          "acceptance_criteria": [
            "For non-streaming: returns 200 OK with JSON response containing 'content' and 'metadata' fields",
            "For streaming: returns 200 OK with Content-Type: text/event-stream and sends Server-Sent Events",
            "Metadata includes: model_used, tokens_used, generation_time_ms, themes_addressed",
            "Streaming response sends chunks as SSE events: data: {\"chunk\": \"...\", \"done\": false}",
            "Streaming response sends final event with done: true and metadata",
            "Content is returned with preserved formatting (markdown, line breaks, etc.)",
            "Empty or very short generations (<10 chars) return 422 Unprocessable Entity with error",
            "If LLM generation fails, returns 503 Service Unavailable with retry-after header",
            "If prompt building fails, returns 500 Internal Server Error with error details",
            "Response includes request_id header for tracing",
            "Response time for non-streaming: <30s total, streaming: first chunk <2s",
            "Response body size limit: 100KB for JSON, unlimited for streaming"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - backend-only, but frontend would consume these responses",
              "API client function to handle both JSON and streaming responses",
              "TypeScript interface for GenerateResponse model",
              "SSE client implementation to consume streaming responses"
            ],
            "backend": [
              "Response formatter: format_generation_response(content: str, metadata: dict) -> dict",
              "Streaming response handler: stream_sse_response(content_generator: AsyncGenerator) -> StreamingResponse",
              "SSE event formatter: format_sse_event(data: dict) -> str",
              "Metadata builder: build_response_metadata(llm_response: LLMResponse, themes: List[str]) -> dict",
              "Content validator: validate_generated_content(content: str) -> ValidationResult",
              "Error response formatter: format_error_response(error: Exception, request_id: str) -> JSONResponse",
              "Response logging service to track successful generations"
            ],
            "middleware": [
              "Response compression middleware (gzip) for JSON responses",
              "Response time tracking middleware to measure total request duration",
              "CORS middleware to set appropriate headers for streaming responses"
            ],
            "shared": [
              "GenerateResponse model with content (str), metadata (dict), request_id (str)",
              "ResponseMetadata model with model_used, tokens_used, generation_time_ms, themes_addressed",
              "SSEEvent model with event_type, data, id",
              "Constants: MIN_CONTENT_LENGTH=10, MAX_RESPONSE_SIZE=100000",
              "Utility function is_valid_markdown(content: str) -> bool",
              "Utility function calculate_generation_metrics(start_time: float, tokens: int) -> dict"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentGenerationAPI.returnGeneratedContent",
          "related_concepts": [
            "Response formatting",
            "Streaming response",
            "Content metadata",
            "Error responses",
            "HTTP status codes",
            "Content-Type headers"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_031.5",
          "description": "Orchestrate the complete end-to-end workflow from request acceptance to response delivery with proper error handling, logging, and state management",
          "type": "sub_process",
          "parent_id": "REQ_031",
          "children": [],
          "acceptance_criteria": [
            "Complete workflow executes all steps: accept input -> build prompt -> invoke LLM -> return content",
            "Each step's success/failure is logged with request_id for tracing",
            "Failed steps trigger appropriate rollback or cleanup actions",
            "Generated content is persisted to conversation history in CWA",
            "User input and generated response are stored as conversation turns",
            "Request metadata (themes, model used, tokens) is persisted for analytics",
            "Performance metrics are collected: total_time, prompt_build_time, llm_time, format_time",
            "Workflow supports both synchronous (complete response) and asynchronous (streaming) modes",
            "Concurrent requests are handled independently without state conflicts",
            "Failed generations do not corrupt conversation history",
            "Workflow respects user's conversation context and maintains continuity",
            "End-to-end workflow completes in <35s for non-streaming, starts streaming in <3s"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - this is backend orchestration"
            ],
            "backend": [
              "ContentGenerationOrchestrator class with generate_content(request: GenerateRequest) -> GenerateResponse",
              "Workflow state machine managing transitions: VALIDATING -> BUILDING_PROMPT -> GENERATING -> FORMATTING -> COMPLETE",
              "Integration with CentralContextStore to persist conversation turns",
              "Function save_generation_to_context(user_text: str, generated_content: str, metadata: dict) -> str",
              "Transaction manager for atomic conversation history updates",
              "Performance monitoring service to track step durations",
              "Audit logger to record all generation attempts (success and failure)",
              "Cleanup service to handle partial failures: cleanup_failed_generation(request_id: str)",
              "Analytics event emitter for generation metrics: emit_generation_event(event: GenerationEvent)"
            ],
            "middleware": [
              "Request context middleware to inject request_id and trace_id",
              "Performance monitoring middleware to measure total request duration",
              "Error handling middleware to catch unhandled exceptions and format responses"
            ],
            "shared": [
              "WorkflowState enum: VALIDATING, BUILDING_PROMPT, GENERATING, FORMATTING, COMPLETE, FAILED",
              "GenerationEvent model for analytics with request_id, user_id, themes, model, duration, success",
              "ConversationTurn model with role (user/assistant), content, timestamp, metadata",
              "Constants: WORKFLOW_TIMEOUT_SECONDS=35, STREAMING_START_TIMEOUT=3",
              "Utility function create_request_context(request: GenerateRequest) -> RequestContext",
              "Utility function measure_step_duration(step_name: str) -> context manager for timing"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentGenerationAPI.integrationWorkflow",
          "related_concepts": [
            "Workflow orchestration",
            "State management",
            "Transaction handling",
            "Conversation persistence",
            "Audit logging",
            "Performance monitoring"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_032",
      "description": "The system must handle multiple file attachment types including documents and images",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_032.1",
          "description": "Accept and validate PDF file uploads with size and content validation",
          "type": "sub_process",
          "parent_id": "REQ_032",
          "children": [],
          "acceptance_criteria": [
            "System accepts PDF files with MIME types 'application/pdf'",
            "PDF files up to 10MB are accepted",
            "System rejects non-PDF files disguised with .pdf extension",
            "File upload returns unique file identifier upon success",
            "System validates PDF structure to ensure file is not corrupted",
            "Upload progress is tracked and reportable",
            "System stores PDF metadata (filename, size, upload timestamp)"
          ],
          "implementation": {
            "frontend": [
              "FileUploadComponent with PDF file type filter",
              "Drag-and-drop zone that accepts .pdf files",
              "File preview component showing PDF thumbnail or first page",
              "Upload progress indicator with percentage",
              "Error message display for invalid files",
              "File size validation before upload (client-side pre-check)"
            ],
            "backend": [
              "POST /api/attachments/upload endpoint accepting multipart/form-data",
              "PDF MIME type validation service",
              "PDF structure validation using PDF parsing library",
              "File storage service (filesystem or S3)",
              "Attachment metadata persistence in database",
              "File size validation (max 10MB)"
            ],
            "middleware": [
              "Multipart file upload middleware (e.g., multer, busboy)",
              "File size limit enforcement middleware",
              "MIME type validation middleware",
              "Request authentication to verify user identity",
              "Rate limiting for upload endpoints"
            ],
            "shared": [
              "FileAttachment data model with fields: id, filename, mime_type, size, storage_path, upload_timestamp, user_id",
              "File validation utility functions",
              "Constants for max file size (MAX_PDF_SIZE_BYTES)",
              "MIME type constants (ALLOWED_PDF_MIME_TYPES)",
              "FileUploadResult interface/type"
            ]
          },
          "testable_properties": [],
          "function_id": "FileUploadService.acceptPDFFiles",
          "related_concepts": [
            "file validation",
            "MIME type checking",
            "PDF parsing",
            "file size limits",
            "multipart upload"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_032.2",
          "description": "Accept and validate image file uploads with format detection and basic image processing",
          "type": "sub_process",
          "parent_id": "REQ_032",
          "children": [],
          "acceptance_criteria": [
            "System accepts common image formats: JPEG, PNG, GIF, WebP, SVG",
            "System validates MIME types: image/jpeg, image/png, image/gif, image/webp, image/svg+xml",
            "Image files up to 5MB are accepted",
            "System generates thumbnails for uploaded images",
            "System extracts image dimensions (width, height)",
            "System rejects files with mismatched extensions and MIME types",
            "Upload returns image metadata including dimensions and format"
          ],
          "implementation": {
            "frontend": [
              "ImageUploadComponent with image file type filter (.jpg, .jpeg, .png, .gif, .webp, .svg)",
              "Image preview component showing thumbnail after selection",
              "Drag-and-drop zone with visual feedback for images",
              "Client-side image dimension validation",
              "Upload progress bar with status messages",
              "Image cropping/resizing interface (optional)"
            ],
            "backend": [
              "POST /api/attachments/upload endpoint with image handling",
              "Image MIME type validation service",
              "Image processing service for thumbnail generation",
              "Image metadata extraction service (dimensions, format, EXIF)",
              "Image storage service with organized directory structure",
              "Database persistence for image attachments and metadata"
            ],
            "middleware": [
              "Multipart upload middleware configured for images",
              "File size validation middleware (max 5MB for images)",
              "Image MIME type validation middleware",
              "Image malware scanning middleware (optional but recommended)",
              "Authentication middleware for upload endpoints"
            ],
            "shared": [
              "ImageAttachment data model extending FileAttachment with: width, height, thumbnail_path, format",
              "Image validation utility functions",
              "Constants for allowed image MIME types (ALLOWED_IMAGE_MIME_TYPES)",
              "Constants for max image size (MAX_IMAGE_SIZE_BYTES)",
              "Image processing utility functions for thumbnail generation",
              "ImageMetadata interface/type"
            ]
          },
          "testable_properties": [],
          "function_id": "FileUploadService.acceptImageFiles",
          "related_concepts": [
            "image validation",
            "MIME type checking",
            "image format detection",
            "thumbnail generation",
            "image metadata extraction",
            "EXIF data"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_032.3",
          "description": "Accept and process text document uploads including DOC, DOCX, TXT, and Markdown files with content extraction",
          "type": "sub_process",
          "parent_id": "REQ_032",
          "children": [],
          "acceptance_criteria": [
            "System accepts text document formats: .txt, .doc, .docx, .md, .rtf",
            "System validates MIME types: text/plain, application/msword, application/vnd.openxmlformats-officedocument.wordprocessingml.document, text/markdown",
            "Text documents up to 10MB are accepted",
            "System extracts plain text content from DOC/DOCX files",
            "System detects and handles UTF-8, UTF-16, and ASCII encodings",
            "System preserves basic document structure for markdown files",
            "Upload returns document metadata including word count and character count"
          ],
          "implementation": {
            "frontend": [
              "DocumentUploadComponent with document file type filter",
              "Document preview component showing first few lines of text",
              "File icon indicator based on document type",
              "Upload progress indicator",
              "Document metadata display (filename, size, type)",
              "Error handling for unsupported document formats"
            ],
            "backend": [
              "POST /api/attachments/upload endpoint with document handling",
              "Document MIME type validation service",
              "Text extraction service for DOC/DOCX files (using libraries like Apache POI, python-docx, or mammoth)",
              "Text encoding detection service",
              "Document metadata extraction (word count, character count, page count)",
              "Plain text storage for full-text search indexing",
              "Document storage service"
            ],
            "middleware": [
              "Multipart upload middleware for documents",
              "File size validation middleware (max 10MB)",
              "Document MIME type validation middleware",
              "Virus scanning middleware for document files",
              "Authentication and authorization middleware"
            ],
            "shared": [
              "TextDocumentAttachment data model with: text_content, word_count, char_count, encoding, format",
              "Document parsing utility functions",
              "Text encoding detection utilities",
              "Constants for allowed document MIME types (ALLOWED_DOCUMENT_MIME_TYPES)",
              "Constants for max document size (MAX_DOCUMENT_SIZE_BYTES)",
              "DocumentMetadata interface/type"
            ]
          },
          "testable_properties": [],
          "function_id": "FileUploadService.acceptTextDocuments",
          "related_concepts": [
            "document parsing",
            "text extraction",
            "MIME type validation",
            "encoding detection",
            "document conversion",
            "plain text extraction"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_032.4",
          "description": "Validate file MIME types through multiple validation layers including magic number detection and extension verification",
          "type": "sub_process",
          "parent_id": "REQ_032",
          "children": [],
          "acceptance_criteria": [
            "System validates MIME type from Content-Type header",
            "System performs magic number/file signature validation",
            "System detects MIME type mismatches between header, extension, and content",
            "System rejects files with suspicious or mismatched MIME types",
            "System maintains whitelist of allowed MIME types per category",
            "Validation occurs before file storage",
            "System logs MIME type validation failures for security monitoring"
          ],
          "implementation": {
            "frontend": [
              "Client-side file type validation before upload",
              "User-friendly error messages for rejected file types",
              "Visual indicators for allowed file types",
              "File type education tooltips/help text",
              "Validation feedback in real-time as files are selected"
            ],
            "backend": [
              "MIME type validation service using magic number detection (e.g., python-magic, file-type library)",
              "GET /api/attachments/allowed-types endpoint returning allowed MIME types",
              "MIME type whitelist configuration service",
              "File signature validation against known patterns",
              "MIME type mismatch detection logic",
              "Security logging service for validation failures"
            ],
            "middleware": [
              "MIME type validation middleware executed before file processing",
              "Content-Type header validation middleware",
              "File extension validation middleware",
              "Security scanning middleware for potentially dangerous files",
              "Request rejection middleware for invalid MIME types"
            ],
            "shared": [
              "MIME type validation utility functions",
              "File signature/magic number constants",
              "MIME type whitelist configuration (ALLOWED_MIME_TYPES by category)",
              "File extension to MIME type mapping",
              "ValidationResult interface with validation details",
              "FileTypeValidator class/module with validation methods",
              "Security event logging utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "FileValidationService.validateFileMimeTypes",
          "related_concepts": [
            "MIME type detection",
            "magic number validation",
            "file signature",
            "content-type header",
            "file extension verification",
            "security validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_032.5",
          "description": "Process uploaded file content including text extraction, metadata generation, thumbnail creation, and indexing for search",
          "type": "sub_process",
          "parent_id": "REQ_032",
          "children": [],
          "acceptance_criteria": [
            "System extracts searchable text content from all supported file types",
            "System generates thumbnails for images and PDF first pages",
            "System extracts comprehensive metadata (author, creation date, modification date, etc.)",
            "Processing occurs asynchronously without blocking upload response",
            "System indexes file content for full-text search",
            "Processing failures are logged and retried with exponential backoff",
            "System updates attachment record with processing status and results",
            "Processing completes within 30 seconds for 95% of files"
          ],
          "implementation": {
            "frontend": [
              "Processing status indicator in attachment list",
              "Real-time updates via WebSocket or polling for processing completion",
              "Thumbnail display once processing completes",
              "Metadata display panel showing extracted information",
              "Retry button for failed processing",
              "Search interface that queries indexed file content"
            ],
            "backend": [
              "POST /api/attachments/{id}/process endpoint to trigger processing",
              "GET /api/attachments/{id}/status endpoint for processing status",
              "Asynchronous job queue (e.g., Celery, Bull, RabbitMQ)",
              "Text extraction worker for different file types",
              "Thumbnail generation worker using image processing library",
              "Metadata extraction worker",
              "Full-text search indexing service (e.g., Elasticsearch, PostgreSQL full-text search)",
              "Processing status tracking in database",
              "Retry mechanism with exponential backoff"
            ],
            "middleware": [
              "Job queue middleware for asynchronous processing",
              "Processing rate limiting middleware",
              "Authentication middleware for processing endpoints",
              "WebSocket middleware for real-time status updates"
            ],
            "shared": [
              "FileProcessingJob data model with: attachment_id, status, created_at, completed_at, error_message, retry_count",
              "ProcessingStatus enum (PENDING, PROCESSING, COMPLETED, FAILED)",
              "Content extraction utilities for each file type",
              "Thumbnail generation utilities",
              "Metadata extraction utilities",
              "Search index data model with: attachment_id, content, metadata",
              "Job queue configuration and utilities",
              "Retry policy configuration (max_retries, backoff_multiplier)"
            ]
          },
          "testable_properties": [],
          "function_id": "FileProcessingService.processFileContent",
          "related_concepts": [
            "content extraction",
            "metadata generation",
            "full-text indexing",
            "thumbnail generation",
            "file analysis",
            "asynchronous processing",
            "background jobs"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_033",
      "description": "The system must provide visual feedback during audio transcription",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_033.1",
          "description": "Display a visual progress indicator while audio transcription is actively processing, showing the user that the system is working on their audio input",
          "type": "sub_process",
          "parent_id": "REQ_033",
          "children": [],
          "acceptance_criteria": [
            "Progress indicator appears within 200ms of transcription start",
            "Indicator uses animated visual (spinner, progress bar, or pulsing animation)",
            "Indicator is positioned near the audio input component or message area",
            "Indicator includes text label 'Transcribing audio...' or similar",
            "Indicator is accessible with proper ARIA attributes (aria-live, role='status')",
            "Indicator disappears immediately when transcription completes or errors",
            "Indicator does not block user from viewing other content",
            "Indicator maintains visibility even if user scrolls within conversation",
            "Multiple simultaneous transcriptions each show independent indicators"
          ],
          "implementation": {
            "frontend": [
              "LoadingSpinner.svelte component with configurable size and color",
              "TranscriptionProgressIndicator.svelte component wrapping spinner with label",
              "CSS animations for smooth fade-in/fade-out transitions",
              "Zustand or Svelte store for transcription state management",
              "Position indicator near AudioRecorder component or in message input area",
              "ARIA live region implementation for screen reader announcements"
            ],
            "backend": [
              "WebSocket event emitted when transcription starts: { event: 'transcription:started', requestId: string }",
              "Server-sent event (SSE) stream for transcription lifecycle updates"
            ],
            "middleware": [
              "Request validation to ensure transcription request ID is valid",
              "Rate limiting on transcription status polling endpoints"
            ],
            "shared": [
              "TranscriptionStatus enum: IDLE, PROCESSING, COMPLETED, FAILED",
              "TranscriptionState interface: { requestId: string, status: TranscriptionStatus, startTime: number }",
              "formatDuration utility for showing elapsed time if transcription takes >5 seconds"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionUI.showProgressIndicator",
          "related_concepts": [
            "Loading states",
            "User feedback patterns",
            "Real-time status updates",
            "Progressive enhancement",
            "Accessibility (ARIA live regions)"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_033.2",
          "description": "Show detailed status information about the transcription process including current stage, elapsed time, and completion percentage if available",
          "type": "sub_process",
          "parent_id": "REQ_033",
          "children": [],
          "acceptance_criteria": [
            "Status shows current stage: 'Uploading audio', 'Processing', 'Finalizing'",
            "Elapsed time updates every second once transcription exceeds 3 seconds",
            "If API provides progress percentage, display as progress bar (0-100%)",
            "Status text updates reflect actual backend processing stages",
            "Status message is concise (max 50 characters)",
            "Status transitions are smooth without flickering",
            "Status persists in UI history after completion with final duration",
            "Status includes file size for audio files >1MB",
            "Status shows estimated time remaining if API provides this data"
          ],
          "implementation": {
            "frontend": [
              "TranscriptionStatusDisplay.svelte component with multi-stage status rendering",
              "ProgressBar.svelte component for percentage-based progress",
              "Timer component showing elapsed time (MM:SS format)",
              "Status message mapping from backend status codes to user-friendly text",
              "Reactive Svelte stores updating status in real-time",
              "Status badge component with color coding (blue=processing, green=complete, red=error)"
            ],
            "backend": [
              "GET /api/transcriptions/{requestId}/status endpoint returning detailed status",
              "WebSocket events for stage transitions: transcription:uploading, transcription:processing, transcription:finalizing",
              "Status response format: { requestId, stage, progress, elapsedMs, estimatedRemainingMs, fileSize }",
              "Polling endpoint with 304 Not Modified caching for unchanged status"
            ],
            "middleware": [
              "Authentication middleware to ensure user can only access their own transcription status",
              "Response compression for status polling to reduce bandwidth"
            ],
            "shared": [
              "TranscriptionStage enum: UPLOADING, QUEUED, PROCESSING, FINALIZING, COMPLETED, FAILED",
              "TranscriptionStatusResponse interface with all status fields",
              "formatFileSize utility function for human-readable file sizes",
              "calculateProgress utility mapping stage to percentage when API doesn't provide it"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionUI.displayTranscriptionStatus",
          "related_concepts": [
            "Status messaging",
            "Real-time updates",
            "User expectations management",
            "Transparency in AI processing",
            "Progress tracking"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_033.3",
          "description": "Dynamically update the user interface with the transcribed text as it becomes available, either streaming word-by-word or displaying the complete result, and integrate it into the conversation flow",
          "type": "sub_process",
          "parent_id": "REQ_033",
          "children": [],
          "acceptance_criteria": [
            "Transcribed text appears in the message input area when transcription completes",
            "If streaming transcription available, text appears word-by-word with smooth animation",
            "Text replaces the audio recording indicator/placeholder",
            "User can edit the transcribed text before sending",
            "Transcribed text maintains paragraph breaks if detected by transcription service",
            "Special formatting for uncertain words (low confidence) shown with lighter color or [brackets]",
            "Character count updates as transcribed text populates",
            "Auto-focus moves to message input area after transcription completes",
            "Transcribed text is clearly marked as 'Transcribed from audio' with small label",
            "Original audio file remains attached to message unless user removes it",
            "Transcribed text supports undo/redo if user wants to revert changes"
          ],
          "implementation": {
            "frontend": [
              "MessageInput.svelte component modified to accept transcribed text prop",
              "StreamingTextDisplay.svelte for word-by-word rendering if streaming available",
              "TranscriptionLabel.svelte badge component showing 'Transcribed' indicator",
              "Text editor integration with focus management",
              "Confidence highlighting CSS classes for low-confidence words",
              "Character counter component updating reactively",
              "Toast notification confirming transcription completion",
              "Undo/redo button controls in message input area"
            ],
            "backend": [
              "WebSocket streaming endpoint for partial transcription results if Whisper streaming enabled",
              "POST /api/transcriptions/{requestId}/result endpoint returning final transcribed text",
              "Response format: { text, confidence, segments: [{ text, start, end, confidence }] }",
              "Paragraph detection and formatting in transcription post-processing",
              "Confidence threshold configuration (mark words <0.8 confidence as uncertain)"
            ],
            "middleware": [
              "Text sanitization middleware to prevent XSS from transcribed content",
              "Content length validation (enforce max message length)"
            ],
            "shared": [
              "TranscriptionResult interface: { requestId, text, segments, confidence, language, duration }",
              "TranscriptionSegment interface: { text, startMs, endMs, confidence }",
              "insertTranscribedText utility function for textarea insertion",
              "highlightLowConfidence utility to wrap uncertain text in spans",
              "Message interface updated with transcriptionMetadata optional field"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionUI.updateUIWithTranscribedText",
          "related_concepts": [
            "Streaming text updates",
            "Progressive rendering",
            "Text formatting",
            "Message integration",
            "User confirmation workflows",
            "Edit capabilities"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_033.4",
          "description": "Detect, display, and provide recovery options for errors that occur during audio transcription, including upload failures, processing errors, timeout issues, and unsupported formats",
          "type": "sub_process",
          "parent_id": "REQ_033",
          "children": [],
          "acceptance_criteria": [
            "Error message appears within 1 second of error detection",
            "Error message is user-friendly and avoids technical jargon",
            "Error message suggests specific action (retry, check file format, check internet)",
            "Different error types show appropriate messages (network vs. processing vs. format)",
            "Retry button appears for transient errors (network, timeout)",
            "Cancel button allows user to dismiss error and remove audio attachment",
            "Error state clears progress indicator and status display",
            "Audio file remains in UI after error so user can retry with same file",
            "Error details available in console.log for debugging but hidden from user",
            "Error tracking sent to analytics/monitoring service",
            "Maximum 3 automatic retries for network errors with exponential backoff",
            "After 3 failed retries, show 'Contact support' option with error ID",
            "Specific error for unsupported audio formats lists supported formats",
            "Specific error for file too large shows max size limit",
            "Timeout errors show after 60 seconds with option to continue waiting"
          ],
          "implementation": {
            "frontend": [
              "ErrorMessage.svelte component with variants for different error types",
              "RetryButton.svelte with loading state and disabled state after max retries",
              "ErrorToast.svelte for non-blocking error notifications",
              "Error state management in transcription store",
              "Error message mapping from error codes to user-friendly messages",
              "Modal dialog for critical errors requiring user acknowledgment",
              "Support link component with pre-filled error context",
              "Audio file retention in state after error for retry capability"
            ],
            "backend": [
              "Standardized error response format: { error: { code, message, retryable, details } }",
              "Error code constants: UPLOAD_FAILED, PROCESSING_FAILED, TIMEOUT, UNSUPPORTED_FORMAT, FILE_TOO_LARGE",
              "POST /api/transcriptions/{requestId}/retry endpoint for retry attempts",
              "Error logging with request ID, user ID, error type, stack trace",
              "Health check endpoint to detect transcription service availability",
              "File format validation before processing (return early with clear error)",
              "File size validation (max 25MB per Whisper API limits)"
            ],
            "middleware": [
              "Global error handler catching unhandled transcription errors",
              "Error sanitization to prevent sensitive data leakage",
              "Rate limiting on retry attempts (max 3 retries per 5 minutes per user)"
            ],
            "shared": [
              "TranscriptionError interface: { code, message, retryable, timestamp, requestId, details }",
              "TranscriptionErrorCode enum with all error types",
              "isRetryableError utility function determining if error can be retried",
              "formatErrorMessage utility mapping error codes to user messages",
              "SUPPORTED_AUDIO_FORMATS constant array: ['mp3', 'wav', 'm4a', 'ogg', 'webm']",
              "MAX_AUDIO_FILE_SIZE constant: 25MB",
              "TRANSCRIPTION_TIMEOUT constant: 60000ms"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionUI.handleTranscriptionErrors",
          "related_concepts": [
            "Error handling patterns",
            "User error messages",
            "Retry mechanisms",
            "Graceful degradation",
            "Error recovery",
            "User support escalation"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_034",
      "description": "The system must store transcription results for future reference",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_034.1",
          "description": "Save transcribed text to database with proper schema and indexing for efficient retrieval",
          "type": "sub_process",
          "parent_id": "REQ_034",
          "children": [],
          "acceptance_criteria": [
            "Transcription table schema created with fields: id (UUID/auto-increment), transcribed_text (TEXT), created_at (timestamp), updated_at (timestamp)",
            "Database migration script created and executed successfully",
            "Transcription text stored with proper character encoding (UTF-8)",
            "Full-text search index created on transcribed_text field for future search capabilities",
            "Database constraints defined (NOT NULL on required fields, default timestamps)",
            "Save operation returns the generated transcription ID",
            "Save operation handles text of any length (up to database TEXT limit)",
            "Transaction handling ensures atomic save operations",
            "Error handling for database connection failures and constraint violations"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Database model/entity class for Transcription with fields: id, transcribed_text, created_at, updated_at, conversation_id (foreign key), audio_file_id (foreign key), metadata (JSONB)",
              "Repository/DAO layer with saveTranscription(text, conversationId, audioFileId, metadata) method",
              "Database migration script for creating transcriptions table",
              "SQL indexes on: id (primary key), conversation_id (foreign key), created_at (timestamp)",
              "Full-text search index configuration (GIN index for PostgreSQL, FTS5 for SQLite)",
              "Service method to validate and sanitize transcription text before saving",
              "Error handling and logging for database operations"
            ],
            "middleware": [],
            "shared": [
              "Transcription data model/interface with type definitions",
              "Database connection configuration and pooling setup",
              "Common database error handling utilities",
              "Validation schemas for transcription data"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.saveTranscription",
          "related_concepts": [
            "database schema design",
            "text storage",
            "indexing strategy",
            "data persistence",
            "PostgreSQL/SQLite operations"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_034.2",
          "description": "Create and maintain bidirectional relationship between transcription records and conversation entries in the database",
          "type": "sub_process",
          "parent_id": "REQ_034",
          "children": [],
          "acceptance_criteria": [
            "Foreign key relationship established from transcriptions to conversations table",
            "Conversation ID required when saving transcription (NOT NULL constraint)",
            "Association persists transcription_id in conversation_turns or messages table",
            "Cascading delete rules defined (DELETE transcription when conversation deleted, or SET NULL based on retention policy)",
            "Association method validates conversation exists before linking",
            "Single transcription can be associated with exactly one conversation",
            "Multiple transcriptions can be associated with same conversation (one-to-many)",
            "Association timestamp recorded for audit trail",
            "Association retrieval returns full conversation context including all associated transcriptions"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Add conversation_id foreign key column to transcriptions table",
              "Add transcription_id field to conversation_turns/messages table (optional back-reference)",
              "Database migration for adding foreign key constraint with ON DELETE CASCADE/SET NULL",
              "ConversationService.linkTranscription(transcriptionId, conversationId) method",
              "Validation logic to check conversation exists before association",
              "Repository method to query all transcriptions for a given conversation",
              "Service method to create conversation turn entry that includes transcription reference",
              "Transaction wrapper to ensure atomic transcription save + conversation association",
              "Indexes on conversation_id in transcriptions table for efficient lookups"
            ],
            "middleware": [
              "Authorization check to verify user owns the conversation before association",
              "Request validation for conversationId format and existence"
            ],
            "shared": [
              "ConversationTranscription relationship model/interface",
              "Database constraint definitions",
              "Common relationship validation utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationService.associateTranscription",
          "related_concepts": [
            "foreign key relationships",
            "conversation context",
            "data integrity",
            "referential integrity",
            "conversation history"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_034.3",
          "description": "Implement retrieval methods to fetch transcriptions by ID, conversation, or search criteria with proper filtering and pagination",
          "type": "sub_process",
          "parent_id": "REQ_034",
          "children": [],
          "acceptance_criteria": [
            "Method to retrieve single transcription by ID: getTranscriptionById(id)",
            "Method to retrieve all transcriptions for a conversation: getTranscriptionsByConversationId(conversationId, pagination)",
            "Method to search transcriptions by text content: searchTranscriptions(query, filters, pagination)",
            "Pagination support with page number and page size parameters (default 20 per page)",
            "Results include total count for pagination UI",
            "Retrieval methods return null/empty for non-existent records (no exceptions for not found)",
            "Retrieved data includes all fields: id, text, timestamps, conversation_id, metadata",
            "Query performance optimized using appropriate indexes (query execution < 100ms for single record)",
            "Support for filtering by date range (created_at between start_date and end_date)",
            "Support for sorting (by created_at ASC/DESC, relevance for search)"
          ],
          "implementation": {
            "frontend": [
              "TranscriptionList component to display paginated transcriptions",
              "TranscriptionDetail component to show full transcription text",
              "Search input component for transcription search",
              "Pagination controls (previous/next, page numbers)",
              "Date range filter UI component",
              "Loading states for transcription retrieval",
              "Error display for failed retrievals"
            ],
            "backend": [
              "GET /api/transcriptions/:id endpoint",
              "GET /api/conversations/:conversationId/transcriptions endpoint with pagination query params",
              "GET /api/transcriptions/search endpoint with query, page, pageSize, startDate, endDate params",
              "Repository methods: findById(), findByConversationId(), searchByText()",
              "SQL queries with LIMIT/OFFSET for pagination",
              "Full-text search implementation using database-specific features (PostgreSQL ts_vector, SQLite FTS)",
              "Query builder for dynamic filtering based on provided parameters",
              "Result mapping to DTOs/response models",
              "Caching layer for frequently accessed transcriptions (optional)",
              "API response format with data, pagination metadata (total, page, pageSize, totalPages)"
            ],
            "middleware": [
              "Authentication middleware to verify user is logged in",
              "Authorization middleware to verify user has access to requested conversation",
              "Query parameter validation (page > 0, pageSize between 1-100, valid date formats)",
              "Rate limiting for search endpoint to prevent abuse"
            ],
            "shared": [
              "TranscriptionResponse DTO/model",
              "PaginatedResponse wrapper type",
              "SearchQuery type definition with filters",
              "API client methods for transcription retrieval",
              "Pagination utility functions"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionRepository.retrieveTranscription",
          "related_concepts": [
            "data retrieval",
            "query optimization",
            "pagination",
            "filtering",
            "search functionality",
            "API design"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_034.4",
          "description": "Capture and store comprehensive metadata about transcriptions including source file information, processing details, quality metrics, and user context",
          "type": "sub_process",
          "parent_id": "REQ_034",
          "children": [],
          "acceptance_criteria": [
            "Metadata includes: audio_file_id, original_filename, file_size, file_format, duration_seconds",
            "Metadata includes: transcription_service_used (Whisper/Google/Azure), model_version, processing_timestamp",
            "Metadata includes: confidence_score (if provided by transcription service), language_detected",
            "Metadata includes: user_id, session_id, ip_address (for audit)",
            "Metadata includes: error_details (if transcription failed or had issues)",
            "Metadata stored as JSONB field for flexible schema evolution",
            "Metadata automatically populated during transcription save operation",
            "Metadata is queryable (can filter transcriptions by metadata fields)",
            "Metadata includes timestamps: audio_uploaded_at, transcription_started_at, transcription_completed_at",
            "Metadata can be updated after initial save (e.g., adding quality review scores)"
          ],
          "implementation": {
            "frontend": [
              "TranscriptionMetadata display component showing file details",
              "Quality score indicator (confidence score visualization)",
              "Processing time display (upload to completion duration)",
              "Metadata accordion/collapsible section in transcription detail view"
            ],
            "backend": [
              "Add metadata JSONB column to transcriptions table",
              "Database migration for metadata column with GIN index",
              "TranscriptionMetadata data class/model with typed fields",
              "MetadataService.createMetadata() method to collect all metadata",
              "Integration with audio file storage to retrieve file metadata (size, format, duration)",
              "Integration with transcription service response to extract confidence scores",
              "Service method to update metadata: updateTranscriptionMetadata(id, metadataUpdates)",
              "Query methods to filter by metadata fields using JSONB operators",
              "Metadata validation to ensure required fields are present",
              "Automatic metadata population in transcription save workflow"
            ],
            "middleware": [
              "Middleware to extract user context (user_id, session_id, ip_address) from request",
              "Middleware to add processing timestamps to request context"
            ],
            "shared": [
              "TranscriptionMetadata TypeScript/Python interface with all fields",
              "MetadataFieldEnum defining standard metadata keys",
              "Utility functions for metadata extraction from audio files",
              "Utility functions for calculating processing duration",
              "JSON schema for metadata validation"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionMetadataService.trackMetadata",
          "related_concepts": [
            "metadata management",
            "audit trail",
            "transcription quality",
            "file tracking",
            "processing analytics",
            "JSONB storage"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_035",
      "description": "The system must implement error handling for failed transcriptions",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_035.1",
          "description": "Implement comprehensive error catching for all transcription API failures including network errors, API rate limits, invalid audio format errors, and service unavailability",
          "type": "sub_process",
          "parent_id": "REQ_035",
          "children": [],
          "acceptance_criteria": [
            "All Whisper API error types are caught and classified (network, authentication, rate limit, invalid format, timeout)",
            "Network errors are caught and wrapped with context about the failure",
            "API authentication errors are detected and logged with sanitized details",
            "Rate limit errors (429) are caught and return specific error type",
            "Invalid audio format errors are caught and return user-friendly message",
            "Timeout errors after 30 seconds are caught and handled",
            "All caught errors include original error message, timestamp, and request context",
            "Errors are logged with appropriate severity levels (ERROR for API failures, WARN for rate limits)",
            "Error responses include error code, message, and recovery suggestions"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed for this service-layer error handling"
            ],
            "backend": [
              "AudioTranscriptionService.transcribe_audio() method with try-catch blocks",
              "Error classification utility to map API errors to internal error types",
              "TranscriptionError custom exception class with error_code, message, and retry_after fields",
              "Error logging service integration for structured error logs",
              "Error response formatter to sanitize errors before returning to frontend"
            ],
            "middleware": [
              "No middleware changes needed for service-layer error handling"
            ],
            "shared": [
              "TranscriptionErrorType enum (NETWORK_ERROR, AUTH_ERROR, RATE_LIMIT, INVALID_FORMAT, TIMEOUT, UNKNOWN)",
              "TranscriptionError interface with code, message, retry_after, original_error fields",
              "Error classification utilities to map HTTP status codes to error types"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionService.handleTranscriptionError",
          "related_concepts": [
            "error handling",
            "API error types",
            "error classification",
            "exception handling",
            "graceful degradation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_035.2",
          "description": "Display user-friendly error messages in the conversation UI when transcription fails, with contextual information and suggested actions",
          "type": "sub_process",
          "parent_id": "REQ_035",
          "children": [],
          "acceptance_criteria": [
            "Error message component displays in conversation UI when transcription fails",
            "Network errors show message: 'Unable to reach transcription service. Please check your connection.'",
            "Rate limit errors show message: 'Transcription service is busy. Please try again in {retry_after} seconds.'",
            "Invalid format errors show message: 'Audio format not supported. Please use WAV, MP3, or M4A files.'",
            "Timeout errors show message: 'Transcription took too long. Please try with a shorter recording.'",
            "Generic errors show message: 'Transcription failed. Please try again.'",
            "Error messages include icon indicating error severity (warning vs critical)",
            "Error messages include timestamp of when error occurred",
            "Error messages include 'Try Again' button for retryable errors",
            "Error messages include 'Learn More' link to troubleshooting documentation",
            "Error messages are dismissible by user",
            "Error messages auto-dismiss after 10 seconds for non-critical errors",
            "Error state replaces loading spinner in message bubble",
            "Original audio attachment remains visible with error indicator overlay"
          ],
          "implementation": {
            "frontend": [
              "ErrorMessage.svelte component with props for error type, message, retry_after, dismissible",
              "AudioMessage.svelte component with error state rendering",
              "Error icon components for different severity levels",
              "Toast notification component for transient error messages",
              "Error message styling with appropriate colors (amber for warnings, red for critical)",
              "Retry button component with click handler",
              "Error message auto-dismiss timer logic",
              "Error message dismiss button and handler"
            ],
            "backend": [
              "POST /api/transcribe endpoint returns standardized error response structure",
              "Error response includes user_message field with friendly text",
              "Error response includes error_code for frontend logic",
              "Error response includes retry_after field for rate limit errors",
              "Error response includes suggested_actions array for user guidance"
            ],
            "middleware": [
              "No middleware changes needed for error display"
            ],
            "shared": [
              "ErrorResponse interface with user_message, error_code, retry_after, suggested_actions fields",
              "Error message template mapping for each error type",
              "Error severity enum (INFO, WARNING, ERROR, CRITICAL)"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationUI.displayTranscriptionError",
          "related_concepts": [
            "error messaging",
            "user experience",
            "error feedback",
            "UI error states",
            "user guidance"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_035.3",
          "description": "Implement automatic retry logic with exponential backoff for transient transcription failures, and provide manual retry capability for user-triggered retries",
          "type": "sub_process",
          "parent_id": "REQ_035",
          "children": [],
          "acceptance_criteria": [
            "Network errors automatically retry up to 3 times with exponential backoff (1s, 2s, 4s)",
            "Rate limit errors do not auto-retry but respect retry_after header from API",
            "Timeout errors do not auto-retry automatically",
            "Invalid format errors do not retry (permanent failure)",
            "Each retry attempt is logged with attempt number and delay",
            "Retry attempts include original request ID for tracing",
            "User can manually trigger retry via 'Try Again' button in UI",
            "Manual retries do not count against automatic retry limit",
            "Retry state is tracked per audio file (not globally)",
            "Retry attempts stop if user navigates away or cancels",
            "Circuit breaker opens after 5 consecutive failures, preventing retries for 60 seconds",
            "Successful transcription after retry closes circuit breaker",
            "Retry progress is communicated to user via UI loading state",
            "Retry logic implements jitter to prevent thundering herd"
          ],
          "implementation": {
            "frontend": [
              "Retry button component in error message with loading state",
              "Retry progress indicator showing attempt number (e.g., 'Retrying... (2/3)')",
              "Cancel button to abort retry sequence",
              "Retry state management in AudioMessage component",
              "Event handlers for manual retry button click"
            ],
            "backend": [
              "RetryService.retry_with_backoff() utility function",
              "Exponential backoff calculation: delay = base_delay * (2 ** attempt) + jitter",
              "Retry decision logic based on error type",
              "CircuitBreaker class to track failure rates and prevent cascading failures",
              "POST /api/transcribe endpoint supports idempotent retries via request_id",
              "Retry metadata tracking (attempt count, last_attempt_time) in database",
              "Async retry queue for background retry processing",
              "Retry attempt logging with correlation IDs"
            ],
            "middleware": [
              "Idempotency middleware to deduplicate retry requests using request_id header"
            ],
            "shared": [
              "RetryConfig interface with max_attempts, base_delay, max_delay, jitter_factor fields",
              "RetryState interface with attempt_count, next_retry_time, circuit_open fields",
              "isRetryableError() utility function to determine if error should trigger retry",
              "calculateBackoffDelay() utility function for exponential backoff with jitter"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioTranscriptionService.retryTranscription",
          "related_concepts": [
            "retry logic",
            "exponential backoff",
            "circuit breaker",
            "transient failures",
            "idempotency"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_035.4",
          "description": "Implement comprehensive error logging for all transcription failures including error details, context, user information, and audio metadata for debugging and monitoring",
          "type": "sub_process",
          "parent_id": "REQ_035",
          "children": [],
          "acceptance_criteria": [
            "All transcription errors are logged to centralized logging system",
            "Log entries include timestamp, error type, error message, and stack trace",
            "Log entries include user_id (anonymized) and conversation_id for correlation",
            "Log entries include audio file metadata (size, duration, format, sample_rate)",
            "Log entries include request_id for distributed tracing",
            "Log entries include API response details (status code, headers, response body)",
            "Log entries include retry attempt information if applicable",
            "Sensitive information (API keys, user PII) is redacted from logs",
            "Error logs are tagged with severity level (ERROR, WARN, INFO)",
            "Error logs are searchable by error type, user, conversation, and time range",
            "Error logs are retained for 90 days minimum",
            "Critical errors (authentication, service unavailable) trigger alerts",
            "Error log format is JSON for structured querying",
            "Error logs include environment information (production, staging, development)"
          ],
          "implementation": {
            "frontend": [
              "Client-side error tracking integration (e.g., Sentry) for frontend errors",
              "Error boundary component to catch unhandled frontend errors",
              "Client-side error logging includes browser info, screen size, user agent"
            ],
            "backend": [
              "ErrorLoggingService.log_error() method with structured logging",
              "Integration with logging framework (e.g., Python logging, Winston)",
              "Log aggregation service integration (e.g., CloudWatch, Datadog, ELK)",
              "PII redaction utility to sanitize sensitive data before logging",
              "Error log formatter to convert errors to JSON structure",
              "Alert rule configuration for critical error thresholds",
              "Log rotation policy to manage log file sizes",
              "Error metrics collection (error count, error rate by type)",
              "Correlation ID middleware to track requests across services"
            ],
            "middleware": [
              "Request logging middleware to capture all API requests with correlation IDs",
              "Error logging middleware to automatically log uncaught exceptions"
            ],
            "shared": [
              "ErrorLogEntry interface with timestamp, level, message, error_type, context, user_id, request_id, stack_trace fields",
              "LogContext interface with user_id, conversation_id, audio_metadata, environment fields",
              "sanitizeForLogging() utility to redact sensitive fields",
              "ErrorMetrics interface for tracking error counts and rates"
            ]
          },
          "testable_properties": [],
          "function_id": "ErrorLoggingService.logTranscriptionError",
          "related_concepts": [
            "error logging",
            "observability",
            "debugging",
            "error tracking",
            "audit trail",
            "monitoring"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_036",
      "description": "The system must support WebSocket or SSE for real-time updates",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_036.1",
          "description": "Establish and maintain WebSocket connection between client and server with automatic reconnection logic",
          "type": "sub_process",
          "parent_id": "REQ_036",
          "children": [],
          "acceptance_criteria": [
            "WebSocket connection successfully established on client initialization",
            "Connection state (connecting, connected, disconnected, reconnecting) is tracked and exposed",
            "Automatic reconnection occurs with exponential backoff (1s, 2s, 4s, 8s, max 30s) when connection drops",
            "Heartbeat/ping messages sent every 30 seconds to keep connection alive",
            "Connection timeout of 5 seconds before retry attempt",
            "Connection events (onOpen, onClose, onError) are properly handled and logged",
            "Client can manually disconnect and reconnect",
            "Connection URL supports both ws:// and wss:// protocols",
            "Authentication token is included in connection handshake",
            "Connection state changes trigger UI updates (e.g., connection indicator)"
          ],
          "implementation": {
            "frontend": [
              "WebSocketClient class with connection state management",
              "Connection status indicator component in UI header",
              "Event listeners for connection state changes",
              "Reconnection notification/toast messages",
              "Manual reconnect button in connection error state"
            ],
            "backend": [
              "WebSocket server endpoint (e.g., /ws or /api/realtime)",
              "Connection authentication and validation logic",
              "Connection pool/registry to track active clients",
              "Heartbeat/ping handler to respond to client pings",
              "Connection timeout monitoring and cleanup",
              "Graceful shutdown handler to close all connections"
            ],
            "middleware": [
              "JWT token validation in WebSocket handshake",
              "Connection upgrade from HTTP to WebSocket",
              "CORS configuration for WebSocket origins",
              "Rate limiting for connection attempts"
            ],
            "shared": [
              "WebSocketConnectionState enum (CONNECTING, CONNECTED, DISCONNECTING, DISCONNECTED, RECONNECTING)",
              "ConnectionConfig interface with timeout, retry, and heartbeat settings",
              "WebSocketMessage base interface/type",
              "ConnectionError types and error codes"
            ]
          },
          "testable_properties": [],
          "function_id": "WebSocketService.establishConnection",
          "related_concepts": [
            "connection lifecycle",
            "heartbeat/ping-pong",
            "reconnection strategy",
            "connection state management",
            "event emitters"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_036.2",
          "description": "Implement Server-Sent Events (SSE) endpoint for unidirectional real-time updates from server to client",
          "type": "sub_process",
          "parent_id": "REQ_036",
          "children": [],
          "acceptance_criteria": [
            "SSE endpoint established at /api/events or /api/stream",
            "Endpoint returns Content-Type: text/event-stream header",
            "Client successfully creates EventSource connection to endpoint",
            "Server can send events in SSE format: 'event: eventType\\ndata: jsonData\\n\\n'",
            "Multiple event types supported (e.g., 'theme-update', 'transcription-complete', 'generation-progress')",
            "Connection includes authentication via query parameter or Authorization header",
            "Server sends periodic keep-alive comments (e.g., ': keep-alive\\n\\n') every 15 seconds",
            "Client automatically reconnects on connection drop with Last-Event-ID support",
            "Server maintains connection registry for active SSE clients",
            "Graceful cleanup when client disconnects or connection times out",
            "Support for filtering events by conversation/project ID"
          ],
          "implementation": {
            "frontend": [
              "SSEClient class wrapping EventSource API",
              "Event type handlers for different update types",
              "Auto-reconnection logic with EventSource native retry",
              "Event listener registration/unregistration methods",
              "Connection status tracking for SSE",
              "Error handling for EventSource failures"
            ],
            "backend": [
              "SSE endpoint handler with streaming response",
              "Event formatter to convert data to SSE format",
              "Active connection registry with client metadata",
              "Event broadcast service to send to specific clients or all clients",
              "Connection authentication and authorization",
              "Keep-alive scheduler to send periodic comments",
              "Connection cleanup on client disconnect"
            ],
            "middleware": [
              "Authentication middleware for SSE endpoint (token in query param or header)",
              "Connection authorization based on user permissions",
              "Request logging for SSE connections",
              "Connection timeout monitoring"
            ],
            "shared": [
              "SSEEvent interface with event type, data, id, and retry fields",
              "SSEEventType enum (THEME_UPDATE, TRANSCRIPTION_COMPLETE, GENERATION_PROGRESS, etc.)",
              "SSEClientMetadata interface with userId, conversationId, connectedAt",
              "SSEMessage serialization utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "SSEService.createEndpoint",
          "related_concepts": [
            "EventSource API",
            "streaming responses",
            "event types",
            "reconnection handling",
            "content-type text/event-stream"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_036.3",
          "description": "Push real-time updates to connected clients via WebSocket or SSE based on backend events",
          "type": "sub_process",
          "parent_id": "REQ_036",
          "children": [],
          "acceptance_criteria": [
            "Backend events (transcription complete, theme extracted, content generated) trigger client updates",
            "Updates are sent only to relevant clients (filtered by conversationId, projectId, userId)",
            "Message format is consistent and structured (type, payload, timestamp, correlationId)",
            "Updates are sent via active WebSocket connections if available, fallback to SSE",
            "Broadcast to all clients in a conversation/project supported",
            "Unicast to specific client supported",
            "Update rate limiting prevents overwhelming clients (max 10 updates/second per client)",
            "Updates include sequence numbers for ordering and duplicate detection",
            "Failed sends are logged but don't crash the service",
            "Update history buffer maintains last 50 updates per conversation for reconnecting clients",
            "Metrics tracked: updates sent, failed sends, average latency"
          ],
          "implementation": {
            "frontend": [
              "Update handler registry to map update types to handlers",
              "Message parser to deserialize incoming updates",
              "Update sequence tracking to detect gaps or duplicates",
              "UI update components for different update types (transcription display, theme badges, generated content)",
              "Loading states and progress indicators driven by updates",
              "Notification system for important updates"
            ],
            "backend": [
              "Event bus or message queue (e.g., Redis pub-sub, in-memory EventEmitter) to trigger updates",
              "UpdateBroadcaster service to route updates to appropriate clients",
              "Client filter logic based on conversationId, projectId, userId",
              "Update serializer to format messages for transmission",
              "Connection manager to look up active WebSocket/SSE connections",
              "Update buffer/cache for recent updates (Redis or in-memory)",
              "Update sending logic with error handling and retries"
            ],
            "middleware": [
              "Rate limiting per client connection",
              "Update authorization check (ensure client should receive update)",
              "Update transformation/sanitization before sending",
              "Logging middleware for update tracking"
            ],
            "shared": [
              "RealtimeUpdate interface with type, payload, timestamp, conversationId, sequenceNumber",
              "UpdateType enum (TRANSCRIPTION_COMPLETE, THEME_EXTRACTED, GENERATION_PROGRESS, CONTENT_GENERATED, ERROR)",
              "ClientFilter interface with conversationId, projectId, userId arrays",
              "UpdatePayload union type for different update types",
              "Serialization/deserialization utilities for updates"
            ]
          },
          "testable_properties": [],
          "function_id": "RealtimeUpdateService.pushUpdates",
          "related_concepts": [
            "event broadcasting",
            "pub-sub pattern",
            "message routing",
            "client filtering",
            "update serialization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_036.4",
          "description": "Implement comprehensive connection failure handling with fallback strategies and user feedback",
          "type": "sub_process",
          "parent_id": "REQ_036",
          "children": [],
          "acceptance_criteria": [
            "Connection failures are detected and classified (network error, server error, authentication error, timeout)",
            "Different retry strategies applied based on error type (immediate retry for network blip, backoff for server errors, no retry for auth errors)",
            "After 5 consecutive connection failures, circuit breaker opens and stops retry attempts for 60 seconds",
            "User is notified of connection issues with actionable messages ('Connection lost, retrying...', 'Unable to connect, check network')",
            "Degraded mode activated when real-time connection unavailable (fallback to polling every 30 seconds)",
            "Manual reconnect option always available to user",
            "Pending messages queued locally when connection down, sent when reconnected (max queue size: 100 messages)",
            "Connection health metrics exposed (uptime, failure count, last successful connection)",
            "Failed connection attempts logged with error details for debugging",
            "Automatic recovery to full real-time mode when connection re-established",
            "Graceful degradation: app remains functional without real-time updates"
          ],
          "implementation": {
            "frontend": [
              "ConnectionFailureHandler class with retry logic and circuit breaker",
              "Error classification logic based on error type and status codes",
              "Message queue for pending updates during disconnection",
              "Polling fallback mechanism for degraded mode",
              "User notification components (toasts, banners) for connection status",
              "Manual reconnect button in error state",
              "Connection health dashboard in settings/debug panel",
              "Local storage for message queue persistence across page reloads"
            ],
            "backend": [
              "Connection health monitoring endpoint (GET /api/health/realtime)",
              "Error response formatting for connection failures",
              "Server-side logging of connection errors",
              "Polling endpoint for degraded mode (GET /api/updates/poll?since=timestamp)",
              "Connection diagnostics endpoint for troubleshooting",
              "Rate limiting for polling requests to prevent abuse"
            ],
            "middleware": [
              "Error response interceptor to standardize error formats",
              "Authentication error detection and handling",
              "Timeout configuration and enforcement",
              "Connection attempt rate limiting"
            ],
            "shared": [
              "ConnectionError interface with errorType, message, isRetryable, suggestedAction",
              "ConnectionErrorType enum (NETWORK_ERROR, SERVER_ERROR, AUTH_ERROR, TIMEOUT, RATE_LIMIT)",
              "ConnectionHealthMetrics interface with uptime, failureCount, lastConnectedAt, currentState",
              "CircuitBreakerState enum (CLOSED, OPEN, HALF_OPEN)",
              "QueuedMessage interface with message, timestamp, attemptCount, priority"
            ]
          },
          "testable_properties": [],
          "function_id": "ConnectionFailureHandler.handleFailures",
          "related_concepts": [
            "error recovery",
            "exponential backoff",
            "circuit breaker",
            "degraded mode",
            "user notifications"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_037",
      "description": "The system must provide a message input component with text and attachment support",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_037.1",
          "description": "Create a textarea component for multi-line text input with auto-resize, character limit, and keyboard shortcuts (Ctrl+Enter to send)",
          "type": "sub_process",
          "parent_id": "REQ_037",
          "children": [],
          "acceptance_criteria": [
            "Textarea renders with appropriate styling matching the application theme",
            "Textarea auto-resizes vertically as user types, up to a maximum height",
            "Character count displays when approaching/exceeding limit (if configured)",
            "Pressing Ctrl+Enter (or Cmd+Enter on Mac) triggers message submission",
            "Pressing Enter alone creates a new line without submitting",
            "Textarea has appropriate ARIA labels for screen readers",
            "Placeholder text displays when textarea is empty",
            "Textarea maintains focus state after attachment operations",
            "Text content persists if user navigates away and returns (draft saving)",
            "Textarea supports standard text editing operations (copy, paste, undo, redo)"
          ],
          "implementation": {
            "frontend": [
              "MessageInputTextarea.svelte component with bindings for text value",
              "Auto-resize logic using scrollHeight detection",
              "Keyboard event handlers for Ctrl+Enter and Enter key combinations",
              "Character counter component with visual warnings",
              "CSS styles for focus states, borders, and responsive sizing",
              "Accessibility attributes (aria-label, role, aria-multiline)",
              "Draft state management using local storage or component store"
            ],
            "backend": [
              "No direct backend requirements for textarea rendering",
              "Message validation endpoint may enforce text length limits"
            ],
            "middleware": [
              "Input sanitization rules to prevent XSS attacks",
              "Text content validation (length, allowed characters)"
            ],
            "shared": [
              "MessageInputConfig interface defining maxLength, placeholder, rows",
              "TextValidationUtils with functions for sanitization and length checks",
              "KeyboardShortcut constants (SUBMIT_MESSAGE, NEW_LINE)"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageInput.TextareaComponent",
          "related_concepts": [
            "text input",
            "form controls",
            "user input",
            "keyboard navigation",
            "accessibility"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_037.2",
          "description": "Add an attachment button with file picker integration supporting multiple file types (images, documents, audio) and drag-and-drop functionality",
          "type": "sub_process",
          "parent_id": "REQ_037",
          "children": [],
          "acceptance_criteria": [
            "Attachment button displays with clear icon (paperclip or similar)",
            "Clicking button opens native file picker dialog",
            "File picker filters by allowed MIME types (images, PDFs, audio files)",
            "Multiple files can be selected simultaneously in file picker",
            "Drag-and-drop zone highlights when files are dragged over the input area",
            "Dropped files are automatically added to attachment list",
            "Invalid file types show error message and are rejected",
            "File size validation occurs before adding to attachment list",
            "Maximum number of attachments is enforced (e.g., 10 files per message)",
            "Button shows loading state while files are being processed",
            "Button is disabled when maximum attachment limit is reached",
            "Keyboard accessible (can trigger file picker with Enter/Space)"
          ],
          "implementation": {
            "frontend": [
              "AttachmentButton.svelte component with file input element",
              "File picker dialog integration with accept attribute for MIME types",
              "Drag-and-drop event handlers (dragover, dragleave, drop)",
              "Visual feedback for drag-and-drop zone (border highlight, overlay)",
              "File validation logic for type and size checking",
              "Error toast/notification component for invalid files",
              "Loading spinner component for file processing state",
              "Disabled state styling when attachment limit reached"
            ],
            "backend": [
              "GET /api/config/attachments endpoint returning allowed file types and size limits",
              "File validation service for server-side type and size verification"
            ],
            "middleware": [
              "MIME type validation middleware",
              "File size validation middleware (e.g., 10MB per file, 50MB total)",
              "Malware scanning integration for uploaded files (optional)"
            ],
            "shared": [
              "AttachmentConfig interface defining allowedTypes, maxFileSize, maxAttachments",
              "FileValidation utility with functions: validateFileType(), validateFileSize(), validateTotalSize()",
              "MIME type constants (IMAGE_TYPES, DOCUMENT_TYPES, AUDIO_TYPES)",
              "File interface with properties: id, name, size, type, url, uploadStatus"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageInput.AttachmentButton",
          "related_concepts": [
            "file upload",
            "file picker",
            "drag and drop",
            "file type validation",
            "MIME types"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_037.3",
          "description": "Display selected attachments with file previews, file names, sizes, and individual remove buttons with visual feedback",
          "type": "sub_process",
          "parent_id": "REQ_037",
          "children": [],
          "acceptance_criteria": [
            "Each attachment displays in a list or grid format below/beside the textarea",
            "Image files show thumbnail previews (scaled appropriately)",
            "Non-image files show appropriate file type icons (PDF, audio, etc.)",
            "File name is displayed, truncated if too long with tooltip showing full name",
            "File size is displayed in human-readable format (KB, MB)",
            "Each attachment has a remove (X) button clearly visible on hover or always visible",
            "Clicking remove button removes the attachment from the list with confirmation if needed",
            "Upload progress bar displays for each file during upload (0-100%)",
            "Successfully uploaded files show a checkmark or success indicator",
            "Failed uploads show error state with retry option",
            "Audio files show waveform preview or play button (optional)",
            "Attachments can be reordered via drag-and-drop (optional)",
            "Total size of all attachments is displayed",
            "Component is responsive and adapts to mobile screens"
          ],
          "implementation": {
            "frontend": [
              "AttachmentList.svelte component rendering array of File objects",
              "AttachmentItem.svelte component for individual file display",
              "Thumbnail generator for image files using FileReader or canvas",
              "File type icon mapping service (PDF icon, audio icon, etc.)",
              "Progress bar component with animated width transition",
              "Remove button with confirmation dialog component (optional)",
              "File size formatter utility (bytes to KB/MB/GB)",
              "Drag-and-drop reordering logic using sortable library or custom implementation",
              "Responsive grid/list layout using CSS Grid or Flexbox",
              "Empty state message when no attachments are present"
            ],
            "backend": [
              "POST /api/attachments/upload endpoint for file upload with multipart/form-data",
              "GET /api/attachments/:id/thumbnail endpoint for thumbnail generation",
              "DELETE /api/attachments/:id endpoint for removing uploaded files",
              "File storage service (local filesystem, S3, or cloud storage)"
            ],
            "middleware": [
              "Multipart form data parser middleware",
              "File upload progress tracking middleware",
              "Temporary file cleanup middleware for failed uploads"
            ],
            "shared": [
              "FileAttachment interface with properties: id, name, size, type, url, thumbnailUrl, uploadProgress, uploadStatus, errorMessage",
              "FileIconMapper utility mapping MIME types to icon components",
              "FileSizeFormatter utility converting bytes to readable format",
              "UploadStatus enum (PENDING, UPLOADING, COMPLETED, FAILED, CANCELLED)",
              "AttachmentStore for managing attachment state across components"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageInput.AttachmentDisplay",
          "related_concepts": [
            "file preview",
            "thumbnail generation",
            "file metadata",
            "list rendering",
            "user feedback"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_037.4",
          "description": "Submit message with text content and all attached files, handling upload sequencing, error recovery, and optimistic UI updates",
          "type": "sub_process",
          "parent_id": "REQ_037",
          "children": [],
          "acceptance_criteria": [
            "Submit button is disabled while message is being sent",
            "Submit button is disabled if textarea is empty AND no attachments are present",
            "All attachments are uploaded before or during message submission",
            "Message submission uses multipart/form-data or separate attachment + message requests",
            "Upload failures prevent message submission with clear error messaging",
            "Retry mechanism allows re-attempting failed attachment uploads",
            "Optimistic UI update shows message in conversation immediately while uploading",
            "Message shows 'sending' indicator (e.g., spinner, clock icon) during submission",
            "Successfully sent messages show confirmation (e.g., checkmark, timestamp)",
            "Failed messages show error state with retry or delete options",
            "Network errors are handled gracefully with user-friendly error messages",
            "Large files upload with progress tracking visible to user",
            "Message content and attachments are cleared from input after successful submission",
            "Form submission is prevented if attachment size exceeds total limit",
            "Keyboard shortcut (Ctrl+Enter) triggers submission with all attachments"
          ],
          "implementation": {
            "frontend": [
              "MessageInputForm.svelte component wrapping textarea and attachments",
              "Form submission handler with validation logic",
              "File upload queue manager for sequential or parallel uploads",
              "Optimistic message rendering in conversation list",
              "Message sending state management (pending, success, error)",
              "Retry button component for failed submissions",
              "Submit button with loading spinner and disabled state",
              "Error notification component with retry/cancel actions",
              "Progress aggregator showing overall upload progress for multiple files",
              "Form reset logic to clear textarea and attachments after success"
            ],
            "backend": [
              "POST /api/messages endpoint accepting message text and attachment IDs",
              "POST /api/messages/with-attachments endpoint handling multipart form data with text + files",
              "Message creation service orchestrating file uploads and message storage",
              "Attachment association logic linking uploaded files to message records",
              "Transaction management ensuring atomicity (all attachments uploaded or rollback)",
              "Webhook/callback for notifying frontend of message processing completion"
            ],
            "middleware": [
              "Authentication middleware verifying user permissions to send messages",
              "Rate limiting middleware preventing message spam",
              "Request size validation middleware for total payload size",
              "Idempotency middleware preventing duplicate submissions using request IDs"
            ],
            "shared": [
              "MessageSubmitRequest interface with properties: text, attachmentIds, conversationId, timestamp, clientRequestId",
              "MessageSubmitResponse interface with properties: messageId, status, attachments, timestamp, errorDetails",
              "UploadQueue class managing attachment upload sequencing",
              "RetryPolicy interface defining maxRetries, backoffStrategy, retryableErrors",
              "MessageStatus enum (PENDING, SENDING, SENT, FAILED, RETRYING)",
              "ErrorHandler utility with functions: handleNetworkError(), handleValidationError(), shouldRetry()"
            ]
          },
          "testable_properties": [],
          "function_id": "MessageInput.SubmitWithAttachments",
          "related_concepts": [
            "form submission",
            "file upload",
            "multipart request",
            "error handling",
            "optimistic updates",
            "retry logic"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_038",
      "description": "The system must implement conversation list display with sorting",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_038.1",
          "description": "Fetch conversation list from API with pagination support and error handling",
          "type": "sub_process",
          "parent_id": "REQ_038",
          "children": [],
          "acceptance_criteria": [
            "API endpoint returns conversation list with id, title, last_message, updated_at, and participant info",
            "Handles network errors gracefully with user-friendly error messages",
            "Implements loading state while fetching data",
            "Supports pagination or infinite scroll for large conversation lists",
            "Returns 401 for unauthorized requests and redirects to login",
            "Caches conversation list data to reduce unnecessary API calls",
            "Implements retry logic for failed requests with exponential backoff"
          ],
          "implementation": {
            "frontend": [
              "Create ConversationList component with loading skeleton",
              "Implement error boundary for API failures",
              "Add retry button for failed requests",
              "Display loading spinner or skeleton UI during fetch",
              "Handle empty state when no conversations exist"
            ],
            "backend": [
              "Create GET /api/conversations endpoint",
              "Return paginated conversation list with metadata",
              "Include fields: id, title, preview_text, updated_at, participant_count, unread_count",
              "Implement query parameters for pagination (page, limit)",
              "Add filtering support by date range or participant",
              "Optimize database query with proper indexing on updated_at"
            ],
            "middleware": [
              "Verify JWT token authentication",
              "Authorize user access to only their conversations",
              "Rate limit API requests to prevent abuse",
              "Validate pagination parameters"
            ],
            "shared": [
              "Define Conversation interface/type with all required fields",
              "Create ConversationListResponse type for API responses",
              "Define PaginationParams type for query parameters",
              "Create ApiError type for standardized error handling"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationService.fetchConversationList",
          "related_concepts": [
            "API integration",
            "data fetching",
            "error handling",
            "loading states",
            "pagination"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_038.2",
          "description": "Sort conversations by most recent activity with configurable sort options",
          "type": "sub_process",
          "parent_id": "REQ_038",
          "children": [],
          "acceptance_criteria": [
            "Conversations are sorted by updated_at timestamp in descending order by default",
            "Most recent conversation appears at the top of the list",
            "Sorting updates automatically when new messages arrive via WebSocket",
            "Supports alternative sort options (alphabetical, unread first, creation date)",
            "Preserves sort preference in user settings or local storage",
            "Handles conversations with null or missing timestamps gracefully",
            "Sorting performance scales efficiently for 1000+ conversations"
          ],
          "implementation": {
            "frontend": [
              "Implement sort dropdown or toggle in ConversationList header",
              "Create sortConversations utility function with multiple strategies",
              "Update UI immediately when sort order changes",
              "Store sort preference in localStorage or user preferences",
              "Add visual indicator showing current sort method",
              "Implement optimistic updates for real-time message sorting"
            ],
            "backend": [
              "Add ORDER BY updated_at DESC to database query",
              "Create index on conversations.updated_at for query performance",
              "Support sort parameter in API query (?sort=recent|alphabetical|unread)",
              "Update conversation.updated_at when new message is created",
              "Return conversations pre-sorted from API to reduce client-side processing"
            ],
            "middleware": [
              "Validate sort parameter values",
              "Sanitize sort input to prevent SQL injection"
            ],
            "shared": [
              "Define SortOption enum (RECENT, ALPHABETICAL, UNREAD_FIRST, OLDEST_FIRST)",
              "Create sortConversations utility function accepting SortOption",
              "Define ConversationSortConfig type for sort preferences",
              "Create compareConversations comparator function for different sort strategies"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationList.sortByMostRecent",
          "related_concepts": [
            "sorting algorithms",
            "date comparison",
            "user preferences",
            "state management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_038.3",
          "description": "Display conversation titles with proper formatting, truncation, and fallback logic",
          "type": "sub_process",
          "parent_id": "REQ_038",
          "children": [],
          "acceptance_criteria": [
            "Displays conversation title if explicitly set by user",
            "Generates title from participant names when no explicit title exists",
            "Truncates long titles with ellipsis at 50 characters",
            "Shows full title on hover using tooltip",
            "Displays 'Untitled Conversation' for empty or undefined titles",
            "Highlights search terms in title when filtering is active",
            "Updates title in real-time when changed by user or system",
            "Title is accessible to screen readers with proper ARIA labels"
          ],
          "implementation": {
            "frontend": [
              "Create ConversationListItem component for individual conversation",
              "Implement title truncation with CSS text-overflow or utility function",
              "Add tooltip component showing full title on hover",
              "Display icon or badge for group conversations vs. direct messages",
              "Implement title editing inline or via modal dialog",
              "Add search highlight component wrapping matching text",
              "Ensure proper semantic HTML with h2/h3 tags for titles"
            ],
            "backend": [
              "Return conversation.title field in API response",
              "Implement title generation logic: use first 3 participant names",
              "Create PUT /api/conversations/:id endpoint for title updates",
              "Validate title length (max 100 characters)",
              "Store both explicit titles and generated titles separately"
            ],
            "middleware": [
              "Verify user is participant before allowing title edits",
              "Sanitize title input to prevent XSS attacks",
              "Validate title length and character restrictions"
            ],
            "shared": [
              "Create truncateText utility function with configurable length",
              "Define Conversation.title and Conversation.generated_title properties",
              "Create getConversationDisplayTitle function implementing fallback logic",
              "Define MAX_TITLE_LENGTH constant (100 characters)",
              "Create highlightSearchTerm utility for search highlighting"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationListItem.displayConversationTitles",
          "related_concepts": [
            "text rendering",
            "truncation",
            "title generation",
            "UI formatting",
            "accessibility"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_038.4",
          "description": "Display preview of last message with sender info, timestamp, and proper text handling",
          "type": "sub_process",
          "parent_id": "REQ_038",
          "children": [],
          "acceptance_criteria": [
            "Shows last message text truncated to 60 characters",
            "Displays sender name or 'You:' prefix for user's own messages",
            "Shows 'Attachment' or 'Audio message' for non-text messages",
            "Displays relative timestamp (2m ago, 1h ago, Yesterday, Jan 5)",
            "Previews update in real-time when new message arrives",
            "Handles deleted or redacted messages with placeholder text",
            "Shows typing indicator when participant is actively typing",
            "Displays unread message count badge",
            "Applies different styling for unread vs. read conversations"
          ],
          "implementation": {
            "frontend": [
              "Create MessagePreview component showing truncated text",
              "Implement relative timestamp formatter (moment.js or date-fns)",
              "Add unread badge component with count",
              "Display sender name with different color for current user",
              "Show typing indicator animation (three dots)",
              "Add icon for message types (paperclip for attachments, mic for audio)",
              "Apply bold styling to unread conversation titles",
              "Update preview via WebSocket when new messages arrive"
            ],
            "backend": [
              "Include last_message object in conversation API response",
              "Return fields: message_text, sender_name, sender_id, created_at, message_type",
              "Calculate unread_count per conversation for current user",
              "Include is_read boolean flag for last message",
              "Update conversation.updated_at when new message created",
              "Implement GET /api/conversations/:id/typing endpoint for typing status"
            ],
            "middleware": [
              "Filter message content for privacy in previews",
              "Strip HTML/markdown from preview text",
              "Handle permissions for viewing message previews"
            ],
            "shared": [
              "Define MessagePreview interface with text, sender, timestamp, type",
              "Create truncateMessage utility handling special characters",
              "Define formatRelativeTime function for timestamp display",
              "Create MessageType enum (TEXT, ATTACHMENT, AUDIO, IMAGE)",
              "Define getMessagePreviewText function with fallbacks for different message types",
              "Create isUnread utility based on last_read_at timestamp"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationListItem.showMessagePreview",
          "related_concepts": [
            "message preview",
            "text truncation",
            "timestamp formatting",
            "sender attribution",
            "message types"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_038.5",
          "description": "Implement real-time updates for conversation list using WebSocket or polling",
          "type": "sub_process",
          "parent_id": "REQ_038",
          "children": [],
          "acceptance_criteria": [
            "Establishes WebSocket connection on component mount",
            "Listens for 'new_message', 'conversation_updated', 'typing' events",
            "Updates conversation order when new message arrives",
            "Increments unread count for conversations with new messages",
            "Shows typing indicator in real-time when participants type",
            "Handles reconnection automatically after connection drop",
            "Falls back to polling if WebSocket is unavailable",
            "Batches updates to prevent UI thrashing with rapid messages"
          ],
          "implementation": {
            "frontend": [
              "Create WebSocketService for managing socket connections",
              "Implement event listeners for conversation updates",
              "Update local state optimistically before API confirmation",
              "Add reconnection logic with exponential backoff",
              "Display connection status indicator to user",
              "Implement polling fallback with setInterval",
              "Debounce rapid updates to prevent performance issues"
            ],
            "backend": [
              "Set up WebSocket server (Socket.io or native WebSockets)",
              "Emit 'conversation_updated' event when new message created",
              "Emit 'typing' event when user types in conversation",
              "Implement room-based broadcasting per conversation",
              "Create fallback REST endpoint GET /api/conversations/updates",
              "Return incremental updates since last_sync timestamp"
            ],
            "middleware": [
              "Authenticate WebSocket connections with JWT",
              "Authorize users to subscribe only to their conversations",
              "Rate limit WebSocket message frequency"
            ],
            "shared": [
              "Define WebSocketEvent types (NEW_MESSAGE, CONVERSATION_UPDATED, TYPING)",
              "Create ConversationUpdatePayload interface",
              "Define TypingIndicator interface with user_id and conversation_id",
              "Create WebSocketConfig type for connection settings",
              "Define RECONNECT_DELAY and MAX_RECONNECT_ATTEMPTS constants"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationList.handleRealtimeUpdates",
          "related_concepts": [
            "WebSocket",
            "real-time communication",
            "event handling",
            "state synchronization",
            "optimistic updates"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_039",
      "description": "The system must support audio file storage in filesystem or cloud storage",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_039.1",
          "description": "Save uploaded audio files to the local filesystem with organized directory structure, naming conventions, and error handling",
          "type": "sub_process",
          "parent_id": "REQ_039",
          "children": [],
          "acceptance_criteria": [
            "Audio files must be saved to a configurable base directory (e.g., /var/app/audio or ./storage/audio)",
            "Files must be organized in a hierarchical structure (e.g., by date: /YYYY/MM/DD/ or by user: /user_{id}/)",
            "Each file must be saved with a unique filename using UUID or timestamp + random string to prevent collisions",
            "Original file extension must be preserved (.mp3, .wav, .m4a, .ogg, etc.)",
            "File write operations must be atomic (write to temp file, then rename) to prevent partial writes",
            "System must check available disk space before saving (fail if less than configurable threshold, e.g., 1GB)",
            "File permissions must be set appropriately (e.g., 644 for files, 755 for directories)",
            "Function must return the full file path upon successful save",
            "System must handle errors gracefully: disk full, permission denied, invalid path, I/O errors",
            "Saved files must be readable and match the original file size and checksum",
            "Configuration must allow toggling between local and cloud storage without code changes"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend components needed for file saving (handled by backend)",
              "Upload progress indicator should reflect when file is being saved to storage"
            ],
            "backend": [
              "POST /api/audio/upload endpoint to receive audio files via multipart/form-data",
              "FileStorageService.saveAudioToLocalFilesystem(file: UploadedFile, metadata: AudioMetadata) -> FilePath",
              "Create directory structure if it doesn't exist (ensure parent directories)",
              "Generate unique filename using UUID v4 + original extension",
              "Write file to temporary location first (.tmp extension)",
              "Verify file write success (size check, optionally checksum)",
              "Rename temporary file to final filename (atomic operation)",
              "Set file permissions using os.chmod() or equivalent",
              "Check disk space using os.statvfs() or equivalent before writing",
              "Implement retry logic for transient I/O errors (max 3 retries)",
              "Log all file operations (path, size, duration) for audit trail",
              "Clean up temporary files on error",
              "Return structured result: { success: boolean, path: string, error?: string }"
            ],
            "middleware": [
              "Authentication middleware to verify user is authorized to upload files",
              "File type validation middleware to check file extension and MIME type match audio formats",
              "File size validation middleware to enforce maximum upload size (e.g., 100MB)",
              "Rate limiting middleware to prevent abuse (e.g., max 10 uploads per minute per user)",
              "Request logging middleware to track all upload attempts"
            ],
            "shared": [
              "AudioFile data model: { id, filename, originalName, path, size, mimeType, duration, createdAt }",
              "StorageConfig interface: { storageType: 'local' | 'cloud', basePath, maxFileSize, allowedExtensions }",
              "FileValidator utility: validateAudioFile(file) -> { valid: boolean, errors: string[] }",
              "PathBuilder utility: buildStoragePath(userId, date) -> string",
              "FileSystemHelper utility: ensureDirectoryExists(path), checkDiskSpace(path) -> bytes",
              "Constants: ALLOWED_AUDIO_EXTENSIONS = ['.mp3', '.wav', '.m4a', '.ogg', '.flac'], MAX_AUDIO_SIZE = 100MB"
            ]
          },
          "testable_properties": [],
          "function_id": "FileStorageService.saveAudioToLocalFilesystem",
          "related_concepts": [
            "file system operations",
            "directory structure",
            "file naming conventions",
            "error handling",
            "disk space management",
            "file permissions",
            "atomic writes"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_039.2",
          "description": "Upload audio files to Amazon S3 or compatible cloud storage (AWS S3, Google Cloud Storage, Azure Blob Storage) with multipart upload support for large files",
          "type": "sub_process",
          "parent_id": "REQ_039",
          "children": [],
          "acceptance_criteria": [
            "System must support multiple cloud providers via abstraction layer (S3, GCS, Azure Blob)",
            "Upload must use multipart upload for files larger than configurable threshold (e.g., 10MB)",
            "Files must be uploaded to a configurable bucket name with proper access control (private by default)",
            "Object key structure must be consistent with local filesystem structure (e.g., audio/{userId}/{YYYY}/{MM}/{filename})",
            "Upload must include metadata: Content-Type, user ID, upload timestamp, original filename",
            "Files must be encrypted at rest using server-side encryption (SSE-S3 or SSE-KMS)",
            "Upload progress must be trackable for frontend progress bars",
            "System must handle upload failures with automatic retry (exponential backoff, max 3 retries)",
            "Upload must verify success using ETag or checksum comparison",
            "Function must return object URL or key upon successful upload",
            "System must support upload cancellation/cleanup of partial uploads",
            "Configuration must use environment variables for credentials (never hardcode)",
            "Upload timeout must be configurable (default 5 minutes for large files)"
          ],
          "implementation": {
            "frontend": [
              "Upload progress bar component showing percentage and estimated time remaining",
              "Cancel upload button to abort in-progress uploads",
              "Retry button for failed uploads",
              "Storage location indicator (showing whether file is stored locally or in cloud)"
            ],
            "backend": [
              "CloudStorageService.uploadAudioToS3(file: UploadedFile, metadata: AudioMetadata) -> CloudStorageResult",
              "Initialize S3 client with credentials from environment (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION)",
              "Determine upload strategy: simple upload (<10MB) vs multipart upload (>=10MB)",
              "Generate object key using consistent naming: audio/{userId}/{YYYY}/{MM}/{uuid}.{ext}",
              "For simple upload: use putObject() with Content-Type and metadata",
              "For multipart upload: initiate upload, upload parts in parallel, complete upload",
              "Set server-side encryption parameters (SSE-S3 or SSE-KMS)",
              "Set ACL to private by default",
              "Track upload progress using callbacks/events",
              "Verify upload success by comparing ETag or calculating checksum",
              "Implement exponential backoff retry for transient errors (network, throttling)",
              "Clean up failed multipart uploads using abortMultipartUpload()",
              "Return { success: boolean, objectKey: string, url?: string, error?: string }",
              "Support cancellation using AbortController or equivalent",
              "Log all cloud operations for debugging and audit"
            ],
            "middleware": [
              "Same authentication and validation middleware as local storage",
              "Cloud storage health check middleware to verify bucket accessibility before upload",
              "Cost monitoring middleware to track upload volume and estimate costs"
            ],
            "shared": [
              "CloudStorageConfig interface: { provider: 'aws' | 'gcs' | 'azure', bucketName, region, credentials, encryption }",
              "CloudStorageResult type: { success: boolean, objectKey: string, url?: string, provider: string, error?: string }",
              "CloudStorageProvider abstract class with upload(), delete(), generateUrl() methods",
              "S3Provider, GCSProvider, AzureProvider concrete implementations",
              "MultipartUploadManager utility for handling large file uploads",
              "CloudStorageFactory to instantiate correct provider based on configuration",
              "Constants: MULTIPART_THRESHOLD = 10MB, MAX_RETRIES = 3, RETRY_BACKOFF = [1s, 2s, 4s]"
            ]
          },
          "testable_properties": [],
          "function_id": "CloudStorageService.uploadAudioToS3",
          "related_concepts": [
            "cloud storage APIs",
            "S3 SDK integration",
            "multipart upload",
            "bucket configuration",
            "access control",
            "encryption",
            "presigned URLs",
            "cloud provider abstraction"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_039.3",
          "description": "Generate secure, time-limited URLs for accessing stored audio files, supporting both public URLs and presigned URLs with expiration",
          "type": "sub_process",
          "parent_id": "REQ_039",
          "children": [],
          "acceptance_criteria": [
            "For local storage: generate HTTP URLs pointing to file serving endpoint with authentication token",
            "For cloud storage: generate presigned URLs with configurable expiration (default 1 hour, max 24 hours)",
            "URLs must be secure and not expose internal file paths or sensitive information",
            "Generated URLs must include authentication/authorization token for local files",
            "Presigned URLs must work without additional authentication (temporary access)",
            "URL generation must support both download URLs (Content-Disposition: attachment) and streaming URLs",
            "URLs must be validated before serving files (check token expiration, user permissions)",
            "System must track URL generation for audit purposes",
            "URLs must support CDN integration (return CDN URL if configured)",
            "Function must handle different storage backends transparently (local vs cloud)",
            "URL expiration must be enforced on the server side when serving files",
            "Generated URLs must be returned in consistent format across storage types"
          ],
          "implementation": {
            "frontend": [
              "Audio player component that accepts secure URLs and handles authentication",
              "Download button that uses generated download URL with proper filename",
              "URL refresh mechanism when presigned URL is approaching expiration",
              "Error handling for expired or invalid URLs with user feedback"
            ],
            "backend": [
              "GET /api/audio/{audioId}/url endpoint to generate access URL",
              "FileUrlService.generateAccessUrl(audioId: string, options: UrlOptions) -> UrlResult",
              "For local storage: create JWT token containing audioId, userId, expiresAt, permissions",
              "For local storage: generate URL format: https://api.example.com/api/audio/{audioId}/stream?token={jwt}",
              "For cloud storage (S3): use generatePresignedUrl() with expiration time",
              "For cloud storage (GCS): use getSignedUrl() with expiration time",
              "For cloud storage (Azure): use generateBlobSASQueryParameters()",
              "Support URL options: expirationMinutes, downloadMode (attachment vs inline), filename",
              "Implement URL validation endpoint: GET /api/audio/{audioId}/stream validates token before serving",
              "For CDN: return CDN URL + token instead of origin URL",
              "Cache generated URLs temporarily (5 minutes) to reduce API calls",
              "Log URL generation events: who accessed what file, when, expiration time",
              "Return { url: string, expiresAt: timestamp, type: 'presigned' | 'token-based' }"
            ],
            "middleware": [
              "Token validation middleware for local file serving endpoints",
              "URL expiration check middleware to reject expired tokens",
              "CORS middleware to allow audio playback from frontend domain",
              "Rate limiting on URL generation to prevent abuse (e.g., 100 requests per minute per user)"
            ],
            "shared": [
              "UrlOptions interface: { expirationMinutes: number, downloadMode: boolean, customFilename?: string }",
              "UrlResult type: { url: string, expiresAt: Date, type: 'presigned' | 'token-based' }",
              "JwtTokenPayload interface: { audioId: string, userId: string, exp: number, permissions: string[] }",
              "UrlGenerator abstract class with generateUrl() method",
              "LocalUrlGenerator and CloudUrlGenerator concrete implementations",
              "TokenService utility for JWT generation and validation",
              "Constants: DEFAULT_URL_EXPIRATION = 3600 seconds, MAX_URL_EXPIRATION = 86400 seconds"
            ]
          },
          "testable_properties": [],
          "function_id": "FileUrlService.generateAccessUrls",
          "related_concepts": [
            "presigned URLs",
            "URL generation",
            "access control",
            "expiration tokens",
            "CDN integration",
            "security tokens",
            "URL signing"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_039.4",
          "description": "Track and manage comprehensive metadata for all stored audio files including file properties, storage location, processing status, and user associations",
          "type": "sub_process",
          "parent_id": "REQ_039",
          "children": [],
          "acceptance_criteria": [
            "System must persist metadata in database immediately after file storage succeeds",
            "Metadata must include: unique ID, user ID, original filename, stored filename, file size, MIME type, duration, sample rate, bit rate",
            "Metadata must track storage type (local or cloud) and exact storage location (path or object key)",
            "Metadata must include timestamps: uploadedAt, processedAt, lastAccessedAt, expiresAt (for temporary files)",
            "System must extract audio properties: duration, codec, channels, sample rate using audio processing libraries",
            "Metadata must support relationships: user who uploaded, conversation/project association, transcription association",
            "Metadata must track processing status: pending, processing, completed, failed, deleted",
            "System must support metadata queries: find by user, find by date range, find by status, find by project",
            "Metadata updates must be atomic and transaction-safe",
            "System must maintain audit log of all metadata changes (who, what, when)",
            "Metadata must be searchable by filename, date, user, tags",
            "System must support soft delete (mark as deleted, retain metadata for configurable retention period)",
            "Metadata must include file checksum (SHA-256) for integrity verification"
          ],
          "implementation": {
            "frontend": [
              "Audio file list view showing metadata: filename, size, duration, upload date, status",
              "Metadata edit form for updating tags, descriptions, or custom metadata",
              "Search/filter interface for finding audio files by metadata criteria",
              "File details modal showing complete metadata including technical properties",
              "Bulk operations UI for managing multiple files (tag, delete, move)"
            ],
            "backend": [
              "POST /api/audio/{audioId}/metadata endpoint to create/update metadata",
              "GET /api/audio/{audioId}/metadata endpoint to retrieve metadata",
              "GET /api/audio/search endpoint with query parameters for filtering",
              "DELETE /api/audio/{audioId} endpoint for soft delete (updates metadata.deletedAt)",
              "AudioMetadataService.createMetadata(audioFile: AudioFile, storageResult: StorageResult) -> AudioMetadata",
              "AudioMetadataService.updateMetadata(audioId: string, updates: Partial<AudioMetadata>) -> AudioMetadata",
              "AudioMetadataService.extractAudioProperties(filePath: string) -> AudioProperties using ffprobe or librosa",
              "AudioMetadataService.searchMetadata(query: SearchQuery) -> AudioMetadata[]",
              "Calculate file checksum using SHA-256 during or after upload",
              "Create database record with all metadata fields",
              "Update lastAccessedAt timestamp when file is accessed via URL",
              "Implement database indexes on frequently queried fields: userId, uploadedAt, status",
              "Create audit log entries for metadata changes using trigger or application logic",
              "Implement scheduled cleanup job to delete expired files and metadata",
              "Support batch metadata updates for bulk operations"
            ],
            "middleware": [
              "Authorization middleware to ensure users can only access their own metadata (or admin can see all)",
              "Validation middleware for metadata updates (check required fields, data types)",
              "Search query sanitization middleware to prevent SQL injection or NoSQL injection"
            ],
            "shared": [
              "AudioMetadata data model: { id, userId, originalFilename, storedFilename, filePath, objectKey, storageType, fileSize, mimeType, duration, sampleRate, bitRate, channels, codec, checksum, status, uploadedAt, processedAt, lastAccessedAt, expiresAt, deletedAt, tags[], description, conversationId, transcriptionId }",
              "AudioProperties type: { duration: number, codec: string, sampleRate: number, bitRate: number, channels: number }",
              "SearchQuery interface: { userId?, filename?, dateFrom?, dateTo?, status?, tags?, limit, offset }",
              "MetadataAuditLog model: { id, audioId, userId, action: 'create' | 'update' | 'delete', changes: object, timestamp }",
              "AudioMetadataRepository with CRUD and search methods",
              "MetadataExtractor utility using ffprobe or audio library for property extraction",
              "Constants: METADATA_RETENTION_DAYS = 90, MAX_SEARCH_RESULTS = 100"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioMetadataService.trackFileMetadata",
          "related_concepts": [
            "metadata management",
            "database storage",
            "file indexing",
            "search capabilities",
            "audit logging",
            "data relationships",
            "metadata extraction"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_040",
      "description": "The system must maintain context limits for conversation turns",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_040.1",
          "description": "Implement a conversation turn counter that increments with each user message and assistant response, maintaining the count in the conversation state",
          "type": "sub_process",
          "parent_id": "REQ_040",
          "children": [],
          "acceptance_criteria": [
            "Turn counter increments by 1 for each user message added to the conversation",
            "Turn counter increments by 1 for each assistant response added to the conversation",
            "Turn count is persisted in the conversation state/database",
            "Turn count is accessible via API for monitoring and enforcement",
            "Turn count resets to 0 when a new conversation is initiated",
            "Turn count survives application restarts and is loaded from persistent storage",
            "Historical turn count is maintained even after context compression"
          ],
          "implementation": {
            "frontend": [
              "Display current turn count in conversation UI header or metadata panel",
              "Show visual indicator when approaching turn limit (e.g., progress bar, warning message)",
              "Display warning message when turn limit is reached",
              "Provide UI affordance to start new conversation when limit reached"
            ],
            "backend": [
              "Add 'turn_count' field to conversation state model/schema",
              "Implement increment logic in message processing pipeline",
              "Create API endpoint GET /api/conversations/{id}/turns to retrieve turn count",
              "Add turn count to conversation metadata in responses",
              "Implement turn count persistence in database operations",
              "Add turn count to checkpoint/resume state"
            ],
            "middleware": [
              "Add turn count validation in message processing middleware",
              "Include turn count in conversation context passed to LLM",
              "Log turn count changes for auditing purposes"
            ],
            "shared": [
              "Define ConversationMetadata interface with turn_count property",
              "Create TurnCounter utility class with increment/reset methods",
              "Define constants for default turn limits",
              "Create ConversationTurn data model with timestamp and role"
            ]
          },
          "testable_properties": [],
          "function_id": "ConversationTracker.trackTurnCount",
          "related_concepts": [
            "conversation state management",
            "turn-based dialogue systems",
            "session persistence",
            "conversation metadata"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_040.2",
          "description": "Implement enforcement mechanism that prevents conversations from exceeding a configurable maximum context window size, measured in tokens or turn count",
          "type": "sub_process",
          "parent_id": "REQ_040",
          "children": [],
          "acceptance_criteria": [
            "Maximum context window limit is configurable per conversation or globally",
            "System accurately calculates current context window size (tokens or turns)",
            "System prevents adding new messages when limit is reached",
            "System returns clear error message when limit exceeded",
            "System provides warning when approaching limit (e.g., 80% threshold)",
            "Enforcement logic runs before each message is added to context",
            "Different limits can be set for different conversation types or user tiers",
            "Token counting accurately reflects the LLM provider's tokenization method"
          ],
          "implementation": {
            "frontend": [
              "Display context window usage meter (current/maximum)",
              "Show toast notification when approaching limit (80%, 90%)",
              "Disable message input when limit reached",
              "Display error message explaining limit reached and options",
              "Provide button to start new conversation when limit reached",
              "Show token/turn count in real-time as user types"
            ],
            "backend": [
              "Create ContextWindowEnforcer service class",
              "Implement token counting function using tiktoken or provider-specific tokenizer",
              "Add enforcement check in message processing pipeline before LLM invocation",
              "Create API endpoint GET /api/conversations/{id}/context-usage",
              "Implement configurable limit retrieval from database or config",
              "Add enforcement logic in CentralContextStore.add() method",
              "Return 429 status code with appropriate error message when limit exceeded"
            ],
            "middleware": [
              "Add pre-processing middleware to check context limits before message handling",
              "Implement authorization check for limit overrides (admin users)",
              "Add logging for limit enforcement events"
            ],
            "shared": [
              "Define ContextWindowLimit interface with maxTokens, maxTurns, warningThreshold",
              "Create TokenCounter utility with count() method",
              "Define ContextUsage interface with currentTokens, maxTokens, currentTurns, maxTurns, percentageUsed",
              "Create constants for default limits (DEFAULT_MAX_TOKENS = 100000, DEFAULT_MAX_TURNS = 50)",
              "Define ContextLimitExceededError exception class"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextWindowEnforcer.enforceMaximumLimit",
          "related_concepts": [
            "token counting",
            "context window management",
            "LLM token limits",
            "rate limiting",
            "conversation boundaries"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_040.3",
          "description": "Implement context compression strategy that replaces older conversation entries with summaries to reduce token usage while preserving essential information",
          "type": "sub_process",
          "parent_id": "REQ_040",
          "children": [],
          "acceptance_criteria": [
            "Compression triggers automatically when context reaches compression threshold (e.g., 70% of limit)",
            "Older entries beyond a configurable retention window are identified for compression",
            "Selected entries are summarized using LLM while preserving key information",
            "Original entries are replaced with their summaries in the context",
            "Compression maintains conversation coherence and critical details",
            "Most recent N entries are never compressed (configurable retention)",
            "Entries marked as 'important' are exempt from compression",
            "Compression process is idempotent and can be run multiple times",
            "Compressed summaries are stored with metadata indicating compression timestamp"
          ],
          "implementation": {
            "frontend": [
              "Display visual indicator on compressed messages (e.g., 'summarized' badge)",
              "Provide tooltip showing compression timestamp on compressed entries",
              "Show option to view original content if available in archive",
              "Display notification when compression occurs in background"
            ],
            "backend": [
              "Create ContextCompressor service with compress() method",
              "Implement entry selection algorithm based on age and importance",
              "Integrate LLM summarization via BAML function (SummarizeConversationEntry)",
              "Update CentralContextStore to replace entries with summaries",
              "Add compression metadata to ContextEntry model (compressed_at, original_tokens, compressed_tokens)",
              "Implement compression scheduling/triggering in context management pipeline",
              "Create API endpoint POST /api/conversations/{id}/compress to manually trigger compression",
              "Archive original content before compression for potential retrieval"
            ],
            "middleware": [
              "Add background task processing for async compression",
              "Implement compression job queue for handling multiple conversations",
              "Add monitoring/metrics for compression effectiveness (token savings)"
            ],
            "shared": [
              "Define CompressionStrategy interface with compress() method",
              "Create CompressionConfig with retentionCount, compressionThreshold, importanceThreshold",
              "Define CompressedEntry data model extending ContextEntry",
              "Create SummarizationPrompt template for LLM compression",
              "Define constants for compression thresholds and retention policies"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextCompressor.compressOlderEntries",
          "related_concepts": [
            "context summarization",
            "rolling context window",
            "information preservation",
            "LLM-based compression",
            "lossy compression strategies"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_040.4",
          "description": "Implement time-to-live (TTL) based expiration system that automatically removes or archives conversation entries after a configurable duration",
          "type": "sub_process",
          "parent_id": "REQ_040",
          "children": [],
          "acceptance_criteria": [
            "Each context entry has a configurable TTL value (in turns or time duration)",
            "TTL countdown begins when entry is added to context",
            "Entries are marked for removal when TTL reaches zero",
            "Removal process runs automatically on a schedule or per-turn basis",
            "Expired entries are either hard-deleted or soft-deleted (archived)",
            "Different entry types can have different default TTL values",
            "Entries marked as 'persistent' are exempt from TTL expiration",
            "TTL expiration respects entry importance/priority levels",
            "Expiration events are logged for audit purposes"
          ],
          "implementation": {
            "frontend": [
              "Display remaining TTL on context entries (e.g., 'expires in 5 turns')",
              "Show visual indicator on entries approaching expiration",
              "Provide UI to mark entries as persistent (pin/bookmark)",
              "Display notification when entries are automatically removed"
            ],
            "backend": [
              "Add 'ttl' and 'created_at' fields to ContextEntry model",
              "Implement TTLManager service with removeExpired() method",
              "Create scheduled job to run TTL cleanup (e.g., every N turns or every X minutes)",
              "Implement soft-delete logic to archive expired entries",
              "Add entry expiration check in context retrieval methods",
              "Create API endpoint GET /api/conversations/{id}/expired to view expired entries",
              "Implement TTL refresh logic for re-referenced entries",
              "Add TTL configuration per entry type in EntryType enum"
            ],
            "middleware": [
              "Add TTL check middleware in context retrieval pipeline",
              "Implement background cleanup job scheduler",
              "Add audit logging for expiration events"
            ],
            "shared": [
              "Define TTLConfig interface with defaultTTL, expirationUnit (turns/seconds)",
              "Create TTLStatus enum (ACTIVE, EXPIRING_SOON, EXPIRED)",
              "Define EntryLifecycle interface with created_at, ttl, expires_at, is_persistent",
              "Create constants for default TTL values per entry type",
              "Define ExpirationPolicy interface for custom expiration rules"
            ]
          },
          "testable_properties": [],
          "function_id": "TTLManager.removeExpiredEntries",
          "related_concepts": [
            "time-to-live (TTL)",
            "entry lifecycle management",
            "automatic cleanup",
            "retention policies",
            "data archival"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_041",
      "description": "The system must support tiered context views with summary and full content modes",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_041.1",
          "description": "Create a summary-only context view that provides condensed information for the orchestrator LLM, excluding full content details to optimize token usage and focus on high-level decision making",
          "type": "sub_process",
          "parent_id": "REQ_041",
          "children": [],
          "acceptance_criteria": [
            "Summary view contains only entry IDs, types, titles, and brief summaries",
            "Full content is excluded from summary view to reduce payload size",
            "Summary view includes metadata (timestamps, source, relevance scores)",
            "Token count for summary view is at least 70% less than full content view",
            "Orchestrator can make routing decisions based solely on summary information",
            "Summary format is consistent across all entry types",
            "Summary view supports filtering by entry type and time range",
            "Summary includes context relationships (parent/child, dependencies)"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - this is a backend service for LLM consumption"
            ],
            "backend": [
              "WorkingLLMContext.build_summary_view() method to construct summary-only data structure",
              "ContextEntry.get_summary() method to extract summary from each entry",
              "SummaryFormatter service to standardize summary output format",
              "TokenCounter utility to measure and validate token reduction",
              "ViewBuilder.apply_summary_filter() to strip full content from entries",
              "MetadataExtractor to include relevant context metadata in summary"
            ],
            "middleware": [
              "View type validation to ensure summary request is honored",
              "Token limit enforcement for summary views",
              "Caching layer for frequently accessed summary views"
            ],
            "shared": [
              "ContextViewType enum (SUMMARY, FULL)",
              "SummaryEntry data model with id, type, title, summary, metadata fields",
              "ViewConfig interface specifying view type and filtering options",
              "TokenBudget model for tracking token usage across views"
            ]
          },
          "testable_properties": [],
          "function_id": "WorkingLLMContext.build_summary_view",
          "related_concepts": [
            "context compression",
            "token optimization",
            "orchestrator efficiency",
            "summary extraction",
            "tiered information architecture"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_041.2",
          "description": "Create a full content view that provides complete entry details for implementation agents that need access to all information for code generation, testing, and detailed analysis",
          "type": "sub_process",
          "parent_id": "REQ_041",
          "children": [],
          "acceptance_criteria": [
            "Full view includes all entry fields: content, summary, metadata, relationships",
            "Content is returned in its original format without truncation or compression",
            "Full view supports pagination for large content sets",
            "Implementation agents can access complete file contents, command outputs, and task results",
            "Full view includes all context entry relationships and dependencies",
            "Content format is preserved (code syntax, markdown, JSON structure)",
            "Full view supports filtering by entry type while maintaining complete content",
            "Performance remains acceptable even with large content entries (< 2s response time)"
          ],
          "implementation": {
            "frontend": [
              "No frontend components needed - this is a backend service for agent consumption"
            ],
            "backend": [
              "ImplementationContext.build_full_view() method to retrieve complete entries",
              "ContextStore.get_entries_with_content() to fetch full entry data",
              "ContentFormatter service to preserve original content formatting",
              "PaginationService to handle large result sets",
              "RelationshipResolver to include full dependency graph",
              "ContentValidator to ensure data integrity of full entries",
              "CacheStrategy for full content to reduce repeated database queries"
            ],
            "middleware": [
              "Content size validation to prevent excessive payloads",
              "Stream processing for large content entries",
              "Compression middleware for network transfer of large content"
            ],
            "shared": [
              "FullContextEntry data model with all fields (id, type, content, summary, metadata, relationships)",
              "PaginationParams interface (page, page_size, cursor)",
              "ContentFormat enum (CODE, MARKDOWN, JSON, PLAINTEXT)",
              "EntryRelationship model for dependency tracking"
            ]
          },
          "testable_properties": [],
          "function_id": "ImplementationContext.build_full_view",
          "related_concepts": [
            "complete context access",
            "implementation detail preservation",
            "content fidelity",
            "agent-specific views",
            "detailed information retrieval"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_041.3",
          "description": "Implement dynamic context view switching capability allowing agents and orchestrators to toggle between summary and full content modes based on their current task requirements and token budget constraints",
          "type": "sub_process",
          "parent_id": "REQ_041",
          "children": [],
          "acceptance_criteria": [
            "View mode can be switched without reinitializing the context manager",
            "Switch operation completes in less than 500ms",
            "Current view state is tracked and retrievable",
            "View switching preserves applied filters and search criteria",
            "Agents can request view mode change via API parameter",
            "View history is logged for debugging and optimization",
            "Default view mode is configurable per agent type",
            "View switch respects token budget constraints",
            "Switching from summary to full triggers only necessary data fetches (not full reload)"
          ],
          "implementation": {
            "frontend": [
              "ViewModeToggle component for debugging/admin interface",
              "Context viewer panel showing current view mode and statistics",
              "View mode indicator in agent execution logs UI"
            ],
            "backend": [
              "ContextViewManager.switch_view_mode(view_type) method",
              "ViewStateTracker to maintain current view configuration",
              "DeltaFetcher to retrieve only additional data needed when switching to full view",
              "ViewModeResolver to determine appropriate view based on agent type and task",
              "ConfigService.get_default_view_mode(agent_type) for agent-specific defaults",
              "AuditLogger to track view mode switches for analysis",
              "CacheInvalidation service to clear stale view caches on switch"
            ],
            "middleware": [
              "View mode parameter extraction from request headers/params",
              "Token budget middleware to validate view mode against available tokens",
              "View mode response header injection for client state tracking"
            ],
            "shared": [
              "ViewMode enum (SUMMARY, FULL)",
              "ViewSwitchRequest model (target_mode, preserve_filters, reason)",
              "ViewState interface tracking current mode, filters, and timestamp",
              "AgentViewPreferences model for default view configurations",
              "ViewSwitchEvent model for audit logging"
            ]
          },
          "testable_properties": [],
          "function_id": "ContextViewManager.switch_view_mode",
          "related_concepts": [
            "dynamic view selection",
            "mode switching",
            "context adaptation",
            "task-based view selection",
            "runtime view configuration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_041.4",
          "description": "Optimize content delivery by implementing intelligent caching, lazy loading, compression, and selective field retrieval to minimize latency and bandwidth while maintaining data accuracy for both summary and full content views",
          "type": "sub_process",
          "parent_id": "REQ_041",
          "children": [],
          "acceptance_criteria": [
            "Frequently accessed summary views are cached with 5-minute TTL",
            "Full content entries support lazy loading for large content fields",
            "Content compression reduces payload size by at least 50% for text content",
            "Cache hit rate exceeds 60% for summary views",
            "Selective field retrieval allows requesting specific fields only",
            "Response time for cached summary views is under 100ms",
            "Response time for full content views is under 2 seconds",
            "Compression/decompression overhead is under 50ms",
            "Stale cache entries are invalidated within 30 seconds of updates",
            "Optimization decisions are logged for performance analysis"
          ],
          "implementation": {
            "frontend": [
              "ProgressIndicator component for lazy-loading full content",
              "CacheStatusDisplay for debugging view showing cache hits/misses",
              "Content loading skeleton states for improved perceived performance"
            ],
            "backend": [
              "ContentDeliveryOptimizer.optimize_response() main optimization orchestrator",
              "CacheManager with Redis/in-memory caching for summary views",
              "LazyContentLoader to defer loading of large content fields",
              "CompressionService (gzip/brotli) for payload compression",
              "FieldSelector to retrieve only requested fields from storage",
              "CacheInvalidationService to expire stale entries on updates",
              "PerformanceMonitor to track response times and cache statistics",
              "ContentSizeAnalyzer to identify optimization candidates",
              "PrefetchingStrategy to preload likely-needed content"
            ],
            "middleware": [
              "Response compression middleware (gzip/brotli)",
              "ETag generation and validation for cache control",
              "Conditional request handling (If-None-Match, If-Modified-Since)",
              "Field selection parameter parsing from query strings",
              "Cache-Control header injection based on content type"
            ],
            "shared": [
              "CacheConfig model (ttl, max_size, eviction_policy)",
              "OptimizationMetrics interface (cache_hit_rate, compression_ratio, response_time)",
              "FieldSelection model for specifying requested fields",
              "CompressionOptions interface (algorithm, level, min_size)",
              "CacheKey generator utility for consistent cache key construction",
              "PerformanceThresholds constants for monitoring alerts"
            ]
          },
          "testable_properties": [],
          "function_id": "ContentDeliveryOptimizer.optimize_response",
          "related_concepts": [
            "performance optimization",
            "caching strategy",
            "lazy loading",
            "data compression",
            "network efficiency",
            "selective loading"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_042",
      "description": "The system must implement requirement decomposition using Claude LLM",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_042.1",
          "description": "Send raw text content to Claude API using the Claude agent SDK with proper authentication, timeout handling, and retry logic for requirement extraction",
          "type": "sub_process",
          "parent_id": "REQ_042",
          "children": [],
          "acceptance_criteria": [
            "Function must accept research content string as input parameter",
            "Function must validate that research content is not empty before sending to API",
            "Function must use run_claude_sync() from claude_runner.py with proper timeout (1300s for extraction)",
            "Function must include extraction prompt template that mandates extracting 2-5 requirements per section",
            "Function must set stream=False to enable JSON parsing of response",
            "Function must handle API timeout errors and return structured error response",
            "Function must handle API authentication failures and return error with helpful message",
            "Function must handle rate limiting with exponential backoff retry strategy",
            "Function must return ClaudeResult with success boolean, output text, error message, and elapsed time",
            "Function must emit progress callback messages during execution if callback provided",
            "Function must log API call duration and token usage for monitoring"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Claude API client wrapper function in planning_pipeline/decomposition.py",
              "Prompt template builder for extraction in planning_pipeline/decomposition.py",
              "API result parser for JSON extraction from response",
              "Error handler for API failures with structured error codes",
              "Timeout manager with configurable timeout values",
              "Progress callback emitter for status updates"
            ],
            "middleware": [
              "API authentication validator using claude_agent_sdk credentials",
              "Request rate limiter to prevent API quota exhaustion",
              "Response validator to ensure JSON format compliance"
            ],
            "shared": [
              "ClaudeResult data model with success, output, error, elapsed fields",
              "DecompositionError data model with error_code enum and details",
              "API timeout configuration constants (default 1300s for extraction)",
              "Prompt template constants for requirement extraction"
            ]
          },
          "testable_properties": [],
          "function_id": "ClaudeAPIClient.sendRawTextToAPI",
          "related_concepts": [
            "Claude Agent SDK",
            "Async/Await Pattern",
            "API Authentication",
            "Timeout Management",
            "Error Handling",
            "Streaming Response",
            "Rate Limiting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_042.2",
          "description": "Parse Claude API JSON response to extract structured requirement objects with descriptions, sub-processes, and related concepts, validating schema compliance",
          "type": "sub_process",
          "parent_id": "REQ_042",
          "children": [],
          "acceptance_criteria": [
            "Function must accept Claude API response text as input",
            "Function must use _extract_json() helper to find JSON object boundaries in response",
            "Function must parse JSON using json.loads() with proper error handling",
            "Function must validate response has 'requirements' array at top level",
            "Function must validate each requirement has 'description' field with minimum 25 characters",
            "Function must extract 'sub_processes' array (can be empty) for each requirement",
            "Function must extract 'related_concepts' array (can be empty) for each requirement",
            "Function must validate metadata section exists with baml_validated, schema_version, llm_model fields",
            "Function must return DecompositionError with INVALID_JSON error code if parsing fails",
            "Function must return DecompositionError with CONVERSION_ERROR if schema validation fails",
            "Function must track extraction statistics (requirements_found, extraction_time_ms)",
            "Function must log validation failures with specific field details for debugging"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "JSON extractor helper function _extract_json() to find JSON boundaries",
              "JSON parser with try-catch for JSONDecodeError handling",
              "Schema validator to verify requirements array structure",
              "Requirement object builder to construct RequirementNode from JSON",
              "Statistics tracker for extraction metrics",
              "Error logger for validation failures"
            ],
            "middleware": [
              "JSON schema validator for response structure",
              "Field-level validator for requirement descriptions (min 25 chars)",
              "Array validator for sub_processes and related_concepts"
            ],
            "shared": [
              "RequirementNode data model with id, description, sub_processes fields",
              "DecompositionError model with INVALID_JSON and CONVERSION_ERROR codes",
              "DecompositionStats model with requirements_found, extraction_time_ms fields",
              "JSON schema definition for requirement extraction response"
            ]
          },
          "testable_properties": [],
          "function_id": "RequirementExtractor.extractStructuredRequirements",
          "related_concepts": [
            "JSON Parsing",
            "Schema Validation",
            "Data Transformation",
            "Error Recovery",
            "BAML Response Types",
            "Requirement Data Models"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_042.3",
          "description": "Construct 3-tier RequirementHierarchy with parent requirements, sub-process children, and implementation detail nodes using LLM expansion for each requirement",
          "type": "sub_process",
          "parent_id": "REQ_042",
          "children": [],
          "acceptance_criteria": [
            "Function must initialize RequirementHierarchy with empty requirements list and metadata",
            "Function must iterate through each extracted requirement from Claude response",
            "Function must generate unique parent IDs using format REQ_XXX (e.g., REQ_001, REQ_002)",
            "Function must create parent RequirementNode with type='parent' for each requirement",
            "Function must call LLM expansion for each parent requirement to get implementation details",
            "Function must create child nodes with IDs format PARENT_ID.N (e.g., REQ_001.1, REQ_001.2)",
            "Function must set child nodes with type='sub_process' and parent_id reference",
            "Function must extract ImplementationComponents (frontend, backend, middleware, shared) from expansion response",
            "Function must invoke save_callback after each requirement is fully processed for incremental persistence",
            "Function must handle LLM expansion failures gracefully with fallback to BAML/Ollama",
            "Function must track hierarchy statistics (total_nodes, subprocesses_expanded)",
            "Function must store statistics in hierarchy metadata for downstream pipeline access"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "RequirementHierarchy initializer with metadata",
              "Parent node generator with unique ID creation (REQ_XXX format)",
              "LLM expansion caller using run_claude_sync() for implementation details",
              "Child node builder with hierarchical ID generation (PARENT_ID.N)",
              "ImplementationComponents extractor from LLM expansion JSON",
              "Fallback processor using BAML ProcessGate1SubprocessDetailsPrompt",
              "Incremental save callback invoker after each requirement",
              "Statistics aggregator for hierarchy metadata"
            ],
            "middleware": [
              "LLM expansion prompt validator for subprocess expansion",
              "JSON parser for expansion response with fallback handling",
              "Child node relationship validator (parent_id references)"
            ],
            "shared": [
              "RequirementHierarchy data model with requirements list and metadata dict",
              "RequirementNode data model with id, description, type, children, parent_id fields",
              "ImplementationComponents data model with frontend, backend, middleware, shared arrays",
              "Hierarchical ID generator utility for parent and child IDs",
              "SaveCallback type alias for incremental persistence function",
              "DecompositionStats model with total_nodes, subprocesses_expanded fields"
            ]
          },
          "testable_properties": [],
          "function_id": "HierarchyBuilder.buildHierarchicalStructure",
          "related_concepts": [
            "Tree Data Structure",
            "Parent-Child Relationships",
            "Hierarchical IDs",
            "Iterative Processing",
            "LLM Expansion",
            "Incremental Saving",
            "Context Management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_042.4",
          "description": "Serialize the complete RequirementHierarchy tree structure with all parent-child relationships, implementation components, and metadata into a structured return format",
          "type": "sub_process",
          "parent_id": "REQ_042",
          "children": [],
          "acceptance_criteria": [
            "Function must return RequirementHierarchy object on successful decomposition",
            "Function must return DecompositionError object on any failure (empty content, API error, JSON parse error)",
            "Return type must be Union[RequirementHierarchy, DecompositionError] for type safety",
            "RequirementHierarchy must include all parent nodes with complete child trees",
            "Each RequirementNode must have valid parent_id references for children",
            "Hierarchy metadata must include source='agent_sdk_decomposition' and research_length",
            "Hierarchy metadata must include decomposition_stats dictionary with all metrics",
            "Statistics must include requirements_found, subprocesses_expanded, total_nodes, extraction_time_ms, expansion_time_ms",
            "Function must validate hierarchy integrity before return (no orphaned nodes, valid IDs)",
            "Function must handle errors during serialization with proper error codes",
            "DecompositionError must include error_code, error message, and optional details dict"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Hierarchy serializer to prepare complete tree structure",
              "Tree integrity validator to check parent-child references",
              "Metadata enricher to add decomposition_stats to hierarchy",
              "Statistics calculator for final metrics (total_nodes, time_ms)",
              "Return type constructor for Union[RequirementHierarchy, DecompositionError]",
              "Error handler for serialization failures"
            ],
            "middleware": [
              "Hierarchy integrity validator for orphaned nodes check",
              "ID reference validator for parent_id consistency",
              "Metadata schema validator for required fields"
            ],
            "shared": [
              "RequirementHierarchy data model with requirements list, metadata dict, add_requirement() method",
              "DecompositionError data model with error_code, error, details fields",
              "Union type definition for return type safety",
              "Metadata schema with source, research_length, decomposition_stats fields",
              "DecompositionStats complete structure with all time and count metrics"
            ]
          },
          "testable_properties": [],
          "function_id": "RequirementHierarchy.returnRequirementTree",
          "related_concepts": [
            "Data Serialization",
            "Tree Traversal",
            "Return Type Validation",
            "Success/Error Handling",
            "Type Unions",
            "Metadata Enrichment"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_043",
      "description": "The system must categorize requirements into functional, non-functional, security, and integration types",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_043.1",
          "description": "Analyze requirements text/audio transcriptions to identify and extract functional features (user-facing capabilities, behaviors, and actions the system must perform)",
          "type": "sub_process",
          "parent_id": "REQ_043",
          "children": [],
          "acceptance_criteria": [
            "System can parse raw text input and identify statements describing system behaviors or capabilities",
            "System can distinguish functional features from non-functional attributes with >90% accuracy",
            "System extracts verb-noun pairs indicating actions (e.g., 'upload file', 'transcribe audio', 'generate content')",
            "System categorizes features by domain area (e.g., 'audio processing', 'content generation', 'user management')",
            "System handles both explicit feature statements and implicit requirements from user descriptions",
            "System integrates with CategoryFunctionalSchema.baml for structured output",
            "System returns hierarchical feature tree with parent-child relationships",
            "System identifies acceptance criteria within feature descriptions",
            "System handles transcribed audio input with same accuracy as text input",
            "System stores extracted features in Context Window Array with appropriate metadata"
          ],
          "implementation": {
            "frontend": [
              "Feature display component showing categorized functional requirements in collapsible tree view",
              "Visual indicators differentiating functional vs non-functional requirements (icons, colors)",
              "Feature detail panel showing description, acceptance criteria, and related concepts",
              "Filter/search interface for finding specific functional features",
              "Real-time feature extraction progress indicator during analysis"
            ],
            "backend": [
              "POST /api/requirements/analyze endpoint accepting text or transcription_id",
              "FunctionalFeatureExtractor service using BAML + Claude for NLP analysis",
              "Feature classification algorithm using CategoryFunctionalSchema.baml patterns",
              "Verb-noun extraction logic using POS tagging or LLM-based parsing",
              "Feature hierarchy builder constructing parent-child relationships",
              "Integration with decomposition.py for requirement decomposition pipeline",
              "Context storage service saving extracted features to CWA with EntryType.SUMMARY",
              "Confidence scoring mechanism for classification accuracy"
            ],
            "middleware": [
              "Input validation ensuring text length limits (e.g., max 50,000 chars per request)",
              "Rate limiting on analysis endpoint (max 10 requests per minute per user)",
              "Authentication check requiring valid user session",
              "Content sanitization removing potentially harmful input",
              "Request timeout handling (max 120s for complex analysis)"
            ],
            "shared": [
              "FunctionalFeature data model with fields: id, text, category, confidence, parent_id, children[], acceptance_criteria[]",
              "RequirementType enum: FUNCTIONAL, NON_FUNCTIONAL, SECURITY, INTEGRATION",
              "FeatureCategory enum: AUDIO_PROCESSING, CONTENT_GENERATION, USER_MANAGEMENT, FILE_HANDLING, etc.",
              "CategoryAnalysisResult interface matching BAML schema output structure",
              "Feature tree builder utility function",
              "Text preprocessing utilities (tokenization, normalization)"
            ]
          },
          "testable_properties": [],
          "function_id": "CategoryAnalyzer.identifyFunctionalFeatures",
          "related_concepts": [
            "functional requirements classification",
            "feature extraction",
            "user story analysis",
            "capability mapping",
            "BAML schema integration",
            "theme categorization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_043.2",
          "description": "Identify and extract non-functional quality attributes (performance, usability, reliability, scalability, maintainability) from requirements text and audio transcriptions",
          "type": "sub_process",
          "parent_id": "REQ_043",
          "children": [],
          "acceptance_criteria": [
            "System identifies performance requirements (response time, throughput, latency targets)",
            "System extracts usability attributes (accessibility, learnability, user experience expectations)",
            "System detects reliability requirements (uptime, fault tolerance, error handling)",
            "System recognizes scalability needs (concurrent users, data volume, load patterns)",
            "System identifies maintainability attributes (code quality, documentation, testability)",
            "System maps quality attributes to ISO 25010 or similar quality frameworks",
            "System extracts measurable metrics from qualitative statements (e.g., 'fast' \u2192 '<2s response time')",
            "System distinguishes implicit quality expectations from explicit requirements",
            "System associates quality attributes with related functional features",
            "System uses CategoryNonFunctionalSchema.baml for structured categorization"
          ],
          "implementation": {
            "frontend": [
              "Quality attributes dashboard showing metrics by category (performance, usability, reliability)",
              "Visual metric cards displaying extracted quantitative targets (e.g., '< 2s load time', '99.9% uptime')",
              "Quality attribute editor allowing users to refine or add metrics",
              "Association view linking quality attributes to functional features",
              "Quality score indicator showing completeness of non-functional requirements"
            ],
            "backend": [
              "POST /api/requirements/quality-attributes endpoint for extraction",
              "QualityAttributeExtractor service using CategoryNonFunctionalSchema.baml",
              "Metric extraction algorithm parsing quantitative values from text (regex + LLM)",
              "Quality framework mapper (maps extracted attributes to ISO 25010 categories)",
              "Implicit requirement detector identifying unstated quality expectations",
              "Association service linking quality attributes to functional features via context",
              "Quality completeness analyzer checking coverage across quality dimensions",
              "Integration with CategoryPerformanceSchema.baml and CategoryUsabilitySchema.baml for specialized analysis"
            ],
            "middleware": [
              "Input validation ensuring quality attribute extraction requests include context",
              "Authorization check for quality attribute modification operations",
              "Caching layer for frequently analyzed requirement patterns",
              "Request throttling (max 20 quality extractions per minute)"
            ],
            "shared": [
              "QualityAttribute data model: id, category, subcategory, description, metric_value, metric_unit, target_threshold, priority",
              "QualityCategory enum: PERFORMANCE, USABILITY, RELIABILITY, SCALABILITY, MAINTAINABILITY, PORTABILITY, SECURITY_QUALITY",
              "MetricExtractor utility parsing quantitative values from text",
              "ISO25010Mapper utility mapping attributes to standard framework",
              "QualityCompleteness calculator checking coverage",
              "AttributeAssociation model linking quality attributes to features"
            ]
          },
          "testable_properties": [],
          "function_id": "QualityAttributeExtractor.extractQualityAttributes",
          "related_concepts": [
            "non-functional requirements",
            "quality attributes",
            "ISO 25010 quality model",
            "performance metrics",
            "usability heuristics",
            "reliability patterns",
            "CategoryNonFunctionalSchema integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_043.3",
          "description": "Analyze requirements to identify security-related needs including authentication, authorization, data protection, privacy, compliance, and threat mitigation requirements",
          "type": "sub_process",
          "parent_id": "REQ_043",
          "children": [],
          "acceptance_criteria": [
            "System detects authentication requirements (login methods, MFA, session management)",
            "System identifies authorization needs (role-based access, permissions, resource controls)",
            "System extracts data protection requirements (encryption at rest/transit, data masking)",
            "System recognizes privacy requirements (PII handling, consent management, data retention)",
            "System identifies compliance needs (GDPR, HIPAA, SOC2, industry standards)",
            "System detects threat mitigation requirements (input validation, XSS prevention, SQL injection protection)",
            "System maps security requirements to OWASP Top 10 or similar frameworks",
            "System identifies both explicit security statements and implicit security implications",
            "System uses CategorySecuritySchema.baml for structured security categorization",
            "System prioritizes security requirements by risk level (critical, high, medium, low)"
          ],
          "implementation": {
            "frontend": [
              "Security requirements dashboard categorized by type (auth, encryption, compliance)",
              "Risk level indicators with color coding (red=critical, yellow=high, etc.)",
              "Security requirement cards showing threat context and mitigation approach",
              "Compliance checklist view mapping requirements to regulatory standards",
              "Security coverage heat map showing which features have security requirements defined",
              "Threat modeling visualizer linking requirements to potential vulnerabilities"
            ],
            "backend": [
              "POST /api/requirements/security endpoint for security analysis",
              "SecurityAnalyzer service using CategorySecuritySchema.baml",
              "Authentication requirement detector identifying login, MFA, session patterns",
              "Authorization pattern extractor identifying RBAC, ABAC, permission needs",
              "Data protection analyzer detecting encryption, masking, anonymization requirements",
              "Compliance mapper identifying regulatory requirements (GDPR keywords, HIPAA triggers)",
              "Threat pattern matcher mapping requirements to OWASP Top 10 categories",
              "Risk scoring algorithm assigning priority levels based on threat context",
              "Integration with existing decomposition pipeline for security requirement decomposition"
            ],
            "middleware": [
              "Authentication required for security analysis endpoints",
              "Authorization check ensuring only users with security roles can modify security requirements",
              "Audit logging for all security requirement modifications",
              "Input sanitization preventing injection attacks in requirement text",
              "Rate limiting on security analysis (max 5 requests per minute to prevent enumeration)"
            ],
            "shared": [
              "SecurityRequirement data model: id, category, subcategory, description, threat_context, mitigation_approach, risk_level, compliance_references[], related_feature_ids[]",
              "SecurityCategory enum: AUTHENTICATION, AUTHORIZATION, DATA_PROTECTION, PRIVACY, COMPLIANCE, THREAT_MITIGATION, AUDIT_LOGGING",
              "RiskLevel enum: CRITICAL, HIGH, MEDIUM, LOW, INFO",
              "ComplianceFramework enum: GDPR, HIPAA, SOC2, PCI_DSS, ISO27001",
              "OWASPMapper utility mapping requirements to OWASP categories",
              "RiskScorer utility calculating priority scores"
            ]
          },
          "testable_properties": [],
          "function_id": "SecurityAnalyzer.detectSecurityRequirements",
          "related_concepts": [
            "security requirements",
            "authentication mechanisms",
            "authorization patterns",
            "data encryption",
            "privacy regulations (GDPR, HIPAA)",
            "threat modeling",
            "CategorySecuritySchema integration",
            "OWASP guidelines"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_043.4",
          "description": "Identify and catalog all integration points including external APIs, third-party services, data sources, authentication providers, and system interfaces required by the requirements",
          "type": "sub_process",
          "parent_id": "REQ_043",
          "children": [],
          "acceptance_criteria": [
            "System identifies external API requirements (REST, GraphQL, gRPC endpoints)",
            "System extracts third-party service dependencies (Whisper API, payment gateways, analytics)",
            "System detects data source integrations (databases, file storage, message queues)",
            "System recognizes authentication provider integrations (OAuth providers, SAML IdP, SSO)",
            "System identifies webhook and event-driven integration requirements",
            "System catalogs integration protocols and data formats (JSON, XML, protobuf)",
            "System extracts API authentication requirements (API keys, OAuth tokens, certificates)",
            "System identifies data synchronization and consistency requirements",
            "System maps integration dependencies between components",
            "System uses CategoryIntegrationSchema.baml for structured integration categorization",
            "System identifies rate limits, quotas, and SLA requirements for integrations"
          ],
          "implementation": {
            "frontend": [
              "Integration map visualization showing all external dependencies with connection types",
              "Integration point cards displaying service name, protocol, authentication method, and status",
              "Dependency graph showing relationships between components and external services",
              "Integration configuration panel for managing API keys and credentials (masked display)",
              "Integration health dashboard showing connection status and error rates",
              "Filter/search for integrations by type (API, database, authentication, storage)"
            ],
            "backend": [
              "POST /api/requirements/integrations endpoint for integration point extraction",
              "IntegrationMapper service using CategoryIntegrationSchema.baml",
              "API requirement detector identifying REST/GraphQL/gRPC mentions and patterns",
              "Service dependency extractor recognizing third-party service names (Stripe, Twilio, AWS, etc.)",
              "Authentication provider detector identifying OAuth, SAML, SSO requirements",
              "Data source analyzer detecting database, cache, storage integration needs",
              "Protocol parser extracting communication protocols and data formats",
              "Dependency graph builder creating relationships between integrations and features",
              "Integration requirement validator checking completeness (auth method, error handling, etc.)",
              "SLA extractor identifying rate limits and availability requirements"
            ],
            "middleware": [
              "Authentication required for integration management endpoints",
              "Authorization check limiting integration configuration to admin users",
              "Credential encryption for stored API keys and tokens",
              "Audit logging for all integration configuration changes",
              "Input validation for API endpoints and configuration values",
              "Rate limiting on integration discovery (max 10 requests per minute)"
            ],
            "shared": [
              "IntegrationPoint data model: id, name, type, protocol, authentication_method, endpoint_url, data_format, rate_limit, sla_requirements, related_feature_ids[], configuration_schema",
              "IntegrationType enum: REST_API, GRAPHQL_API, GRPC_API, DATABASE, MESSAGE_QUEUE, FILE_STORAGE, AUTHENTICATION_PROVIDER, WEBHOOK, EVENT_STREAM",
              "AuthenticationMethod enum: API_KEY, OAUTH2, BASIC_AUTH, BEARER_TOKEN, SAML, CERTIFICATE, NONE",
              "DataFormat enum: JSON, XML, PROTOBUF, CSV, BINARY, MULTIPART",
              "IntegrationStatus enum: CONFIGURED, PENDING, ERROR, DISABLED",
              "DependencyGraph utility building integration relationships",
              "IntegrationValidator utility checking configuration completeness"
            ]
          },
          "testable_properties": [],
          "function_id": "IntegrationMapper.listIntegrationPoints",
          "related_concepts": [
            "integration requirements",
            "API dependencies",
            "third-party services",
            "data source connections",
            "authentication providers (OAuth, SAML)",
            "webhook integrations",
            "CategoryIntegrationSchema",
            "service dependencies"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_044",
      "description": "The system must support batch processing of tasks within context limits",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_044.1",
          "description": "Analyze and group related tasks based on context similarity, dependencies, and functional relationships to optimize batch processing efficiency",
          "type": "sub_process",
          "parent_id": "REQ_044",
          "children": [],
          "acceptance_criteria": [
            "Tasks with shared context entries are grouped together to minimize redundant context loading",
            "Dependent tasks are grouped in execution order within the same batch when possible",
            "Similar task types (e.g., all file operations, all searches) are grouped together",
            "Grouping algorithm completes in O(n log n) time or better for n tasks",
            "Groups maintain logical boundaries (no mixing of unrelated functional domains)",
            "Each group has metadata indicating shared context and dependencies",
            "Grouping respects explicit user-defined task boundaries or priorities"
          ],
          "implementation": {
            "frontend": [
              "No UI components required - backend processing only"
            ],
            "backend": [
              "BatchGroupingService.analyzeTaskSimilarity() - calculates similarity scores between tasks",
              "BatchGroupingService.buildDependencyGraph() - creates directed acyclic graph of task dependencies",
              "BatchGroupingService.clusterTasks() - groups tasks using clustering algorithm",
              "ContextAnalyzer.findSharedContext() - identifies common context entries across tasks",
              "TaskPriorityResolver.orderGroups() - determines optimal group execution order"
            ],
            "middleware": [
              "Validation that input tasks have required metadata (type, context_ids, dependencies)",
              "Error handling for circular dependencies in task graph"
            ],
            "shared": [
              "TaskGroup model with fields: id, task_ids, shared_context_ids, total_tokens, priority",
              "TaskSimilarity model with fields: task1_id, task2_id, similarity_score, shared_contexts",
              "DependencyGraph utility for topological sorting and cycle detection",
              "SimilarityCalculator utility for computing task affinity scores"
            ]
          },
          "testable_properties": [],
          "function_id": "BatchProcessor.groupRelatedTasks",
          "related_concepts": [
            "task similarity scoring",
            "dependency analysis",
            "context affinity",
            "task clustering",
            "priority grouping"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_044.2",
          "description": "Calculate and enforce token limits for each batch to ensure processing stays within model context windows and system constraints",
          "type": "sub_process",
          "parent_id": "REQ_044",
          "children": [],
          "acceptance_criteria": [
            "Token count is calculated for each task including content, summaries, and metadata",
            "Batch token total never exceeds configured limit (default: model max - safety margin)",
            "System accounts for overhead tokens (system prompts, formatting, delimiters)",
            "Token counting supports multiple tokenizer types (GPT, Claude, custom)",
            "Batch is split automatically if adding next task would exceed limit",
            "Safety margin (e.g., 10% buffer) is applied to prevent edge case overflows",
            "Token counts are cached and reused for repeated calculations",
            "Different limits can be configured per model or client type",
            "Warning is logged when batch approaches 80% of token limit"
          ],
          "implementation": {
            "frontend": [
              "No UI components required - backend processing only"
            ],
            "backend": [
              "TokenCounter.countTaskTokens() - calculates tokens for individual task",
              "TokenCounter.countBatchTokens() - sums tokens across all tasks in batch",
              "TokenLimitManager.validateBatchSize() - checks if batch is within limits",
              "TokenLimitManager.splitOversizedBatch() - divides batch when limit exceeded",
              "TokenLimitManager.calculateOverhead() - computes system prompt and formatting tokens",
              "ConfigService.getTokenLimit() - retrieves model-specific token limits",
              "TokenCache.getCachedCount() - retrieves previously calculated token counts"
            ],
            "middleware": [
              "Pre-processing validation to ensure all tasks have countable content",
              "Post-processing verification that batches meet token constraints"
            ],
            "shared": [
              "TokenLimit model with fields: model_name, max_tokens, safety_margin, overhead_tokens",
              "BatchTokenMetrics model with fields: total_tokens, task_tokens[], overhead_tokens, remaining_capacity",
              "TokenizerFactory utility to instantiate appropriate tokenizer for model type",
              "TokenCache utility for memoizing token counts with TTL expiration"
            ]
          },
          "testable_properties": [],
          "function_id": "TokenLimitManager.respectTokenLimits",
          "related_concepts": [
            "token counting",
            "context window management",
            "batch size optimization",
            "overhead calculation",
            "dynamic limit adjustment"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_044.3",
          "description": "Execute task batches in order while managing context loading, result collection, and error handling for each batch",
          "type": "sub_process",
          "parent_id": "REQ_044",
          "children": [],
          "acceptance_criteria": [
            "Batches are processed strictly in order determined by grouping phase",
            "Context is loaded once per batch and shared across all tasks in that batch",
            "Results from each task are collected and associated with original task ID",
            "Failed tasks in a batch do not block remaining tasks unless dependencies require it",
            "Context is properly cleaned up after batch completion to free memory",
            "Progress is tracked and reportable at batch and task granularity",
            "Each batch execution is isolated from previous batch state (no leakage)",
            "Timeout handling prevents runaway batch execution",
            "Batch execution can be paused and resumed at batch boundaries"
          ],
          "implementation": {
            "frontend": [
              "No UI components required - backend processing only"
            ],
            "backend": [
              "BatchExecutor.executeSequentially() - main orchestration loop for batch processing",
              "BatchExecutor.loadBatchContext() - loads shared context entries for batch",
              "BatchExecutor.executeTask() - runs individual task within batch context",
              "BatchExecutor.collectResults() - aggregates task results into batch result",
              "BatchExecutor.handleTaskFailure() - manages error recovery and fallback logic",
              "BatchExecutor.cleanupBatchContext() - releases context and resources after batch",
              "ProgressTracker.updateBatchProgress() - records completion status",
              "TimeoutManager.enforceTimeout() - aborts batch if execution exceeds limit"
            ],
            "middleware": [
              "Pre-execution validation that all required context is available",
              "Post-execution verification that results match expected format",
              "Timeout enforcement middleware to prevent hanging batches"
            ],
            "shared": [
              "BatchExecutionResult model with fields: batch_id, task_results[], success_count, failure_count, duration",
              "TaskResult model with fields: task_id, status, output, error, execution_time",
              "BatchContext model with fields: context_entries[], loaded_at, expires_at",
              "ExecutionState enum: PENDING, RUNNING, COMPLETED, FAILED, TIMEOUT, PAUSED"
            ]
          },
          "testable_properties": [],
          "function_id": "BatchExecutor.processBatchesSequentially",
          "related_concepts": [
            "sequential execution",
            "context lifecycle",
            "result aggregation",
            "error recovery",
            "state management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_044.4",
          "description": "Monitor and record completion status of all batches and individual tasks, providing visibility and enabling resume capabilities",
          "type": "sub_process",
          "parent_id": "REQ_044",
          "children": [],
          "acceptance_criteria": [
            "Completion status is recorded for each task (success, failure, skipped, timeout)",
            "Batch-level completion status is calculated from constituent task statuses",
            "Completion data is persisted to enable resume after interruption",
            "Progress percentage is calculated accurately (completed / total)",
            "Completion timestamps are recorded for each task and batch",
            "Failed task details include error type, message, and retry count",
            "Completion tracking data is queryable by batch ID, status, or time range",
            "Overall job completion triggers appropriate callbacks or notifications",
            "Tracking data supports generating summary reports and analytics",
            "Historical completion data is retained according to retention policy"
          ],
          "implementation": {
            "frontend": [
              "No UI components required - backend processing only"
            ],
            "backend": [
              "CompletionTracker.recordTaskCompletion() - saves individual task completion status",
              "CompletionTracker.recordBatchCompletion() - saves batch-level completion status",
              "CompletionTracker.calculateProgress() - computes overall progress percentage",
              "CompletionTracker.queryCompletionStatus() - retrieves completion data by filters",
              "CompletionTracker.generateSummaryReport() - creates completion statistics",
              "CheckpointService.saveCompletionCheckpoint() - persists state for resume",
              "NotificationService.onJobComplete() - triggers completion callbacks",
              "RetentionService.cleanupOldCompletionData() - removes expired tracking records"
            ],
            "middleware": [
              "Validation that completion records have all required fields before persisting",
              "Error handling for database write failures during completion tracking"
            ],
            "shared": [
              "TaskCompletion model with fields: task_id, batch_id, status, completed_at, duration, error, retry_count",
              "BatchCompletion model with fields: batch_id, status, tasks_total, tasks_completed, tasks_failed, started_at, completed_at",
              "JobProgress model with fields: job_id, batches_total, batches_completed, progress_percentage, estimated_completion",
              "CompletionStatus enum: SUCCESS, FAILED, SKIPPED, TIMEOUT, CANCELLED, PARTIAL",
              "CompletionQuery model for filtering completion records by various criteria"
            ]
          },
          "testable_properties": [],
          "function_id": "BatchCompletionTracker.trackBatchCompletion",
          "related_concepts": [
            "completion tracking",
            "progress monitoring",
            "checkpoint creation",
            "status reporting",
            "audit logging"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_045",
      "description": "The system must provide API client library for frontend integration",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_045.1",
          "description": "Create HTTP client wrapper with configurable base URL, timeout settings, and interceptor support for requests and responses",
          "type": "sub_process",
          "parent_id": "REQ_045",
          "children": [],
          "acceptance_criteria": [
            "HTTP client wrapper supports GET, POST, PUT, PATCH, DELETE methods",
            "Base URL can be configured via environment variables or constructor parameters",
            "Request timeout is configurable with default value of 30 seconds",
            "Request interceptors can modify headers, body, and URL before sending",
            "Response interceptors can transform data and handle errors globally",
            "Network errors are caught and wrapped in custom error types",
            "Supports request cancellation via AbortController or similar mechanism",
            "Implements automatic retry logic for failed requests with exponential backoff",
            "Handles CORS configuration for cross-origin requests",
            "Provides TypeScript type definitions for all methods and configurations"
          ],
          "implementation": {
            "frontend": [
              "Create ApiClient class with configuration options",
              "Implement request/response interceptor registration methods",
              "Add loading state management hooks for UI components",
              "Create error boundary components for handling API failures",
              "Implement request caching mechanism for GET requests"
            ],
            "backend": [
              "Not applicable - this is a frontend client library"
            ],
            "middleware": [
              "Create request interceptor for adding authentication headers",
              "Implement response interceptor for token refresh on 401 errors",
              "Add request interceptor for logging and monitoring",
              "Create response interceptor for standardizing error formats"
            ],
            "shared": [
              "Define ApiClientConfig interface with base URL, timeout, headers",
              "Create HttpMethod enum (GET, POST, PUT, PATCH, DELETE)",
              "Define RequestConfig interface with method, URL, body, headers, params",
              "Create ApiError class extending Error with status code and response data",
              "Define interceptor interfaces: RequestInterceptor and ResponseInterceptor",
              "Create utility functions for query string serialization",
              "Define RetryConfig interface with max attempts and backoff strategy"
            ]
          },
          "testable_properties": [],
          "function_id": "ApiClient.createHttpWrapper",
          "related_concepts": [
            "axios",
            "fetch API",
            "HTTP interceptors",
            "request configuration",
            "error handling",
            "retry logic",
            "connection pooling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_045.2",
          "description": "Define type-safe API methods for all backend endpoints including transcription, theme extraction, content generation, conversations, and file uploads",
          "type": "sub_process",
          "parent_id": "REQ_045",
          "children": [],
          "acceptance_criteria": [
            "Each API method corresponds to a backend endpoint with correct HTTP method",
            "All methods accept typed request parameters matching backend expectations",
            "All methods return typed response objects matching backend responses",
            "Methods support query parameters for filtering, pagination, and sorting",
            "File upload methods handle FormData with progress tracking",
            "Methods support request cancellation tokens",
            "Audio transcription endpoint accepts File/Blob and returns transcript text",
            "Theme extraction endpoint accepts text input and returns theme array",
            "Content generation endpoint accepts theme and context, returns generated content",
            "Conversation CRUD methods (create, read, update, delete, list) are implemented",
            "Pagination is handled consistently across list endpoints with cursor or offset",
            "API methods include JSDoc comments with parameter and return type documentation"
          ],
          "implementation": {
            "frontend": [
              "Create hooks for each API method (useTranscribe, useGenerateContent, etc.)",
              "Implement upload progress tracking UI for file uploads",
              "Create infinite scroll or pagination components for list endpoints",
              "Add optimistic UI updates for create/update/delete operations",
              "Implement error toast notifications for failed API calls"
            ],
            "backend": [
              "POST /api/transcribe - accepts audio file, returns transcript",
              "POST /api/extract-themes - accepts text, returns theme array",
              "POST /api/generate - accepts request with text and themes, returns content",
              "GET /api/conversations - returns paginated conversation list",
              "POST /api/conversations - creates new conversation, returns conversation object",
              "GET /api/conversations/:id - returns single conversation with messages",
              "PATCH /api/conversations/:id - updates conversation metadata",
              "DELETE /api/conversations/:id - soft deletes conversation",
              "POST /api/upload - handles file uploads, returns file metadata",
              "GET /api/projects - returns user's project list"
            ],
            "middleware": [
              "Validate request payloads against schemas before sending",
              "Add authentication token to all protected endpoints",
              "Transform snake_case backend responses to camelCase for frontend",
              "Handle multipart/form-data encoding for file uploads"
            ],
            "shared": [
              "Define TranscribeRequest interface with file: File",
              "Define TranscribeResponse interface with text: string, duration: number",
              "Define ExtractThemesRequest interface with text: string",
              "Define ExtractThemesResponse interface with themes: Theme[], keyPoints: string[]",
              "Define GenerateRequest interface with text: string, themes: string[]",
              "Define GenerateResponse interface with content: string, metadata: object",
              "Define Conversation interface with id, title, createdAt, updatedAt, messages",
              "Define Message interface with id, role, content, timestamp, attachments",
              "Define PaginationParams interface with limit, offset/cursor, sortBy, sortOrder",
              "Define PaginatedResponse<T> interface with items: T[], total: number, hasMore: boolean",
              "Define FileUploadRequest interface with file: File, metadata: object",
              "Define FileUploadResponse interface with fileId, url, size, mimeType"
            ]
          },
          "testable_properties": [],
          "function_id": "ApiClient.defineApiMethods",
          "related_concepts": [
            "REST API",
            "endpoint mapping",
            "request/response types",
            "API versioning",
            "pagination",
            "filtering",
            "sorting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_045.3",
          "description": "Implement secure authentication token management including storage, automatic injection into requests, refresh logic, and token expiration handling",
          "type": "sub_process",
          "parent_id": "REQ_045",
          "children": [],
          "acceptance_criteria": [
            "Access tokens are stored securely in memory or httpOnly cookies",
            "Refresh tokens are stored in httpOnly cookies (not localStorage)",
            "Tokens are automatically injected into Authorization header for protected requests",
            "Token expiration is detected before requests are made",
            "Automatic token refresh is triggered when access token expires",
            "Failed refresh attempts log user out and clear all tokens",
            "Concurrent requests wait for a single token refresh operation",
            "Token refresh uses refresh token to obtain new access token",
            "Implements token rotation security pattern (new refresh token on refresh)",
            "Provides methods for login, logout, and token validation",
            "Handles 401 Unauthorized responses by attempting token refresh once",
            "Tokens are cleared on logout or authentication errors"
          ],
          "implementation": {
            "frontend": [
              "Create AuthContext provider for managing authentication state",
              "Implement useAuth hook for accessing authentication methods",
              "Create ProtectedRoute component that checks authentication status",
              "Add login/logout UI components",
              "Implement token expiration countdown display",
              "Create session timeout warning modal",
              "Add automatic redirect to login on authentication failure"
            ],
            "backend": [
              "POST /api/auth/login - accepts credentials, returns access and refresh tokens",
              "POST /api/auth/refresh - accepts refresh token, returns new access token",
              "POST /api/auth/logout - invalidates refresh token",
              "GET /api/auth/me - returns current user info using access token"
            ],
            "middleware": [
              "Create token injection interceptor for adding Bearer token to headers",
              "Implement token refresh interceptor that catches 401 and retries after refresh",
              "Add token validation middleware to check expiration before requests",
              "Create logout interceptor to clear tokens on authentication errors"
            ],
            "shared": [
              "Define AuthTokens interface with accessToken, refreshToken, expiresIn",
              "Define LoginRequest interface with username/email and password",
              "Define LoginResponse interface with user object and tokens",
              "Define RefreshRequest interface with refreshToken",
              "Define RefreshResponse interface with new accessToken and refreshToken",
              "Create TokenManager class with methods: setTokens, getAccessToken, clearTokens",
              "Define User interface with id, email, username, roles",
              "Create isTokenExpired utility function accepting JWT token",
              "Define AuthState interface with user, isAuthenticated, isLoading",
              "Create decodeJWT utility function to extract payload from token"
            ]
          },
          "testable_properties": [],
          "function_id": "ApiClient.handleAuthenticationTokens",
          "related_concepts": [
            "JWT",
            "OAuth",
            "token storage",
            "token refresh",
            "session management",
            "security",
            "localStorage vs sessionStorage",
            "httpOnly cookies"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_045.4",
          "description": "Implement automatic request/response data transformation including serialization, deserialization, date parsing, case conversion, and content type handling",
          "type": "sub_process",
          "parent_id": "REQ_045",
          "children": [],
          "acceptance_criteria": [
            "Request bodies are automatically serialized to JSON for Content-Type: application/json",
            "Response bodies are automatically parsed from JSON to typed objects",
            "Date strings in responses are converted to Date objects automatically",
            "Supports multipart/form-data for file uploads with proper boundary handling",
            "Converts frontend camelCase property names to backend snake_case in requests",
            "Converts backend snake_case property names to frontend camelCase in responses",
            "Handles null and undefined values consistently in requests (omit vs send null)",
            "Supports URL-encoded form data (application/x-www-form-urlencoded)",
            "Handles binary response types (blob, arrayBuffer) for file downloads",
            "Strips empty string values from query parameters",
            "Encodes special characters in URL parameters correctly",
            "Provides custom serializer/deserializer registration for specific types"
          ],
          "implementation": {
            "frontend": [
              "Create FormData builder utility for file upload forms",
              "Implement file download trigger for binary responses",
              "Create form validation that matches backend expectations",
              "Add loading indicators during request processing",
              "Implement request payload preview for debugging in dev mode"
            ],
            "backend": [
              "Ensure API returns consistent JSON format with snake_case properties",
              "Ensure date fields are returned in ISO 8601 format",
              "Support Accept header for content negotiation",
              "Return appropriate Content-Type headers for responses"
            ],
            "middleware": [
              "Create request transformer to convert camelCase to snake_case",
              "Create response transformer to convert snake_case to camelCase",
              "Implement date parsing transformer for ISO date strings",
              "Add content-type header based on request body type",
              "Create query parameter serializer for arrays and objects"
            ],
            "shared": [
              "Create camelToSnake utility function for object property conversion",
              "Create snakeToCamel utility function for object property conversion",
              "Define ContentType enum (JSON, FORM_DATA, URL_ENCODED, BLOB)",
              "Create isDateString utility function to detect ISO date strings",
              "Define Serializer<T> interface with serialize(data: T): string method",
              "Define Deserializer<T> interface with deserialize(data: string): T method",
              "Create transformKeys utility function accepting transformation function",
              "Define FormDataBuilder class for building multipart requests",
              "Create QueryStringBuilder class for URL parameter serialization",
              "Define DateTransformer utility to handle date serialization/parsing"
            ]
          },
          "testable_properties": [],
          "function_id": "ApiClient.manageRequestResponseFormatting",
          "related_concepts": [
            "data transformation",
            "serialization",
            "deserialization",
            "JSON parsing",
            "content negotiation",
            "multipart form data",
            "camelCase vs snake_case"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_046",
      "description": "The system must implement authentication and authorization for API endpoints",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_046.1",
          "description": "Implement JWT token generation with user claims and expiration handling",
          "type": "sub_process",
          "parent_id": "REQ_046",
          "children": [],
          "acceptance_criteria": [
            "JWT tokens are generated with user ID, email, and role claims",
            "Tokens include configurable expiration time (e.g., 1 hour for access tokens)",
            "Tokens are signed using HS256 or RS256 algorithm with secure secret key",
            "Refresh tokens are generated with longer expiration (e.g., 7 days)",
            "Token generation includes proper error handling for invalid inputs",
            "Generated tokens can be successfully verified and decoded",
            "Secret keys are stored securely in environment variables, not hardcoded",
            "Token payload includes issued-at (iat) and expiration (exp) timestamps"
          ],
          "implementation": {
            "frontend": [
              "Login form component with username/password fields",
              "Token storage in localStorage or httpOnly cookies",
              "Automatic token inclusion in API request headers",
              "Token refresh logic when access token expires",
              "Logout functionality to clear stored tokens"
            ],
            "backend": [
              "POST /api/auth/login endpoint for token generation",
              "POST /api/auth/refresh endpoint for token renewal",
              "POST /api/auth/logout endpoint for token invalidation",
              "JWT library integration (e.g., jsonwebtoken for Node.js, PyJWT for Python)",
              "User authentication service to verify credentials before token generation",
              "Token blacklist mechanism for revoked tokens"
            ],
            "middleware": [
              "Token generation middleware with configurable expiration",
              "Secret key loading from environment variables",
              "Token signing with appropriate algorithm selection"
            ],
            "shared": [
              "TokenPayload interface/model with user claims structure",
              "AuthConfig model for token expiration and algorithm settings",
              "JWT utility functions for encoding and signing",
              "Environment variable definitions for JWT_SECRET and JWT_REFRESH_SECRET"
            ]
          },
          "testable_properties": [],
          "function_id": "AuthService.generateJWT",
          "related_concepts": [
            "JSON Web Tokens",
            "Token signing",
            "Claims management",
            "Token expiration",
            "Refresh tokens",
            "Secret key management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_046.2",
          "description": "Implement middleware to validate JWT access tokens on protected routes",
          "type": "sub_process",
          "parent_id": "REQ_046",
          "children": [],
          "acceptance_criteria": [
            "Middleware extracts token from Authorization header (Bearer scheme)",
            "Token signature is verified using the same secret key used for signing",
            "Token expiration time is checked and expired tokens are rejected",
            "Invalid or malformed tokens return 401 Unauthorized response",
            "Missing tokens return 401 Unauthorized response",
            "Valid tokens attach user information to request context for downstream handlers",
            "Middleware can be applied to specific routes or route groups",
            "Token validation errors include descriptive error messages",
            "Middleware handles token tampering attempts securely"
          ],
          "implementation": {
            "frontend": [
              "Axios/Fetch interceptor to add Authorization header to requests",
              "Error handling for 401 responses to redirect to login",
              "Token refresh interceptor for expired token responses",
              "UI indicators for authentication status (logged in/out)"
            ],
            "backend": [
              "Authentication middleware function to validate tokens",
              "Token decoding and verification logic",
              "User lookup from token claims to attach to request context",
              "Error response handlers for authentication failures",
              "Route protection by applying middleware to specific endpoints"
            ],
            "middleware": [
              "Token extraction from Authorization header with Bearer prefix",
              "JWT verification using secret key and algorithm",
              "Token expiration validation",
              "Request context augmentation with authenticated user data",
              "Error handling for various token validation failures"
            ],
            "shared": [
              "AuthenticatedRequest interface extending base request with user property",
              "TokenValidationError custom error class",
              "JWT verification utility function",
              "Token extraction utility function"
            ]
          },
          "testable_properties": [],
          "function_id": "AuthMiddleware.validateToken",
          "related_concepts": [
            "Token verification",
            "Request authentication",
            "Token expiration checking",
            "Invalid token handling",
            "Authorization headers",
            "Middleware chain"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_046.3",
          "description": "Implement role-based access control to restrict actions based on user roles",
          "type": "sub_process",
          "parent_id": "REQ_046",
          "children": [],
          "acceptance_criteria": [
            "System supports predefined roles (e.g., admin, user, guest)",
            "Each role has associated permissions defined in configuration",
            "Middleware checks user role from token claims against required permissions",
            "Unauthorized access attempts return 403 Forbidden response",
            "Permissions are checked before executing protected operations",
            "Role hierarchy is supported (e.g., admin inherits user permissions)",
            "Permissions can be resource-specific (e.g., edit own posts vs. edit any post)",
            "RBAC configuration is centralized and easily maintainable",
            "Role changes are reflected immediately without requiring re-login"
          ],
          "implementation": {
            "frontend": [
              "Conditional UI rendering based on user role (hide/disable restricted actions)",
              "Role-based navigation menu items",
              "Permission checking before displaying action buttons",
              "Error messages for insufficient permissions",
              "Admin dashboard components only visible to admin users"
            ],
            "backend": [
              "GET /api/auth/permissions endpoint to fetch user permissions",
              "Role definition service with permission mappings",
              "Authorization middleware to check role-based permissions",
              "Database schema for users with role field",
              "Permission checking utilities for business logic layers",
              "Audit logging for authorization failures"
            ],
            "middleware": [
              "RBAC middleware accepting required roles/permissions as parameters",
              "Permission checking logic against user's role from token",
              "Resource ownership validation for resource-specific permissions",
              "403 Forbidden response for insufficient permissions"
            ],
            "shared": [
              "Role enum/constant defining all system roles",
              "Permission enum/constant defining all system permissions",
              "RolePermissions mapping configuration",
              "User model with role property",
              "Permission checking utility functions",
              "ResourcePermission interface for resource-level access control"
            ]
          },
          "testable_properties": [],
          "function_id": "RBACService.checkPermissions",
          "related_concepts": [
            "Role-based access control (RBAC)",
            "User roles",
            "Permissions",
            "Authorization policies",
            "Access control lists",
            "Resource-level permissions"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_046.4",
          "description": "Apply comprehensive security measures to protect sensitive API endpoints",
          "type": "sub_process",
          "parent_id": "REQ_046",
          "children": [],
          "acceptance_criteria": [
            "All sensitive endpoints require valid authentication tokens",
            "Rate limiting is applied to prevent brute force attacks (e.g., 100 requests/15 minutes)",
            "Input validation prevents SQL injection and XSS attacks",
            "CORS is configured to allow only trusted origins",
            "Security headers are set (X-Frame-Options, X-Content-Type-Options, etc.)",
            "HTTPS is enforced for all API communications in production",
            "Sensitive data (passwords, tokens) is never logged or exposed in error messages",
            "File upload endpoints validate file types and sizes",
            "API endpoints sanitize all user inputs before processing",
            "Database queries use parameterized statements to prevent injection"
          ],
          "implementation": {
            "frontend": [
              "HTTPS-only API client configuration",
              "CSRF token handling for state-changing requests",
              "Input sanitization on form submissions",
              "File upload validation (type, size) before sending to backend",
              "Error message display without exposing sensitive system details"
            ],
            "backend": [
              "Rate limiting middleware (e.g., express-rate-limit, flask-limiter)",
              "Input validation middleware using validation libraries (e.g., Joi, Zod, Pydantic)",
              "CORS middleware with whitelist of allowed origins",
              "Security headers middleware (e.g., Helmet for Express)",
              "HTTPS redirect middleware for production environments",
              "Request sanitization middleware to strip dangerous characters",
              "File upload validation with MIME type checking",
              "Parameterized database queries using ORM or prepared statements",
              "Error handling middleware that sanitizes error responses"
            ],
            "middleware": [
              "Rate limiting configuration per endpoint or globally",
              "Input validation schemas for each endpoint",
              "CORS policy configuration",
              "Security headers configuration",
              "Request sanitization and normalization",
              "File upload constraints enforcement"
            ],
            "shared": [
              "ValidationSchema models for API request bodies",
              "SecurityConfig model with rate limits, CORS origins, etc.",
              "Input sanitization utility functions",
              "File validation utility functions",
              "Constants for allowed file types, max file sizes, rate limits",
              "Error sanitization utilities to remove sensitive information"
            ]
          },
          "testable_properties": [],
          "function_id": "SecurityMiddleware.secureEndpoints",
          "related_concepts": [
            "API security",
            "Rate limiting",
            "Input validation",
            "CORS policies",
            "HTTPS enforcement",
            "Security headers",
            "SQL injection prevention",
            "XSS protection"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_047",
      "description": "The system must support local development with Ollama for offline LLM access",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_047.1",
          "description": "Configure Ollama client connection with local endpoint URL, model selection, and connection parameters for offline LLM access",
          "type": "sub_process",
          "parent_id": "REQ_047",
          "children": [],
          "acceptance_criteria": [
            "BAML client definition includes Ollama provider with configurable base_url (default: http://localhost:11434)",
            "Configuration supports model selection from available local Ollama models",
            "Client configuration includes timeout settings (connect_timeout, read_timeout)",
            "Configuration validates Ollama service availability on startup",
            "Client supports temperature, top_p, and other generation parameters",
            "Configuration file or environment variables define Ollama-specific settings",
            "Documentation describes how to configure Ollama client for different models",
            "Client handles connection errors gracefully with informative error messages"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Update baml_src/clients.baml to add Ollama client definition",
              "Create OllamaClientConfig class with base_url, model_name, timeout parameters",
              "Implement connection validation service to check Ollama availability",
              "Add environment variable parsing for OLLAMA_BASE_URL and OLLAMA_MODEL",
              "Create configuration schema in settings.py or config.yaml for Ollama parameters"
            ],
            "middleware": [
              "Add connection health check middleware for Ollama availability",
              "Implement request timeout middleware with configurable limits"
            ],
            "shared": [
              "Define OllamaConfig dataclass with base_url, model, timeout fields",
              "Create OllamaModels enum listing supported local models",
              "Add utility function validate_ollama_connection(base_url: str) -> bool",
              "Define OllamaClientError exception class for connection issues"
            ]
          },
          "testable_properties": [],
          "function_id": "OllamaClient.configure",
          "related_concepts": [
            "BAML client configuration",
            "local model registry",
            "connection pooling",
            "timeout settings",
            "model capabilities"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_047.2",
          "description": "Establish connection to local Ollama models and verify model availability for inference operations",
          "type": "sub_process",
          "parent_id": "REQ_047",
          "children": [],
          "acceptance_criteria": [
            "Client successfully connects to Ollama API at configured endpoint",
            "Connection verifies that specified model exists and is loaded in Ollama",
            "Client retrieves and caches model capabilities (context length, token limits)",
            "Connection attempt includes retry logic with exponential backoff (max 3 retries)",
            "Client lists all available local models if requested model not found",
            "Connection health check runs periodically to detect Ollama service restarts",
            "Client logs connection status and model information at startup",
            "Connection supports multiple concurrent requests with connection pooling"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Implement connect() method in OllamaClient class to establish HTTP connection",
              "Create list_models() API call to Ollama /api/tags endpoint",
              "Implement check_model_loaded() to verify model availability via /api/show endpoint",
              "Add get_model_info() to retrieve model metadata (context_length, parameters)",
              "Create connection pool manager with configurable pool size",
              "Implement health check background task that pings Ollama every 60 seconds",
              "Add retry decorator with exponential backoff for connection attempts",
              "Create detailed connection logs with model name, endpoint, and status"
            ],
            "middleware": [
              "Add connection pooling middleware to reuse HTTP connections",
              "Implement request queuing middleware when model is loading"
            ],
            "shared": [
              "Define OllamaModelInfo dataclass with name, size, context_length, modified_at",
              "Create OllamaConnectionStatus enum (CONNECTED, DISCONNECTED, MODEL_LOADING, ERROR)",
              "Add utility function parse_ollama_model_info(response: dict) -> OllamaModelInfo",
              "Define constant OLLAMA_DEFAULT_TIMEOUT = 30 seconds",
              "Create RetryConfig dataclass for retry policy configuration"
            ]
          },
          "testable_properties": [],
          "function_id": "OllamaClient.connect",
          "related_concepts": [
            "model loading",
            "service discovery",
            "health checks",
            "model versioning",
            "capability detection"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_047.3",
          "description": "Implement fallback mechanism to switch to local Ollama models when cloud API services are unavailable or unreachable",
          "type": "sub_process",
          "parent_id": "REQ_047",
          "children": [],
          "acceptance_criteria": [
            "System detects API unavailability through connection errors, timeouts, or HTTP 5xx responses",
            "Fallback triggers automatically when cloud API fails after retry attempts exhausted",
            "Provider priority list defines order: cloud API (primary) -> Ollama (fallback)",
            "Fallback logic logs reason for switching to local provider with error details",
            "System attempts to reconnect to cloud API periodically (every 5 minutes) after fallback",
            "Fallback preserves request context and retries with Ollama seamlessly",
            "Configuration allows disabling fallback for production environments if needed",
            "System notifies user/logs when operating in fallback mode",
            "Fallback respects BAML retry policies defined for each provider"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create LLMProviderManager class to orchestrate provider selection",
              "Implement detect_api_failure() to identify connection/timeout/5xx errors",
              "Add fallback_to_ollama() method that switches provider on API failure",
              "Create provider_priority_list configurable via settings",
              "Implement circuit breaker pattern with failure threshold (3 failures = open circuit)",
              "Add periodic_reconnect_check() background task to test cloud API availability",
              "Create fallback_execute() that retries request with Ollama provider",
              "Add fallback event logging with timestamps, error reasons, and provider switches",
              "Implement preserve_request_context() to maintain prompt/parameters during switch"
            ],
            "middleware": [
              "Add provider selection middleware that checks circuit breaker state",
              "Implement error detection middleware to identify API failure patterns",
              "Create fallback notification middleware that logs provider switches"
            ],
            "shared": [
              "Define ProviderType enum (OPENAI, ANTHROPIC, OLLAMA)",
              "Create ProviderStatus dataclass with is_available, last_check, failure_count",
              "Add FallbackReason enum (TIMEOUT, CONNECTION_ERROR, API_ERROR, RATE_LIMIT)",
              "Define CircuitBreakerState enum (CLOSED, OPEN, HALF_OPEN)",
              "Create ProviderPriority type alias = List[ProviderType]",
              "Add utility function should_fallback(error: Exception) -> bool",
              "Define constant RECONNECT_CHECK_INTERVAL = 300 seconds"
            ]
          },
          "testable_properties": [],
          "function_id": "LLMProvider.fallback",
          "related_concepts": [
            "circuit breaker pattern",
            "failover strategy",
            "provider priority",
            "error detection",
            "graceful degradation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_047.4",
          "description": "Test suite to verify Ollama integration works correctly with local models for all LLM operations including generation, streaming, and error handling",
          "type": "sub_process",
          "parent_id": "REQ_047",
          "children": [],
          "acceptance_criteria": [
            "Test successfully connects to local Ollama instance and lists available models",
            "Test generates text completion from Ollama model with sample prompt",
            "Test verifies streaming responses work correctly with Ollama provider",
            "Test validates response format matches BAML type definitions",
            "Test confirms fallback mechanism switches to Ollama when cloud API mocked as down",
            "Test measures Ollama response latency and compares to cloud API baseline",
            "Test handles Ollama service unavailability gracefully with proper error messages",
            "Test verifies context window limits respected for local models",
            "Test confirms model parameters (temperature, top_p) applied correctly",
            "Integration test runs full pipeline (research/decomposition) using only Ollama"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create test_ollama_connection.py with connection and model listing tests",
              "Implement test_ollama_generation() that sends prompt and validates response",
              "Add test_ollama_streaming() that verifies streaming token delivery",
              "Create test_baml_ollama_integration() that calls BAML functions with Ollama client",
              "Implement test_fallback_to_ollama() that mocks API failure and verifies switch",
              "Add test_ollama_performance() that measures generation latency",
              "Create test_ollama_error_handling() for service down scenarios",
              "Implement test_context_window_limits() that validates token limit enforcement",
              "Add test_ollama_parameters() that verifies temperature/top_p settings applied",
              "Create test_full_pipeline_offline() that runs complete workflow with Ollama",
              "Implement pytest fixtures for Ollama setup/teardown and model mocking",
              "Add performance benchmark suite comparing Ollama vs cloud API speed/quality"
            ],
            "middleware": [],
            "shared": [
              "Define OllamaTestConfig dataclass with test_model, test_endpoint, timeout",
              "Create mock_ollama_response() fixture for unit testing without real service",
              "Add sample_prompts constant list for testing various generation scenarios",
              "Define expected_response_schemas for validation",
              "Create OllamaPerformanceMetrics dataclass with latency, tokens_per_second"
            ]
          },
          "testable_properties": [],
          "function_id": "OllamaClient.test",
          "related_concepts": [
            "integration testing",
            "model validation",
            "performance benchmarking",
            "response quality",
            "error scenarios"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_048",
      "description": "The system must implement exponential backoff retry policy for LLM API failures",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_048.1",
          "description": "Configure and enforce maximum retry attempts for failed LLM API calls to prevent infinite loops and excessive resource consumption",
          "type": "sub_process",
          "parent_id": "REQ_048",
          "children": [],
          "acceptance_criteria": [
            "System allows configuration of maximum retry count through environment variables or configuration files",
            "Default maximum retry count is set to 3 attempts if not explicitly configured",
            "Maximum retry count must be between 1 and 10 inclusive",
            "System validates retry count configuration at startup and throws descriptive error for invalid values",
            "Retry count is enforced per individual API request, not globally",
            "After maximum retries exhausted, system throws a specific MaxRetriesExceededError with context",
            "Configuration can be overridden per LLM provider (OpenAI, Anthropic, Ollama)",
            "Unit tests verify retry count enforcement with mocked API failures",
            "Integration tests confirm proper termination after max retries with actual API endpoints"
          ],
          "implementation": {
            "frontend": [
              "Display retry configuration in admin/settings UI",
              "Show current retry count during ongoing API calls in status indicators",
              "Display error message when max retries exceeded with user-friendly explanation",
              "Provide toast/notification when API calls are being retried"
            ],
            "backend": [
              "Create RetryPolicy configuration class with maxRetries property",
              "Implement validateRetryCount() method to check boundaries (1-10)",
              "Create getMaxRetries() method with provider-specific override logic",
              "Add MaxRetriesExceededError custom exception class",
              "Implement retry counter tracking in API client wrapper",
              "Create configuration loader to read max_retries from environment/config files"
            ],
            "middleware": [
              "Add retry count header to API requests for debugging",
              "Implement request interceptor to check current retry count",
              "Add response interceptor to increment retry counter on failures",
              "Create middleware to inject retry policy into request context"
            ],
            "shared": [
              "Define RetryConfig interface with maxRetries, provider, and override properties",
              "Create RetryMetrics type for tracking retry statistics",
              "Define MaxRetriesExceededError type with requestId, provider, and attemptCount properties",
              "Create constants file with DEFAULT_MAX_RETRIES=3, MIN_RETRIES=1, MAX_RETRIES=10",
              "Define ProviderRetryConfig type for provider-specific configurations"
            ]
          },
          "testable_properties": [],
          "function_id": "RetryPolicy.setMaximumRetryCount",
          "related_concepts": [
            "circuit breaker pattern",
            "failure threshold",
            "resource management",
            "configuration management",
            "retry budget"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_048.2",
          "description": "Calculate exponentially increasing delay between retry attempts with optional jitter to prevent thundering herd and respect API rate limits",
          "type": "sub_process",
          "parent_id": "REQ_048",
          "children": [],
          "acceptance_criteria": [
            "Base delay starts at configurable value (default 1000ms)",
            "Each retry delay is calculated as: baseDelay * (2 ^ attemptNumber)",
            "Maximum delay is capped at configurable value (default 32000ms/32 seconds)",
            "Jitter is applied using full jitter strategy: random(0, calculatedDelay)",
            "Formula is: min(maxDelay, baseDelay * 2^attempt) * random(0, 1)",
            "First retry (attempt 0) uses base delay with jitter",
            "Delay calculation is deterministic for testing when jitter disabled",
            "Configuration supports custom base delay and max delay per provider",
            "Unit tests verify exponential growth: 1s, 2s, 4s, 8s, 16s, 32s (capped)",
            "Unit tests verify jitter produces values in expected range across 1000 iterations",
            "Performance tests confirm delay calculation completes in <1ms"
          ],
          "implementation": {
            "frontend": [
              "Display countdown timer showing remaining wait time before next retry",
              "Show visual progress indicator during retry delays",
              "Display calculated delay values in debug/developer mode",
              "Provide manual retry button that bypasses delay for user-initiated retries"
            ],
            "backend": [
              "Create calculateExponentialDelay(attemptNumber, baseDelay, maxDelay) method",
              "Implement applyJitter(delay) method using Math.random() for full jitter",
              "Create getBaseDelay() method with provider-specific configuration",
              "Implement getMaxDelay() method with configuration override support",
              "Add sleep/delay utility function that respects calculated backoff",
              "Create BackoffCalculator class encapsulating delay logic and configuration"
            ],
            "middleware": [
              "Add delay calculation timing to request metadata",
              "Implement delay enforcement before retry attempt execution",
              "Add header with calculated delay to API requests for debugging",
              "Create middleware to pause request processing during backoff period"
            ],
            "shared": [
              "Define BackoffConfig interface with baseDelay, maxDelay, useJitter properties",
              "Create DelayCalculation type with attempt, baseDelay, calculatedDelay, finalDelay properties",
              "Define constants: DEFAULT_BASE_DELAY=1000, DEFAULT_MAX_DELAY=32000",
              "Create utility function exponentialBackoff(attempt, config) for reusability",
              "Define JitterStrategy enum with values: NONE, FULL, EQUAL, DECORRELATED"
            ]
          },
          "testable_properties": [],
          "function_id": "RetryPolicy.calculateBackoffDelay",
          "related_concepts": [
            "exponential backoff algorithm",
            "jitter strategy",
            "rate limiting",
            "thundering herd prevention",
            "decorrelated jitter",
            "backoff multiplier"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_048.3",
          "description": "Automatically retry failed LLM API requests with exponential backoff, distinguishing between retryable and non-retryable errors",
          "type": "sub_process",
          "parent_id": "REQ_048",
          "children": [],
          "acceptance_criteria": [
            "System automatically retries on HTTP 429 (rate limit), 500, 502, 503, 504 errors",
            "System does NOT retry on HTTP 400, 401, 403, 404, 422 (client errors)",
            "System does NOT retry on authentication failures or invalid API keys",
            "Network timeout errors (ETIMEDOUT, ECONNRESET) are retried",
            "Each retry includes full context from original request (headers, body, metadata)",
            "Retry mechanism respects provider-specific rate limit headers (Retry-After)",
            "If Retry-After header present, system waits specified duration instead of calculated backoff",
            "Original request ID is preserved across all retry attempts for traceability",
            "Successful retry returns response as if first attempt succeeded",
            "Failed retries after max attempts throw original error with retry metadata attached",
            "Integration tests verify retry behavior with mocked rate limit responses",
            "Integration tests confirm non-retryable errors fail immediately without retries",
            "Load tests verify system handles burst of 429 errors without cascading failures"
          ],
          "implementation": {
            "frontend": [
              "Display retry status badge on UI elements triggering API calls",
              "Show detailed retry history in developer tools/debug panel",
              "Provide user notification when retries are in progress",
              "Display different icons for transient vs permanent failures",
              "Allow users to cancel ongoing retry sequences"
            ],
            "backend": [
              "Create isRetryableError(error) method checking HTTP status and error type",
              "Implement executeWithRetry(request, retryPolicy) wrapper method",
              "Create preserveRequestContext(request) to maintain state across retries",
              "Implement parseRetryAfterHeader(response) to extract wait duration",
              "Create shouldUseRetryAfter(response) decision logic",
              "Implement RetryableError and NonRetryableError exception classes",
              "Add retry metadata attachment to error objects (attempts, delays, timestamps)",
              "Create LLMClientWrapper that intercepts and retries failed calls"
            ],
            "middleware": [
              "Add error classification middleware to categorize failures",
              "Implement retry decision middleware based on error type",
              "Create request cloning middleware to preserve original request",
              "Add Retry-After header parsing middleware",
              "Implement circuit breaker middleware to prevent retry storms"
            ],
            "shared": [
              "Define RetryableErrorCode enum with HTTP status codes: 429, 500, 502, 503, 504",
              "Create NonRetryableErrorCode enum with: 400, 401, 403, 404, 422",
              "Define RequestContext interface with id, headers, body, timestamp, metadata",
              "Create RetryMetadata type with attemptNumber, delay, timestamp, errorType",
              "Define ErrorClassification interface with isRetryable, errorCategory, httpStatus",
              "Create utility function classifyError(error) returning ErrorClassification"
            ]
          },
          "testable_properties": [],
          "function_id": "LLMClient.retryFailedRequests",
          "related_concepts": [
            "transient fault handling",
            "idempotency",
            "error classification",
            "circuit breaker integration",
            "request deduplication",
            "timeout management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_048.4",
          "description": "Comprehensively log all retry attempts with detailed context for monitoring, debugging, and analysis of LLM API failure patterns",
          "type": "sub_process",
          "parent_id": "REQ_048",
          "children": [],
          "acceptance_criteria": [
            "Each retry attempt generates structured log entry with consistent schema",
            "Log entries include: timestamp, requestId, provider, attemptNumber, errorType, httpStatus, delay, totalElapsed",
            "Initial failure logged at WARN level, subsequent retries at INFO level",
            "Final failure after max retries logged at ERROR level with full context",
            "Successful retry after failures logged at INFO level with recovery metrics",
            "Logs include correlation ID for tracing requests across system boundaries",
            "Log format supports JSON for machine parsing and structured querying",
            "Sensitive data (API keys, user content) is redacted from logs",
            "Log entries include provider-specific context (model, tokens, temperature)",
            "System emits metrics alongside logs: retry_count, success_rate, average_delay",
            "Logs integrate with existing logging infrastructure (e.g., Winston, Pino)",
            "Unit tests verify log output format and content",
            "Integration tests confirm logs appear in configured destinations (stdout, file, service)"
          ],
          "implementation": {
            "frontend": [
              "Display retry logs in browser console during development",
              "Create admin dashboard showing retry statistics and patterns",
              "Provide log export functionality for debugging",
              "Show real-time retry metrics in monitoring UI",
              "Create alerts/notifications for excessive retry rates"
            ],
            "backend": [
              "Create logRetryAttempt(context, attempt, error) method with structured output",
              "Implement logRetrySuccess(context, attempt, response) for successful retries",
              "Create logRetryExhausted(context, attempts, finalError) for final failures",
              "Implement redactSensitiveData(logEntry) to remove API keys and PII",
              "Create getLogLevel(attemptNumber, isSuccess) decision logic",
              "Implement RetryLogger class with methods for each log scenario",
              "Add metric emission alongside logging (retry_counter, delay_histogram)",
              "Create log aggregation utilities for batch logging of retry sequences"
            ],
            "middleware": [
              "Add logging middleware to capture retry events automatically",
              "Implement correlation ID injection middleware for request tracing",
              "Create log context middleware to attach request metadata",
              "Add response time tracking middleware for performance metrics"
            ],
            "shared": [
              "Define RetryLogEntry interface with all required fields",
              "Create LogLevel enum: DEBUG, INFO, WARN, ERROR",
              "Define RetryMetrics interface with counts, rates, durations",
              "Create SensitiveFieldPattern constants for redaction regex patterns",
              "Define LogContext interface with requestId, correlationId, userId, sessionId",
              "Create utility function formatLogEntry(entry) for consistent formatting",
              "Define MetricEvent type for retry-related metrics emission"
            ]
          },
          "testable_properties": [],
          "function_id": "RetryLogger.logRetryAttempts",
          "related_concepts": [
            "observability",
            "structured logging",
            "log aggregation",
            "metrics collection",
            "distributed tracing",
            "audit trail"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_049",
      "description": "The system must support multiple audio formats for recording and upload",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_049.1",
          "description": "Accept and validate WAV format audio files for recording and upload, supporting both PCM and compressed WAV variants with proper header validation",
          "type": "sub_process",
          "parent_id": "REQ_049",
          "children": [],
          "acceptance_criteria": [
            "System accepts WAV files with audio/wav and audio/x-wav MIME types",
            "System validates RIFF header structure (RIFF chunk ID, WAVE format identifier)",
            "System supports common sample rates (8kHz, 16kHz, 22.05kHz, 44.1kHz, 48kHz)",
            "System supports bit depths of 8-bit, 16-bit, 24-bit, and 32-bit",
            "System supports mono and stereo channel configurations",
            "System rejects corrupted or invalid WAV files with descriptive error messages",
            "System enforces maximum file size limit (e.g., 100MB) for WAV uploads",
            "System extracts and displays audio metadata (duration, sample rate, channels) from WAV files",
            "Browser-recorded WAV audio (via MediaRecorder API) is accepted without conversion",
            "File upload progress indicator shows percentage for large WAV files"
          ],
          "implementation": {
            "frontend": [
              "File input component with WAV format filter (.wav extension)",
              "Drag-and-drop zone with WAV format validation before upload",
              "Client-side MIME type validation for audio/wav",
              "File size validation UI feedback (show warning if >100MB)",
              "Audio metadata display component (duration, sample rate, channels)",
              "Error toast notifications for invalid WAV format",
              "Upload progress bar for WAV file uploads",
              "Audio preview player for uploaded WAV files"
            ],
            "backend": [
              "POST /api/audio/upload endpoint accepting WAV files",
              "WAV format validation service checking RIFF header structure",
              "Audio metadata extraction service (using library like pydub, ffprobe, or python-soundfile)",
              "File storage service for WAV files (filesystem or S3)",
              "Audio duration calculation endpoint",
              "WAV header parsing utility to extract format details",
              "File size validation middleware (reject >100MB)",
              "MIME type verification using magic numbers (not just extension)"
            ],
            "middleware": [
              "Multipart form-data parser for file uploads",
              "File type validation middleware checking MIME type and magic numbers",
              "File size limit enforcement (100MB max)",
              "Request timeout configuration for large file uploads",
              "Content-Type header validation for audio/wav",
              "Rate limiting for upload endpoints to prevent abuse"
            ],
            "shared": [
              "AudioFile data model with fields: id, filename, format, mimeType, size, duration, sampleRate, bitDepth, channels, uploadedAt",
              "AudioFormat enum: WAV, MP3, OGG",
              "WAV_MIME_TYPES constant array: ['audio/wav', 'audio/x-wav', 'audio/wave']",
              "MAX_FILE_SIZE_BYTES constant (100MB)",
              "SUPPORTED_SAMPLE_RATES constant array",
              "SUPPORTED_BIT_DEPTHS constant array",
              "AudioMetadata interface with format-specific fields",
              "File validation error types and messages"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioFormatValidator.validateWAVFormat",
          "related_concepts": [
            "RIFF/WAVE file structure",
            "PCM audio encoding",
            "WAV header parsing",
            "Audio bit depth validation",
            "Sample rate validation",
            "File size limits",
            "MIME type validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_049.2",
          "description": "Accept and validate MP3 format audio files for recording and upload, supporting various MP3 encoding bitrates and ID3 tag structures",
          "type": "sub_process",
          "parent_id": "REQ_049",
          "children": [],
          "acceptance_criteria": [
            "System accepts MP3 files with audio/mpeg and audio/mp3 MIME types",
            "System validates MP3 frame header structure and sync word (0xFFE or 0xFFF)",
            "System supports CBR and VBR encoded MP3 files",
            "System supports bitrates from 32kbps to 320kbps",
            "System extracts ID3v1 and ID3v2 metadata tags when present",
            "System rejects corrupted or invalid MP3 files with specific error codes",
            "System enforces maximum file size limit (e.g., 100MB) for MP3 uploads",
            "System calculates accurate duration for VBR MP3 files using VBR headers (Xing/VBRI)",
            "System displays audio quality information (bitrate, encoding type)",
            "File upload process handles MP3 files without requiring server-side transcoding"
          ],
          "implementation": {
            "frontend": [
              "File input component with MP3 format filter (.mp3 extension)",
              "Drag-and-drop zone with MP3 format validation",
              "Client-side MIME type validation for audio/mpeg",
              "MP3 bitrate and quality indicator display",
              "ID3 tag metadata display (if available: title, artist, album)",
              "Error messages for corrupted MP3 files",
              "Upload progress tracking for MP3 files",
              "Audio waveform visualization component for MP3 playback"
            ],
            "backend": [
              "POST /api/audio/upload endpoint handling MP3 format",
              "MP3 frame header validation service",
              "MP3 metadata extraction service using ID3 parser (e.g., mutagen, python-id3)",
              "VBR header detection for accurate duration calculation",
              "Bitrate detection service (CBR vs VBR identification)",
              "MP3 integrity check service (frame sync validation)",
              "Audio duration calculation handling VBR files correctly",
              "File storage service optimized for compressed audio formats"
            ],
            "middleware": [
              "Multipart form-data parser with MP3-specific handling",
              "MIME type validation for audio/mpeg and audio/mp3",
              "File size limit enforcement (100MB max)",
              "MP3 magic number validation (0xFFE or 0xFFF sync word)",
              "Request compression handling for MP3 uploads",
              "Upload retry mechanism for network interruptions"
            ],
            "shared": [
              "AudioFile model extended with MP3-specific fields: bitrate, encodingType (CBR/VBR), hasID3Tags",
              "MP3_MIME_TYPES constant array: ['audio/mpeg', 'audio/mp3']",
              "SUPPORTED_MP3_BITRATES constant array: [32, 64, 96, 128, 192, 256, 320]",
              "MP3Metadata interface with ID3 tag fields",
              "EncodingType enum: CBR, VBR, ABR",
              "MP3ValidationError error class with specific error codes",
              "Audio quality classification utility (low/medium/high based on bitrate)"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioFormatValidator.validateMP3Format",
          "related_concepts": [
            "MPEG-1/MPEG-2 Audio Layer III",
            "ID3v1 and ID3v2 tags",
            "MP3 frame header validation",
            "Constant bitrate (CBR) and variable bitrate (VBR)",
            "MP3 metadata extraction",
            "Audio codec validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_049.3",
          "description": "Accept and validate OGG container format audio files (Vorbis and Opus codecs) for recording and upload, with proper codec detection and validation",
          "type": "sub_process",
          "parent_id": "REQ_049",
          "children": [],
          "acceptance_criteria": [
            "System accepts OGG files with audio/ogg and audio/ogg; codecs=vorbis MIME types",
            "System validates OGG container structure (OggS page headers)",
            "System detects and supports both Vorbis and Opus codecs within OGG containers",
            "System extracts Vorbis comment metadata from OGG files",
            "System validates codec-specific headers (Vorbis identification header, Opus header)",
            "System rejects OGG files with unsupported codecs with descriptive errors",
            "System enforces maximum file size limit (e.g., 100MB) for OGG uploads",
            "System correctly calculates duration from OGG granule positions",
            "System displays codec information (Vorbis vs Opus) to users",
            "Browser-recorded OGG audio (via MediaRecorder with Opus) is properly accepted"
          ],
          "implementation": {
            "frontend": [
              "File input component with OGG format filter (.ogg, .oga extensions)",
              "Drag-and-drop zone with OGG format validation",
              "Client-side MIME type validation for audio/ogg",
              "Codec information display (Vorbis or Opus)",
              "Vorbis comment metadata display component",
              "Error notifications for unsupported OGG codecs",
              "Upload progress indicator for OGG files",
              "Browser compatibility check for OGG playback",
              "MediaRecorder API integration for recording OGG/Opus audio"
            ],
            "backend": [
              "POST /api/audio/upload endpoint supporting OGG format",
              "OGG container validation service checking OggS magic number",
              "Codec detection service (Vorbis vs Opus identification)",
              "Vorbis comment parser for metadata extraction",
              "Opus header validation service",
              "OGG page structure validation",
              "Duration calculation from granule positions",
              "Codec-specific quality parameter extraction (Vorbis quality, Opus bitrate)",
              "Storage service handling OGG container format"
            ],
            "middleware": [
              "Multipart form-data parser for OGG uploads",
              "MIME type validation for audio/ogg and codec variants",
              "OGG magic number validation (OggS signature)",
              "File size limit enforcement (100MB max)",
              "Codec whitelist enforcement (only Vorbis and Opus allowed)",
              "Stream processing for large OGG files"
            ],
            "shared": [
              "AudioFile model with OGG-specific fields: codec (Vorbis/Opus), containerFormat, quality",
              "OGG_MIME_TYPES constant array: ['audio/ogg', 'audio/ogg; codecs=vorbis', 'audio/ogg; codecs=opus']",
              "SUPPORTED_OGG_CODECS enum: VORBIS, OPUS",
              "OGGMetadata interface with Vorbis comment fields",
              "CodecInfo interface with codec-specific parameters",
              "OGG_MAGIC_NUMBER constant: 'OggS'",
              "Audio codec detection utility function",
              "Browser compatibility constants for OGG format support"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioFormatValidator.validateOGGFormat",
          "related_concepts": [
            "OGG container format",
            "Vorbis audio codec",
            "Opus audio codec",
            "OGG page structure",
            "Vorbis comment headers",
            "Opus header validation",
            "Open source audio formats"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_049.4",
          "description": "Automatically detect when audio format conversion is required and convert between WAV, MP3, and OGG formats using efficient transcoding, with quality preservation and user notification",
          "type": "sub_process",
          "parent_id": "REQ_049",
          "children": [],
          "acceptance_criteria": [
            "System detects when uploaded format is not supported by target system and triggers conversion",
            "System converts WAV to MP3/OGG when storage optimization is needed (lossy compression)",
            "System converts MP3/OGG to WAV when lossless processing is required",
            "System converts OGG to MP3 for maximum compatibility when needed",
            "System preserves maximum audio quality during conversion (e.g., 320kbps for MP3)",
            "System maintains original audio metadata during conversion when possible",
            "Conversion process runs asynchronously without blocking user uploads",
            "System notifies users when conversion is in progress and when complete",
            "System provides option to download both original and converted files",
            "Conversion failures trigger automatic retries with fallback strategies",
            "System logs conversion operations with source format, target format, duration, and success status",
            "Converted files are automatically linked to original upload in database"
          ],
          "implementation": {
            "frontend": [
              "Format conversion status indicator showing progress",
              "User notification component for conversion start and completion",
              "Format selection dropdown for manual conversion requests",
              "Quality settings UI for manual conversions (bitrate, sample rate)",
              "Download button for both original and converted files",
              "Conversion history list showing all format changes",
              "Error display for failed conversions with retry button",
              "Real-time conversion progress bar with estimated time remaining"
            ],
            "backend": [
              "POST /api/audio/convert endpoint for manual conversion requests",
              "Automatic format detection service determining conversion needs",
              "FFmpeg wrapper service for audio transcoding",
              "Conversion queue manager using background job system (Celery, Bull, or similar)",
              "Format compatibility checker service",
              "Conversion preset service (optimized settings for each format pair)",
              "Metadata preservation service during conversion",
              "Converted file storage service with original file linking",
              "Conversion job status endpoint GET /api/audio/convert/:jobId/status",
              "Batch conversion service for processing multiple files",
              "Audio quality analysis service (before/after comparison)",
              "Automatic cleanup service for temporary conversion files"
            ],
            "middleware": [
              "Conversion job authentication and authorization",
              "Rate limiting for conversion requests to prevent abuse",
              "Job queue priority management",
              "Conversion timeout enforcement (e.g., 10 minutes max)",
              "Resource usage monitoring for FFmpeg processes",
              "Webhook notification system for conversion completion"
            ],
            "shared": [
              "ConversionJob model with fields: id, sourceFileId, targetFileId, sourceFormat, targetFormat, status, progress, startedAt, completedAt, errorMessage",
              "ConversionStatus enum: PENDING, IN_PROGRESS, COMPLETED, FAILED, CANCELLED",
              "ConversionPreset interface with format-specific settings",
              "FORMAT_CONVERSION_MATRIX constant mapping supported conversions",
              "CONVERSION_QUALITY_PRESETS constant object (high, medium, low)",
              "ConversionSettings interface: targetFormat, bitrate, sampleRate, channels, quality",
              "FormatCompatibility utility class with compatibility check methods",
              "FFMPEG_COMMAND_TEMPLATES constant object for each conversion type",
              "ConversionError error class with specific error codes and recovery suggestions",
              "Audio format detection utility using magic numbers and headers"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioFormatConverter.convertFormatsAsNeeded",
          "related_concepts": [
            "Audio transcoding",
            "FFmpeg integration",
            "Codec conversion",
            "Quality preservation during conversion",
            "Lossy vs lossless conversion",
            "Format compatibility",
            "Transcoding queue management",
            "Audio normalization"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    }
  ],
  "metadata": {
    "source": "agent_sdk_decomposition",
    "research_length": 39389,
    "decomposition_stats": {
      "requirements_found": 50,
      "subprocesses_expanded": 235,
      "total_nodes": 285,
      "extraction_time_ms": 75248,
      "expansion_time_ms": 3553272
    },
    "source_research": "/home/maceo/thoughts/repos/silmari-Context-Engine/shared/research/2026-01-09-building-writing-agent-ui.md",
    "decomposed_at": "2026-01-09T14:40:09.684877"
  }
}