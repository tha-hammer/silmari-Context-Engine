{
  "requirements": [
    {
      "id": "REQ_000",
      "description": "The system must organize the project into 14 main directories with distinct purposes for core functionality, language support, CLI automation, data utilities, and development resources",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_000.1",
          "description": "Maintain silmari_rlm_act/ as the main Python package directory containing the core RLM ACT implementation, including proper package initialization, module organization, and public API exposure",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "silmari_rlm_act/ directory exists at project root",
            "__init__.py file exists in silmari_rlm_act/ to mark it as a package",
            "All core RLM ACT implementation modules are contained within silmari_rlm_act/",
            "Package exports clear public API through __init__.py using __all__ or explicit imports",
            "Sub-modules are logically organized by functionality (e.g., models/, services/, utils/)",
            "Each sub-directory has its own __init__.py for proper package hierarchy",
            "Package can be imported successfully: 'from silmari_rlm_act import <module>'",
            "No circular dependencies between modules within the package",
            "Package follows Python naming conventions (lowercase with underscores)",
            "Core classes and functions are accessible from top-level package import",
            "Package metadata is defined in pyproject.toml with correct package name",
            "All Python files in package have proper docstrings and type hints",
            "Package structure supports both relative and absolute imports",
            "Version information is accessible via __version__ attribute"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - this is a backend package structure"
            ],
            "backend": [
              "Create/maintain silmari_rlm_act/__init__.py with package initialization",
              "Organize core RLM ACT modules into logical sub-directories",
              "Define public API exports in __init__.py",
              "Implement version management in __init__.py or version.py",
              "Create sub-packages for major functional areas (models, services, core)",
              "Ensure all modules follow single responsibility principle",
              "Implement proper logging configuration at package level",
              "Create package-level constants and configuration management"
            ],
            "middleware": [
              "No middleware components required - this is package structure organization"
            ],
            "shared": [
              "Define package __init__.py with __all__ exports list",
              "Create shared types.py for common type definitions",
              "Create shared constants.py for package-wide constants",
              "Create shared exceptions.py for custom exception classes",
              "Define shared interfaces/protocols for core abstractions",
              "Create shared utils/ sub-package for utility functions",
              "Implement package-level configuration dataclasses/schemas"
            ]
          },
          "testable_properties": [],
          "function_id": "ProjectStructure.maintainSilmariRlmActPackage",
          "related_concepts": [
            "Python package structure",
            "Module organization",
            "__init__.py initialization",
            "Public API design",
            "Import path management",
            "Package metadata",
            "Core business logic"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.2",
          "description": "Maintain planning_pipeline/ directory for pipeline orchestration logic, managing workflow execution, state transitions, and coordination between planning stages",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "planning_pipeline/ directory exists at project root",
            "__init__.py exists to mark planning_pipeline as a Python package",
            "Pipeline orchestration logic is contained within planning_pipeline/",
            "Pipeline stages are clearly defined and organized",
            "State management for pipeline execution is implemented",
            "Pipeline configuration files or modules are present",
            "Error handling and recovery mechanisms are implemented",
            "Pipeline can be executed via planning_orchestrator.py",
            "Pipeline supports resume functionality (linked to resume_pipeline.py)",
            "Each pipeline stage is independently testable",
            "Pipeline supports both sequential and parallel execution patterns",
            "Logging and monitoring hooks are integrated throughout pipeline",
            "Pipeline state can be persisted and restored",
            "Clear interfaces define input/output contracts for each stage"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - this is backend orchestration logic"
            ],
            "backend": [
              "Create/maintain planning_pipeline/__init__.py with pipeline exports",
              "Implement pipeline orchestrator class for execution control",
              "Create stage definitions module defining each pipeline stage",
              "Implement state management module for tracking pipeline state",
              "Create pipeline configuration loader and validator",
              "Implement stage executor with error handling and retry logic",
              "Create pipeline context object to pass data between stages",
              "Implement checkpoint/resume functionality for long-running pipelines",
              "Create pipeline scheduler for managing execution order",
              "Implement pipeline monitoring and metrics collection",
              "Create pipeline builder/factory for constructing pipelines",
              "Implement hooks system for pre/post stage execution"
            ],
            "middleware": [
              "Implement pipeline execution middleware for logging",
              "Create error handling middleware to catch and handle stage failures",
              "Implement state validation middleware between stages",
              "Create timeout middleware for stage execution limits"
            ],
            "shared": [
              "Define PipelineStage interface/protocol for stage implementations",
              "Create PipelineContext dataclass for shared pipeline state",
              "Define PipelineConfig schema for pipeline configuration",
              "Create StageResult dataclass for stage execution results",
              "Define PipelineState enum for execution states",
              "Create pipeline exceptions hierarchy",
              "Define stage metadata schemas for stage registration",
              "Create utility functions for pipeline state serialization"
            ]
          },
          "testable_properties": [],
          "function_id": "ProjectStructure.maintainPlanningPipelineDirectory",
          "related_concepts": [
            "Pipeline orchestration",
            "Workflow management",
            "State machine patterns",
            "Stage coordination",
            "Pipeline configuration",
            "Execution control",
            "Error handling in pipelines"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.3",
          "description": "Maintain agents/ directory for agent implementations, including agent definitions, configurations, behaviors, and agent orchestration logic",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "agents/ directory exists at project root",
            "__init__.py exists to mark agents as a Python package",
            "Agent base classes or interfaces are defined",
            "Individual agent implementations are organized within agents/",
            "Agent configuration files or schemas are present",
            "Agent registry or factory for instantiating agents exists",
            "Agent communication protocols are defined",
            "Agent lifecycle management (create, run, stop) is implemented",
            "Each agent has clear responsibilities and interfaces",
            "Agent configurations can be loaded from external files",
            "Agents can be instantiated and executed independently",
            "Agent monitoring and logging is implemented",
            "Agent error handling and recovery is in place",
            "Documentation exists for each agent type and its purpose"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - this is backend agent logic"
            ],
            "backend": [
              "Create/maintain agents/__init__.py with agent exports",
              "Implement BaseAgent abstract class or protocol",
              "Create individual agent implementation files (e.g., planning_agent.py)",
              "Implement agent factory or registry for agent instantiation",
              "Create agent configuration loader and validator",
              "Implement agent lifecycle manager (start, stop, restart)",
              "Create agent communication layer for inter-agent messaging",
              "Implement agent state management and persistence",
              "Create agent scheduler for managing agent execution",
              "Implement agent monitoring and health check mechanisms",
              "Create agent capability registry for discovering agent features",
              "Implement agent error handling and exception recovery"
            ],
            "middleware": [
              "Implement agent execution middleware for logging and monitoring",
              "Create authentication middleware for agent identity verification",
              "Implement rate limiting middleware for agent API calls",
              "Create context injection middleware for agent execution environment"
            ],
            "shared": [
              "Define Agent interface/protocol with standard methods",
              "Create AgentConfig dataclass for agent configuration",
              "Define AgentState enum for agent lifecycle states",
              "Create AgentMessage dataclass for inter-agent communication",
              "Define AgentCapability interface for capability definitions",
              "Create agent exceptions hierarchy",
              "Define AgentMetadata schema for agent registration",
              "Create utility functions for agent serialization and deserialization",
              "Define AgentResult dataclass for agent execution results"
            ]
          },
          "testable_properties": [],
          "function_id": "ProjectStructure.maintainAgentsDirectory",
          "related_concepts": [
            "Agent architecture",
            "Agent behaviors",
            "Agent configuration",
            "Multi-agent systems",
            "Agent communication",
            "Agent lifecycle",
            "Agent registry"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.4",
          "description": "Maintain baml_src/ and baml_client/ directories for BAML (Bayesian Approximate Machine Learning) integration, including source configurations, generated client code, and integration interfaces",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "baml_src/ directory exists at project root for BAML source files",
            "baml_client/ directory exists at project root for generated client code",
            "baml_src/ contains BAML configuration and definition files",
            "baml_client/ contains Python client code generated from BAML definitions",
            "baml_client/__init__.py exists to expose client functionality",
            "BAML client can be imported and used from Python code",
            "BAML definitions are version controlled in baml_src/",
            "Generated client code in baml_client/ is gitignored or clearly marked as generated",
            "Build process includes BAML client generation step",
            "BAML client provides type-safe interfaces to ML models",
            "Integration tests verify BAML client functionality",
            "Documentation exists for BAML configuration and client usage",
            "Error handling is implemented for BAML client failures",
            "BAML client supports async operations where applicable"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - this is backend ML integration"
            ],
            "backend": [
              "Maintain baml_src/ directory structure for BAML definitions",
              "Create BAML configuration files defining models and interfaces",
              "Set up BAML code generation tooling and scripts",
              "Configure build process to generate baml_client/ code from baml_src/",
              "Create wrapper services around generated BAML client for business logic",
              "Implement error handling and retry logic for BAML client calls",
              "Create BAML client initialization and configuration module",
              "Implement model versioning and migration strategies",
              "Create monitoring and logging for BAML client usage",
              "Implement caching layer for BAML client responses",
              "Create integration layer connecting BAML client to core application",
              "Implement request/response transformation logic"
            ],
            "middleware": [
              "Implement request validation middleware for BAML client inputs",
              "Create response transformation middleware for BAML outputs",
              "Implement error handling middleware for BAML client failures",
              "Create logging middleware to track BAML client usage and performance"
            ],
            "shared": [
              "Define interfaces wrapping generated BAML client types",
              "Create configuration schemas for BAML client initialization",
              "Define request/response dataclasses for BAML operations",
              "Create BAML client exceptions hierarchy",
              "Define type aliases for BAML-specific types",
              "Create utility functions for BAML data transformation",
              "Define constants for BAML model names and versions",
              "Create validation schemas for BAML inputs and outputs",
              "Define mock objects for testing BAML integrations"
            ]
          },
          "testable_properties": [],
          "function_id": "ProjectStructure.maintainBamlIntegration",
          "related_concepts": [
            "BAML integration",
            "Generated client code",
            "ML model integration",
            "Code generation",
            "BAML configuration",
            "Type-safe ML interfaces",
            "Model versioning"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.5",
          "description": "Maintain go/ directory for Go language components, including Go modules, Go-Python interoperability, performance-critical implementations, and Go package organization",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "go/ directory exists at project root",
            "go.mod file exists at project root defining Go module",
            "go.sum file exists for dependency verification",
            "Go source files are organized within go/ directory",
            "Go packages follow standard Go project structure",
            "Go code can be built independently using 'go build'",
            "Go-Python interoperability is implemented (if required)",
            "Performance-critical components are implemented in Go",
            "Go code includes proper package documentation",
            "Go tests are present and can run with 'go test'",
            "Build scripts include Go compilation steps",
            "Go binaries are output to dist/ directory",
            "Go code follows Go conventions and passes 'go vet' and 'golint'",
            "Clear interfaces define communication between Go and Python components"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - this is backend Go implementation"
            ],
            "backend": [
              "Maintain go/ directory structure following Go project conventions",
              "Create Go package structure (cmd/, internal/, pkg/ if needed)",
              "Implement performance-critical components in Go",
              "Create Go-Python interop layer using CGO or gRPC",
              "Implement Go service interfaces matching Python equivalents",
              "Create Go build scripts and Makefiles",
              "Implement Go logging using standard Go logging libraries",
              "Create Go configuration loading from environment or files",
              "Implement Go error handling following Go idioms",
              "Create Go test files for all packages",
              "Implement Go benchmarks for performance-critical code",
              "Create Go documentation using godoc comments"
            ],
            "middleware": [
              "Implement Go middleware for HTTP handlers (if applicable)",
              "Create logging middleware for request/response tracking",
              "Implement error recovery middleware",
              "Create metrics collection middleware"
            ],
            "shared": [
              "Define Go structs matching Python dataclasses",
              "Create Go interfaces for shared abstractions",
              "Define Go constants matching Python constants",
              "Create Go utility packages for common operations",
              "Define Go error types for error handling",
              "Create Go configuration structs",
              "Define protocol buffers or JSON schemas for Go-Python communication",
              "Create Go type aliases for clarity",
              "Implement Go serialization/deserialization utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "ProjectStructure.maintainGoDirectory",
          "related_concepts": [
            "Go modules",
            "Go-Python interop",
            "Performance optimization",
            "Multi-language architecture",
            "CGO bindings",
            "Go package structure",
            "Go build process"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_001",
      "description": "The system must implement a Core Application Layer consisting of silmari_rlm_act/ for main Python implementation, planning_pipeline/ for pipeline orchestration, and agents/ for agent system functionality",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_001.1",
          "description": "Implement RLM ACT system in silmari_rlm_act/ Python package",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.implement",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_001.2",
          "description": "Implement pipeline orchestration in planning_pipeline/ module",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.implement",
          "related_concepts": [],
          "category": "functional"
        },
        {
          "id": "REQ_001.3",
          "description": "Implement agent configurations in agents/ module",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [],
          "implementation": null,
          "testable_properties": [],
          "function_id": "Service.implement",
          "related_concepts": [],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_002",
      "description": "The system must support multi-language architecture with Python-first development and Go support for performance-critical components, including BAML integration with dedicated source and client directories",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_002.1",
          "description": "Maintain baml_src/ directory structure with BAML configuration files, type definitions, function declarations, and prompt templates for Bayesian Approximate Machine Learning integration",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "baml_src/ directory exists at project root with proper permissions (755)",
            "Directory contains organized subdirectories for types/, functions/, and prompts/",
            "All BAML type definitions (.baml files) follow BAML syntax specification",
            "Function declarations include input/output type annotations",
            "Prompt templates use BAML templating syntax with proper variable interpolation",
            "Configuration files include client connection settings (API keys, endpoints)",
            "All BAML files pass syntax validation via BAML CLI validator",
            "README or documentation exists explaining baml_src/ structure",
            "Files use consistent naming convention (snake_case or camelCase)",
            "Version control ignores sensitive configuration (API keys in .env, not in .baml)",
            "Type definitions are reusable across multiple functions",
            "Error handling specifications are defined for each function"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend components required",
              "Documentation page showing available BAML functions and their signatures"
            ],
            "backend": [
              "File system organization service to create and maintain baml_src/ structure",
              "BAML syntax validation service integrated into build pipeline",
              "Configuration loader to read BAML settings from baml_src/",
              "Type definition registry to track all BAML types",
              "Function registry to catalog all declared BAML functions",
              "Prompt template validator to check variable bindings",
              "Migration service to update BAML schemas when specification changes"
            ],
            "middleware": [
              "File system access control to restrict BAML source modifications",
              "Build-time validation middleware to check BAML syntax before deployment",
              "Configuration validation to ensure required settings are present",
              "Schema versioning middleware to track BAML specification compatibility"
            ],
            "shared": [
              "BAMLSourceConfig data model defining directory structure",
              "BAMLTypeDefinition interface for type schemas",
              "BAMLFunctionDeclaration interface for function signatures",
              "BAMLPromptTemplate interface for prompt structure",
              "Constants for BAML file extensions (.baml)",
              "Utility functions for BAML file path resolution",
              "Validation utilities for BAML syntax checking",
              "Error types for BAML configuration errors"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLConfiguration.maintainSourceFiles",
          "related_concepts": [
            "BAML type system",
            "Prompt engineering",
            "Function declarations",
            "Type safety",
            "Configuration management",
            "Version control",
            "Schema validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.2",
          "description": "Automatically generate Python client code from BAML source files in baml_src/, output to baml_client/ directory, and maintain synchronization between source definitions and generated client code",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "baml_client/ directory exists at project root with __init__.py",
            "Client generation runs automatically when baml_src/ files change",
            "Generated Python code includes type-safe function wrappers for all BAML functions",
            "Generated code includes Python type hints matching BAML type definitions",
            "Client code is importable as a Python package (from baml_client import ...)",
            "Generated client handles async/await patterns for LLM calls",
            "Error handling code is generated for each BAML function",
            "Client includes retry logic and timeout handling",
            "Generated code passes mypy type checking",
            "Build process regenerates client if baml_src/ is newer than baml_client/",
            "Generated files include header comments indicating auto-generation",
            "Client supports connection configuration (API keys, base URLs)",
            "Generated client includes documentation strings from BAML source"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend components required",
              "Developer documentation showing how to import and use baml_client",
              "Code examples demonstrating client usage patterns"
            ],
            "backend": [
              "BAML compiler service to parse baml_src/ files into AST",
              "Code generator service to transform BAML AST into Python code",
              "File writer service to output generated code to baml_client/",
              "Build hook to trigger regeneration on source changes",
              "Type mapper service to convert BAML types to Python type hints",
              "Client wrapper generator for async function calls",
              "Error handling code generator for exceptions",
              "Retry logic generator with exponential backoff",
              "Configuration loader for client connection settings",
              "Cache service to avoid unnecessary regeneration",
              "Dependency resolver to handle BAML type dependencies"
            ],
            "middleware": [
              "Build middleware to integrate BAML generation into CI/CD pipeline",
              "File watching middleware to detect baml_src/ changes in development",
              "Validation middleware to ensure generated code compiles",
              "Version checking middleware to ensure BAML compiler compatibility"
            ],
            "shared": [
              "BAMLClientConfig data model for client settings",
              "BAMLGeneratedFunction interface for generated function structure",
              "BAMLTypeMapping utility to map BAML types to Python types",
              "CodeGenerationContext model tracking generation state",
              "Constants for generated file templates",
              "Utility functions for Python code formatting",
              "Error types for generation failures",
              "Client base class that generated code extends",
              "Connection pool interface for BAML service connections",
              "Retry policy configuration model"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLClient.generateAndMaintainClient",
          "related_concepts": [
            "Code generation",
            "Client SDK",
            "Type safety",
            "API bindings",
            "Automatic synchronization",
            "Build automation",
            "Dependency management",
            "Python type hints"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.3",
          "description": "Implement performance-critical components in Go language within go/ package, maintain go.mod and go.sum dependency files, and provide interoperability with Python codebase through appropriate interfaces",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "go/ directory exists at project root with proper Go module structure",
            "go.mod file defines module name (e.g., github.com/silmari/context-engine/go)",
            "go.sum file tracks checksums for all Go dependencies",
            "Go version specified in go.mod is >= 1.18 for generics support",
            "All Go code passes 'go build' without errors",
            "Go code follows standard Go project layout (cmd/, pkg/, internal/)",
            "Python-Go interface defined using gRPC, CGo, or subprocess communication",
            "Performance benchmarks show Go components perform 2-10x faster than Python equivalents",
            "Go modules include proper error handling and logging",
            "Documentation explains which components are implemented in Go and why",
            "Integration tests verify Python can call Go components successfully",
            "Go code includes unit tests with >80% coverage",
            "Build process compiles Go binaries for target platforms",
            "Go dependencies are compatible with project's Go version"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend components required",
              "Performance metrics dashboard showing Go component throughput",
              "Developer documentation on when to use Go vs Python components"
            ],
            "backend": [
              "Go module initialization service (go mod init)",
              "Dependency management service (go mod tidy, go mod download)",
              "Performance-critical algorithm implementations in Go (e.g., context window processing, vector operations)",
              "gRPC server in Go exposing performance-critical functions",
              "Python client library to call Go gRPC services",
              "CGo wrapper functions for direct Python-Go integration if needed",
              "Build service to compile Go binaries as part of main build",
              "Performance monitoring service to track Go component metrics",
              "Error translation service between Go and Python error types",
              "Logging bridge to unify Go and Python logs",
              "Health check service for Go components"
            ],
            "middleware": [
              "gRPC middleware for authentication and authorization",
              "Request validation middleware in Go services",
              "Logging middleware to capture Go service requests",
              "Metrics collection middleware for Prometheus/monitoring",
              "Circuit breaker middleware for Go service resilience"
            ],
            "shared": [
              "Go module configuration (go.mod, go.sum)",
              "Protocol Buffer definitions for Python-Go communication",
              "Shared data structure definitions in both Go and Python",
              "Constants for service endpoints and ports",
              "Error code mappings between Go and Python",
              "Configuration models in both languages",
              "Utility functions for data serialization/deserialization",
              "Interface definitions for Python-Go contracts",
              "Build scripts to compile and distribute Go binaries",
              "Docker configuration to include Go runtime"
            ]
          },
          "testable_properties": [],
          "function_id": "GoComponents.implementPerformanceModules",
          "related_concepts": [
            "Go modules",
            "Performance optimization",
            "Language interoperability",
            "CGo bindings",
            "gRPC communication",
            "Dependency management",
            "Cross-compilation",
            "Python-Go bridge"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.4",
          "description": "Configure BAML (Bayesian Approximate Machine Learning) services integration including API authentication, endpoint configuration, model selection, prompt optimization settings, and monitoring for LLM service interactions",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "BAML service configuration file exists (e.g., baml_config.yaml or .env)",
            "API keys and secrets are stored securely (environment variables, secrets manager)",
            "Multiple LLM provider support configured (OpenAI, Anthropic, etc.)",
            "Model selection logic allows per-function model override",
            "Rate limiting configured to respect provider limits",
            "Timeout settings defined for LLM API calls (default: 30-60 seconds)",
            "Retry logic configured with exponential backoff",
            "Fallback provider configured if primary provider fails",
            "Cost tracking enabled to monitor API usage",
            "Logging configured to capture request/response metadata (without sensitive data)",
            "Request batching configured where supported by provider",
            "Prompt caching enabled to reduce duplicate API calls",
            "Connection pooling configured for HTTP clients",
            "Health check endpoint verifies BAML service connectivity"
          ],
          "implementation": {
            "frontend": [
              "Admin UI for BAML configuration management",
              "Model selection dropdown in function configuration",
              "API usage dashboard showing costs and request volumes",
              "Real-time monitoring of BAML service health",
              "Alert notifications for API errors or rate limit warnings"
            ],
            "backend": [
              "Configuration loader service to read BAML settings",
              "Secrets manager integration for API key retrieval",
              "LLM provider factory to instantiate provider clients",
              "Request router to select appropriate provider and model",
              "Rate limiter service to enforce request quotas",
              "Timeout manager for API call duration limits",
              "Retry handler with exponential backoff and jitter",
              "Fallback orchestrator to switch providers on failure",
              "Cost calculator service to estimate and track API costs",
              "Request logger to capture metadata without exposing secrets",
              "Caching service to store and retrieve prompt responses",
              "Batch processor for multiple prompt requests",
              "Connection pool manager for HTTP clients",
              "Health check service to ping BAML providers periodically",
              "Metrics collector for Prometheus/monitoring integration"
            ],
            "middleware": [
              "Authentication middleware to inject API keys into requests",
              "Rate limiting middleware to block requests exceeding quotas",
              "Request logging middleware to capture timing and metadata",
              "Error handling middleware to transform provider errors into standard format",
              "Caching middleware to check cache before making API calls",
              "Cost tracking middleware to log estimated costs per request"
            ],
            "shared": [
              "BAMLServiceConfig data model for provider settings",
              "LLMProviderConfig interface for provider-specific configuration",
              "ModelConfig model defining model name, max tokens, temperature, etc.",
              "RateLimitConfig model for quota and time window settings",
              "RetryPolicy model for retry attempts and backoff strategy",
              "CostConfig model for pricing per provider and model",
              "Constants for default timeouts, retry counts, and rate limits",
              "Error types for BAML service errors (RateLimitError, TimeoutError, etc.)",
              "Utility functions for API key validation",
              "Monitoring metrics interfaces for observability",
              "Health status enum (Healthy, Degraded, Unavailable)"
            ]
          },
          "testable_properties": [],
          "function_id": "BAMLServices.configureIntegration",
          "related_concepts": [
            "LLM integration",
            "API authentication",
            "Service configuration",
            "Prompt optimization",
            "Model selection",
            "Rate limiting",
            "Cost monitoring",
            "Error handling",
            "Fallback strategies"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_003",
      "description": "The system must provide CLI interface through commands/ directory and context window management utilities through context_window_array/ directory",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_003.1",
          "description": "Implement CLI command to find and display the next feature to implement with priority, dependencies, and verification steps",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Command checks claude-progress.txt for IN PROGRESS features first",
            "If no in-progress work, finds highest priority incomplete feature from feature_list.json",
            "Verifies all dependencies are met before recommending a feature",
            "Displays feature ID, description, priority, dependencies status, and verification steps",
            "Shows clear BLOCKED message if dependencies are not complete",
            "Calculates and displays estimated complexity based on verification steps count",
            "Command is accessible via 'silmari-rlm-act next' or as standalone script",
            "Gracefully handles missing or malformed JSON files with clear error messages",
            "Returns appropriate exit codes (0 for success, 1 for blocked/error)"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "commands/next.py - Main command implementation with Click decorator",
              "Parse feature_list.json to extract features with .passes==false",
              "Sort features by priority field (ascending order)",
              "Read claude-progress.txt and search for 'Status: IN PROGRESS' pattern",
              "Implement dependency checker that validates all dependencies have .passes==true",
              "Format output with feature metadata (ID, description, priority, dependencies)",
              "Display verification steps as numbered list",
              "Calculate complexity score based on steps count",
              "Integrate with main CLI group in silmari_rlm_act/cli.py"
            ],
            "middleware": [
              "File existence validation for feature_list.json and claude-progress.txt",
              "JSON schema validation for feature_list structure",
              "Error handling for file I/O operations"
            ],
            "shared": [
              "commands/utils/feature_parser.py - FeatureList data model with Feature class",
              "commands/utils/progress_parser.py - ProgressTracker for parsing claude-progress.txt",
              "commands/utils/dependency_resolver.py - DependencyChecker class",
              "JSON schema for feature_list.json validation",
              "Shared formatting utilities for terminal output"
            ]
          },
          "testable_properties": [],
          "function_id": "commands.NextCommand.execute",
          "related_concepts": [
            "feature_list.json parsing",
            "claude-progress.txt status tracking",
            "priority-based task selection",
            "dependency resolution",
            "jq-style JSON querying in Python"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.2",
          "description": "Implement CLI command to show comprehensive project status including git state, feature progress, and recent session activity",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Displays git status output in short format showing modified/staged files",
            "Shows last 10 git commits with oneline format (hash + message)",
            "Calculates and displays feature progress metrics: total, completed, remaining counts",
            "Extracts and displays last 30 lines from claude-progress.txt as recent session info",
            "Presents information in organized sections with clear headers",
            "Highlights uncommitted changes if present",
            "Shows completion percentage for features",
            "Command is accessible via 'silmari-rlm-act status' or as standalone script",
            "Gracefully handles cases where git is not initialized or files are missing",
            "Formatted output is easy to scan with visual separators"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "commands/status.py - Main command implementation with Click decorator",
              "Execute 'git status --short' subprocess call and capture output",
              "Execute 'git log --oneline -10' subprocess call for recent commits",
              "Parse feature_list.json to calculate completion metrics",
              "Read last 30 lines from claude-progress.txt using tail or file seek",
              "Format output with section headers (=== separators)",
              "Calculate completion percentage from passes field in features array",
              "Integrate with main CLI group in silmari_rlm_act/cli.py"
            ],
            "middleware": [
              "Git availability check before executing git commands",
              "Subprocess error handling for git operations",
              "File existence validation with fallback behavior"
            ],
            "shared": [
              "commands/utils/git_wrapper.py - GitStatus class for git operations",
              "commands/utils/feature_parser.py - Reuse FeatureList from next command",
              "commands/utils/progress_parser.py - Reuse ProgressTracker from next command",
              "commands/utils/metrics_calculator.py - StatusMetrics class for aggregating stats",
              "Shared terminal output formatting utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "commands.StatusCommand.execute",
          "related_concepts": [
            "git status integration",
            "git log parsing",
            "feature_list.json metrics",
            "claude-progress.txt session tracking",
            "multi-source status aggregation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.3",
          "description": "Provide data structure utilities for exporting and importing context entries to/from various formats (JSON, pickle, compressed) for persistence and sharing",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Supports export to JSON format with human-readable structure",
            "Supports export to pickle format for Python-native serialization",
            "Supports compressed export (gzip) for large context stores",
            "Import function can restore full context store from exported files",
            "Preserves all ContextEntry fields including metadata, TTL, references",
            "Handles circular references in derived_from and references fields",
            "Validates imported data against ContextEntry schema before loading",
            "Provides batch export for multiple entries with filtering options",
            "Includes metadata in exports (timestamp, version, entry count)",
            "Export/import operations are atomic (succeed completely or fail completely)",
            "Supports partial imports (merge with existing store without overwriting)",
            "Command-line utilities available for export/import operations"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "context_window_array/utils/serializer.py - ContextSerializer class",
              "Implement to_json() method using ContextEntry.to_dict()",
              "Implement from_json() method using ContextEntry.from_dict()",
              "Implement to_pickle() using pickle module with protocol 5",
              "Implement from_pickle() with error handling for version mismatches",
              "Implement compress()/decompress() using gzip module",
              "Add export_store() method that iterates all entries and serializes",
              "Add import_store() method that validates and loads entries into CentralContextStore",
              "Handle datetime serialization/deserialization with ISO format",
              "Add filtering options (by entry_type, date range, searchable flag)"
            ],
            "middleware": [
              "JSON schema validation for import operations",
              "File format detection (JSON vs pickle vs compressed)",
              "Version compatibility checking for imports",
              "Atomic file operations with temporary files and rename",
              "Error recovery with detailed error messages"
            ],
            "shared": [
              "context_window_array/utils/__init__.py - Export ContextSerializer",
              "context_window_array/utils/validators.py - Schema validators for imports",
              "context_window_array/utils/compression.py - Compression utilities",
              "commands/export_context.py - CLI command for exporting context",
              "commands/import_context.py - CLI command for importing context",
              "Integration with existing CentralContextStore methods",
              "Documentation for export/import file formats",
              "Migration utilities for upgrading old context formats"
            ]
          },
          "testable_properties": [],
          "function_id": "context_window_array.utils.ContextSerializer.export_to_file",
          "related_concepts": [
            "context persistence",
            "serialization/deserialization",
            "checkpoint management",
            "context state recovery",
            "format conversion",
            "compression for large contexts"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.4",
          "description": "Implement CLI command to troubleshoot pipeline failures by analyzing logs, context state, and providing diagnostic information with suggested fixes",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Analyzes most recent pipeline execution logs for errors and warnings",
            "Inspects context window array state (entry counts, compressed entries, TTL status)",
            "Checks for common issues (missing dependencies, permission errors, API failures)",
            "Displays stack traces with highlighted error messages",
            "Suggests specific fixes based on error patterns (e.g., 'Run pip install X' for import errors)",
            "Shows recent test failures with file paths and line numbers",
            "Provides context entry diagnostics (expired entries, missing references)",
            "Validates project configuration files (pyproject.toml, feature_list.json)",
            "Command accessible via 'silmari-rlm-act debug' with optional --verbose flag",
            "Outputs actionable recommendations in priority order",
            "Supports --last-n flag to analyze last N pipeline runs"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "commands/debug.py - Main debug command with Click decorator",
              "Implement log parser to extract errors/warnings from pipeline logs",
              "Query CentralContextStore for diagnostic metrics (count, compressed, expired)",
              "Pattern matching for common errors (ImportError, FileNotFoundError, APIError)",
              "Test failure parser for pytest output extraction",
              "Configuration file validator using JSON schema",
              "Recommendation engine that maps error types to fix suggestions",
              "Stack trace formatter with syntax highlighting",
              "Integration with existing CWAIntegration for context inspection"
            ],
            "middleware": [
              "Log file location detection (output/, logs/ directories)",
              "Permission checks for log file access",
              "Safe parsing of potentially malformed log files"
            ],
            "shared": [
              "commands/utils/log_parser.py - LogAnalyzer class for parsing logs",
              "commands/utils/error_patterns.py - ErrorPattern database with fix suggestions",
              "commands/utils/config_validator.py - ConfigValidator for project files",
              "commands/utils/test_parser.py - TestFailureParser for pytest output",
              "context_window_array/diagnostics.py - ContextDiagnostics class for CWA inspection",
              "Shared utilities for syntax highlighting terminal output",
              "Database of common error patterns and solutions"
            ]
          },
          "testable_properties": [],
          "function_id": "commands.DebugCommand.execute",
          "related_concepts": [
            "log analysis",
            "error diagnosis",
            "context state inspection",
            "common failure patterns",
            "troubleshooting workflows",
            "test failure analysis"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.5",
          "description": "Implement CLI command to identify and display current blockers including failed dependencies, missing resources, and unresolved issues preventing progress",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Scans feature_list.json for features blocked by incomplete dependencies",
            "Identifies missing files or resources referenced in implementation plans",
            "Detects failed tests that block dependent features",
            "Checks for configuration issues (missing API keys, invalid paths)",
            "Lists blockers in priority order (highest priority features first)",
            "Shows blocker details: type, affected features, root cause, suggested resolution",
            "Displays dependency chains for complex blocking scenarios",
            "Provides clear actionable steps to unblock each item",
            "Command accessible via 'silmari-rlm-act blockers'",
            "Supports filtering by blocker type (dependency, resource, configuration, test)",
            "Shows estimated impact (number of features blocked by each issue)"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "commands/blockers.py - Main blockers command with Click decorator",
              "Dependency graph analyzer to find blocked features in feature_list.json",
              "Resource checker that validates file paths and external dependencies",
              "Test failure analyzer that links failures to dependent features",
              "Configuration validator for required settings and credentials",
              "Blocker prioritization algorithm based on feature priority and impact",
              "Dependency chain builder for visualizing blocking relationships",
              "Action recommender that suggests resolution steps per blocker"
            ],
            "middleware": [
              "File system access validation",
              "Test result parsing from pytest cache",
              "Environment variable checking for configuration"
            ],
            "shared": [
              "commands/utils/dependency_resolver.py - Enhanced with blocking analysis",
              "commands/utils/resource_checker.py - ResourceValidator class",
              "commands/utils/blocker_detector.py - BlockerAnalyzer with detection logic",
              "commands/utils/impact_calculator.py - ImpactCalculator for affected features",
              "Integration with feature_parser.py for dependency graph",
              "Shared data models for Blocker types and resolutions"
            ]
          },
          "testable_properties": [],
          "function_id": "commands.BlockersCommand.execute",
          "related_concepts": [
            "dependency blocking detection",
            "resource availability checking",
            "issue tracking integration",
            "critical path analysis",
            "blocker prioritization"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_004",
      "description": "The system must isolate build artifacts in dist/ directory and runtime output in output/ directory with clear separation from source code",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_004.1",
          "description": "Generate build artifacts and compiled packages in dist/ directory for Python packages, Go binaries, and BAML-generated clients with proper version tagging and platform-specific builds",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "dist/ directory must contain Python wheel (.whl) files generated via poetry build for silmari-rlm-act package",
            "dist/ directory must contain Python source distribution (.tar.gz) files for silmari-rlm-act package",
            "dist/ directory must contain Go binary executables for context-engine and loop-runner built from go/cmd/ source",
            "Go binaries must support cross-platform builds (darwin-amd64, darwin-arm64, linux-amd64, linux-arm64, windows-amd64) as defined in go/Makefile",
            "All dist/ artifacts must include version information from git tags or pyproject.toml version field",
            "Build process must strip debug symbols and optimize binary size using ldflags -s -w for Go builds",
            "Wheel files must include all packages defined in pyproject.toml packages section (silmari_rlm_act, planning_pipeline, context_window_array)",
            "dist/ directory must be automatically created if it doesn't exist before build",
            "Build artifacts must be named with semantic version pattern: {package}-{version}-{platform}.{ext}",
            "BAML client code in baml_client/ must be generated before Python package build if baml_src/ has changes",
            "Build process must validate that all required dependencies from pyproject.toml are available",
            "Go builds must embed version, git commit hash, and build date metadata using ldflags",
            "Build system must fail cleanly with descriptive error messages if source files are missing or invalid",
            "dist/ directory must never contain source code files, only compiled/packaged artifacts"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Build orchestration script or Makefile target that coordinates Python and Go builds",
              "Poetry build command integration: poetry build --format wheel && poetry build --format sdist",
              "Go Makefile integration for cross-platform builds: make -C go build-all",
              "Pre-build hook to run BAML code generation if baml_src/ directory exists and has modifications",
              "Version extraction service to read version from pyproject.toml [tool.poetry.version] and git describe --tags",
              "Build artifact validation service to verify file integrity and format correctness",
              "Build cleanup service to remove stale artifacts before new build",
              "Platform detection service to determine current OS/architecture for native builds",
              "Build logging service to capture build output and errors to dist/build.log"
            ],
            "middleware": [
              "Build permission checks to ensure write access to dist/ directory",
              "Git repository validation to ensure git commands work for version extraction",
              "Dependency resolution validation before build starts",
              "Lock file verification for poetry.lock and go.sum to ensure reproducible builds"
            ],
            "shared": [
              "BuildConfig model defining build targets, platforms, and output paths",
              "ArtifactMetadata model storing version, commit, timestamp, platform info",
              "BuildResult model containing success status, artifact paths, and error details",
              "Constants for dist/ path, artifact name patterns, supported platforms",
              "Utility functions: get_version(), get_git_commit(), generate_artifact_name(), validate_artifact()",
              "DIST_DIR constant pointing to project_root/dist/",
              "PLATFORM_MAPPINGS dictionary for GOOS/GOARCH combinations"
            ]
          },
          "testable_properties": [],
          "function_id": "BuildSystem.generateDistArtifacts",
          "related_concepts": [
            "poetry build",
            "go build",
            "cross-compilation",
            "semantic versioning",
            "wheel distribution",
            "tarball distribution",
            "binary compilation",
            "BAML code generation",
            "build automation",
            "artifact naming conventions"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.2",
          "description": "Generate runtime artifacts and output files in output/ directory including analysis results, context generation outputs, checkpoint files, and execution logs with structured organization by project and timestamp",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "output/ directory must be organized by project with subdirectories: output/{project-name}/groups/, output/{project-name}/checkpoints/, output/{project-name}/logs/",
            "Context generation must produce file_groups.json in output/{project-name}/groups/ containing grouped file listings from codebase analysis",
            "Context generation must produce tech_stack.json in output/{project-name}/groups/ containing detected languages, frameworks, testing tools, and build systems",
            "Planning pipeline checkpoints must be saved to output/{project-name}/checkpoints/ with naming pattern: checkpoint_{step}_{timestamp}.json",
            "Execution logs must be written to output/{project-name}/logs/ with naming pattern: {component}_{timestamp}.log",
            "All output files must be valid JSON or text format with proper encoding (UTF-8)",
            "Output directory structure must be automatically created including all necessary subdirectories",
            "File_groups.json must include file paths, group names, and purpose descriptions as shown in research context",
            "Tech_stack.json must include languages, frameworks, testing_frameworks, and build_systems arrays",
            "Output files must include metadata headers with generation timestamp, researcher name, git commit, and branch",
            "Output directory must support concurrent writes from multiple pipeline stages without file corruption",
            "Old output files must be retained with timestamps for audit trail and debugging",
            "Output file paths must be resolved relative to project root, not absolute paths",
            "Runtime output must never include build artifacts like .whl, .tar.gz, or binary executables"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "OutputManager service for coordinating all runtime output operations",
              "ContextGenerationService to analyze codebase and produce file_groups.json and tech_stack.json using TechStackResult dataclass from planning_pipeline/context_generation.py",
              "CheckpointPersistence service to save and restore pipeline state using planning_pipeline/checkpoint_manager.py",
              "LoggingService to handle structured logging to output/{project}/logs/ directory",
              "OutputPathResolver service to generate correct output paths based on project name and output type",
              "DirectoryCreationService to ensure output subdirectories exist before writing",
              "FileWriteService with atomic write operations using temp files and rename for safety",
              "MetadataInjectionService to add headers with timestamp, git info, and researcher details",
              "OutputCleanupService to manage retention policies and archive old outputs if needed"
            ],
            "middleware": [
              "Write permission validation for output/ directory before execution",
              "File locking mechanism to prevent concurrent write conflicts using fcntl or similar",
              "Output size monitoring to prevent disk space exhaustion",
              "Error handling for filesystem failures with retry logic"
            ],
            "shared": [
              "OutputConfig model defining output directory structure and naming conventions",
              "OutputMetadata model for file headers including timestamp, git commit, branch, researcher",
              "ProjectContext model containing project_name, root_path, branch for path resolution",
              "FileGroupData model matching the structure in file_groups.json (groups array with name, files, purpose)",
              "TechStackResult model from planning_pipeline/context_generation.py (languages, frameworks, testing_frameworks, build_systems)",
              "Constants: OUTPUT_DIR pointing to project_root/output/, GROUPS_SUBDIR='groups/', CHECKPOINTS_SUBDIR='checkpoints/', LOGS_SUBDIR='logs/'",
              "Utility functions: generate_output_path(), ensure_output_dirs(), write_json_safely(), get_project_metadata()",
              "TIMESTAMP_FORMAT constant for consistent timestamp formatting: 'YYYY-MM-DDTHH:MM:SS-TZ'"
            ]
          },
          "testable_properties": [],
          "function_id": "RuntimeSystem.generateOutputArtifacts",
          "related_concepts": [
            "runtime output management",
            "context generation",
            "checkpoint persistence",
            "execution logging",
            "analysis results",
            "file_groups.json",
            "tech_stack.json",
            "planning pipeline outputs",
            "dynamic file generation",
            "temporal organization"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.3",
          "description": "Maintain strict separation between build outputs (dist/), runtime artifacts (output/), and source code with gitignore rules, validation checks, and clear directory boundaries to prevent accidental mixing",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            ".gitignore must explicitly exclude dist/ directory to prevent build artifacts from being committed",
            ".gitignore must explicitly exclude output/ directory to prevent runtime artifacts from being committed",
            ".gitignore must NOT exclude source directories: silmari_rlm_act/, planning_pipeline/, context_window_array/, baml_src/, go/, agents/, commands/",
            "No Python source files (.py) must exist in dist/ or output/ directories",
            "No compiled binaries from dist/ must exist in source code directories",
            "No runtime logs or JSON outputs must exist in source code directories",
            "dist/ directory must only contain: .whl files, .tar.gz files, .exe files, and platform-specific binaries",
            "output/ directory must only contain: .json files, .log files, .txt files, and structured subdirectories",
            "Build scripts must validate that source files are not being written to dist/ or output/",
            "Runtime scripts must validate that they are not writing to source directories",
            "Path resolution must use absolute paths or project-root-relative paths to avoid accidental writes",
            "CI/CD pipeline must verify separation with automated checks before deployment",
            "Documentation must clearly define the purpose and contents of dist/, output/, and source directories",
            "Clean command must be able to remove dist/ and output/ completely without affecting source code",
            "New developers must not be able to accidentally commit dist/ or output/ contents based on .gitignore rules"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "DirectorySeparationValidator service to check for violations during build and runtime",
              "PathValidationService to ensure write operations target correct directories",
              "GitignoreUpdater service to maintain .gitignore rules programmatically if needed",
              "CleanupService with separate commands: clean-dist, clean-output, clean-all",
              "DirectoryAuditService to scan directories and report any misplaced files",
              "BuildGuardService to prevent writing non-artifact files to dist/",
              "RuntimeGuardService to prevent writing non-output files to output/",
              "SourceProtectionService to prevent writes to source directories from build/runtime processes",
              "CIValidationService to run separation checks in continuous integration"
            ],
            "middleware": [
              "Pre-build validation hook to check directory state before building",
              "Pre-runtime validation hook to check directory state before execution",
              "Post-operation validation hook to verify separation was maintained",
              "Path interception middleware to catch and block invalid write attempts"
            ],
            "shared": [
              "DirectoryConfig model defining allowed directories and file types for each zone",
              "SeparationRule model defining what belongs in dist/, output/, and source/",
              "ValidationResult model containing pass/fail status, violations found, and recommendations",
              "Constants: SOURCE_DIRS=['silmari_rlm_act', 'planning_pipeline', 'context_window_array', 'baml_src', 'go', 'agents', 'commands'], ARTIFACT_DIRS=['dist', 'output']",
              "ALLOWED_DIST_EXTENSIONS=['.whl', '.tar.gz', '.exe', '.bin', '.so']",
              "ALLOWED_OUTPUT_EXTENSIONS=['.json', '.log', '.txt', '.md']",
              "FORBIDDEN_SOURCE_WRITES=['dist/', 'output/']",
              "Utility functions: validate_write_path(), is_source_directory(), is_artifact_directory(), check_file_extension(), audit_directory_contents()",
              "GitignorePattern class to parse and validate .gitignore rules"
            ]
          },
          "testable_properties": [],
          "function_id": "SourceCodeIsolation.maintainSeparation",
          "related_concepts": [
            ".gitignore configuration",
            "directory structure enforcement",
            "source code protection",
            "clean architecture",
            "build hygiene",
            "artifact isolation",
            "version control exclusions",
            "directory validation",
            "path resolution",
            "anti-patterns prevention"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_005",
      "description": "The system must maintain development resources including tests/ for test suite, docs/ for documentation, thoughts/ for research and knowledge base, and silmari-messenger-plans/ for messenger-specific planning",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_005.1",
          "description": "Maintain comprehensive test suite including unit tests, integration tests, and test utilities in tests/ directory with proper organization, coverage tracking, and continuous integration support",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "tests/ directory exists with subdirectories for unit/, integration/, and utilities/",
            "All unit tests achieve minimum 80% code coverage for core modules",
            "Integration tests cover critical system workflows end-to-end",
            "Test utilities provide reusable fixtures, mocks, and helper functions",
            "pytest.ini configuration file specifies test discovery patterns and coverage settings",
            "conftest.py files provide shared fixtures at appropriate directory levels",
            "Each test file follows naming convention test_*.py or *_test.py",
            "All tests are executable via 'pytest' command from project root",
            "Test execution reports include coverage metrics and failed test details",
            "CI/CD pipeline automatically runs full test suite on pull requests",
            "Tests are isolated and can run in parallel without conflicts",
            "Test data fixtures are stored in tests/fixtures/ or tests/data/ directory",
            "Mock objects are used to isolate external dependencies (APIs, databases)",
            "Each test has clear docstrings explaining what is being tested",
            "Flaky tests are identified and marked with @pytest.mark.flaky decorator",
            "Performance tests exist for critical paths in tests/performance/",
            "Test requirements are specified in pyproject.toml [tool.poetry.dev-dependencies]"
          ],
          "implementation": {
            "frontend": [
              "No frontend components required - testing infrastructure only"
            ],
            "backend": [
              "Create tests/unit/ directory structure mirroring silmari_rlm_act/ package structure",
              "Create tests/integration/ for end-to-end workflow tests",
              "Create tests/utilities/ for shared test helpers and fixtures",
              "Implement test runners using pytest framework",
              "Configure coverage.py for code coverage tracking",
              "Create test fixtures for common test data scenarios",
              "Implement mock objects for external service dependencies",
              "Create performance test suite using pytest-benchmark",
              "Implement test database seeding and teardown utilities",
              "Create API client test fixtures for integration tests"
            ],
            "middleware": [
              "Configure pytest plugins for async testing (pytest-asyncio)",
              "Set up test database connection management",
              "Implement test authentication token generators",
              "Create middleware for test request/response capture",
              "Configure test environment variable management"
            ],
            "shared": [
              "Define TestConfig data model for test configuration settings",
              "Create TestDataFactory utility for generating test data",
              "Implement MockServiceProvider for service mocking",
              "Define test constants in tests/constants.py",
              "Create BaseTestCase class with common setup/teardown methods",
              "Implement assertion utility functions for common validations",
              "Define test fixture models in tests/models.py",
              "Create test logging configuration utilities"
            ]
          },
          "testable_properties": [],
          "function_id": "TestSuite.maintainTestDirectory",
          "related_concepts": [
            "test-driven development",
            "pytest framework",
            "test coverage metrics",
            "CI/CD integration",
            "test fixtures",
            "mocking and stubbing",
            "integration testing",
            "test isolation",
            "test data management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.2",
          "description": "Maintain comprehensive project documentation and user guides in docs/ directory including architecture documentation, API references, setup guides, and user tutorials with proper versioning and search capabilities",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "docs/ directory exists with subdirectories: architecture/, api/, guides/, tutorials/",
            "README.md exists at docs/ root with navigation to all documentation sections",
            "Architecture documentation includes system diagrams and component descriptions",
            "API documentation is auto-generated from code docstrings and type hints",
            "Setup guides cover installation, configuration, and environment setup",
            "User tutorials provide step-by-step instructions for common use cases",
            "All documentation files use consistent markdown formatting",
            "Documentation includes code examples with syntax highlighting",
            "CHANGELOG.md tracks all project changes by version",
            "Documentation is versioned to match software releases",
            "Internal links between documentation files are functional",
            "Documentation build process generates static site or PDF output",
            "Search functionality is available for documentation navigation",
            "Documentation includes troubleshooting section with common issues",
            "Contributing guidelines exist in docs/CONTRIBUTING.md",
            "All documentation is reviewed and updated quarterly",
            "Documentation includes glossary of domain-specific terms"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend - documentation may be rendered via static site generator",
              "If documentation site exists: navigation menu, search box, version selector"
            ],
            "backend": [
              "Create docs/architecture/ with system design documents",
              "Create docs/api/ for API endpoint documentation",
              "Create docs/guides/ for setup and configuration guides",
              "Create docs/tutorials/ for step-by-step user tutorials",
              "Implement documentation build script using Sphinx or MkDocs",
              "Create script to auto-generate API docs from code docstrings",
              "Implement documentation versioning system",
              "Create CHANGELOG.md generation from git commit history",
              "Set up documentation hosting (GitHub Pages, ReadTheDocs, or similar)",
              "Implement documentation link validation checks"
            ],
            "middleware": [
              "Configure documentation build pipeline in CI/CD",
              "Set up documentation deployment automation",
              "Implement documentation version routing",
              "Create pre-commit hooks to validate documentation links"
            ],
            "shared": [
              "Define DocumentationConfig for build settings",
              "Create markdown templates for consistent documentation structure",
              "Define documentation style guide constants",
              "Implement MarkdownValidator utility for format checking",
              "Create DocumentationIndex model for search functionality",
              "Define CodeExampleValidator for verifying code snippets",
              "Create DiagramRenderer utility for generating architecture diagrams",
              "Implement ChangelogGenerator utility for version tracking"
            ]
          },
          "testable_properties": [],
          "function_id": "Documentation.maintainDocsDirectory",
          "related_concepts": [
            "documentation-as-code",
            "markdown documentation",
            "API documentation",
            "architecture diagrams",
            "user guides",
            "onboarding documentation",
            "changelog management",
            "documentation versioning",
            "searchable documentation",
            "code examples"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.3",
          "description": "Maintain research documents, technical notes, decision logs (ADRs), and institutional knowledge in thoughts/ directory with proper categorization, searchability, and decision tracking for engineering decisions and research findings",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "thoughts/ directory exists with subdirectories: adr/, research/, rfcs/, investigations/",
            "Architecture Decision Records (ADRs) follow standardized template format",
            "Each ADR is numbered sequentially and includes status, context, decision, consequences",
            "Research documents are dated and tagged with relevant topics",
            "Investigation reports include problem statement, findings, and recommendations",
            "RFC (Request for Comments) documents follow proposal template",
            "All thought documents include metadata: date, author, status, tags",
            "Index file (INDEX.md) catalogs all thought documents by category",
            "Decision log tracks all major architectural and technical decisions",
            "Research findings are linked to related code implementations",
            "Thought documents use consistent markdown formatting with frontmatter",
            "Search tags are defined and consistently applied across documents",
            "Post-mortem reports exist for major incidents in thoughts/postmortems/",
            "Technical debt items are documented with severity and mitigation plans",
            "Thought documents are discoverable via grep/search by topic and tag",
            "Deprecated decisions are marked as superseded with references to new decisions",
            "Template files exist for ADRs, RFCs, and research documents"
          ],
          "implementation": {
            "frontend": [
              "No frontend components - internal knowledge management system"
            ],
            "backend": [
              "Create thoughts/adr/ for Architecture Decision Records",
              "Create thoughts/research/ for research findings and investigations",
              "Create thoughts/rfcs/ for Request for Comments proposals",
              "Create thoughts/investigations/ for problem investigation reports",
              "Create thoughts/postmortems/ for incident post-mortem analyses",
              "Implement ADR template generator script",
              "Create RFC template generator script",
              "Implement INDEX.md auto-generation from document metadata",
              "Create search indexing script for thought document discovery",
              "Implement decision log aggregator from ADR files",
              "Create validation script to check document frontmatter compliance",
              "Implement tag consistency checker across all thought documents"
            ],
            "middleware": [
              "Create pre-commit hook to validate new thought document formatting",
              "Implement git commit template for thought document changes",
              "Set up automated INDEX.md regeneration on document additions"
            ],
            "shared": [
              "Define ThoughtDocumentMetadata model with date, author, status, tags fields",
              "Create ADRTemplate with status, context, decision, consequences sections",
              "Define RFCTemplate with problem, proposal, alternatives, decision sections",
              "Implement FrontmatterParser utility for extracting document metadata",
              "Create DocumentIndexer for building searchable index",
              "Define TagValidator for ensuring tag consistency",
              "Implement MarkdownFrontmatterGenerator utility",
              "Create DecisionLogEntry model for tracking decision history",
              "Define ResearchDocument model with findings, references, conclusions",
              "Implement TemplateRenderer for generating new thought documents from templates"
            ]
          },
          "testable_properties": [],
          "function_id": "KnowledgeBase.maintainThoughtsDirectory",
          "related_concepts": [
            "architecture decision records",
            "knowledge management",
            "research documentation",
            "technical debt tracking",
            "decision logging",
            "institutional knowledge",
            "RFC process",
            "design proposals",
            "investigation reports",
            "post-mortem analysis"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.4",
          "description": "Maintain messenger-specific planning files, configurations, and agent definitions in silmari-messenger-plans/ directory with version control, plan templates, and execution tracking for messenger integration workflows",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "silmari-messenger-plans/ directory exists with organized plan files",
            "Plan files follow consistent naming convention (e.g., plan_<name>_<version>.yaml)",
            "Each plan file includes metadata: version, author, created_date, status",
            "Plan templates exist for common messenger integration patterns",
            "Plan files define agent configurations, roles, and coordination rules",
            "Messenger-specific communication protocols are documented in plans",
            "Plan validation schema ensures all required fields are present",
            "Version control tracks changes to plan files with descriptive commits",
            "Deprecated plans are archived in silmari-messenger-plans/archived/",
            "Active plans are cataloged in PLANS_INDEX.yaml or INDEX.md",
            "Plan execution logs reference specific plan file and version used",
            "Plan files support parameterization for different environments",
            "Integration tests validate plan file syntax and structure",
            "Plan migration guides exist when breaking changes are introduced",
            "Plan files include examples and usage instructions",
            "Plan review process ensures quality before activation",
            "Plan files are compatible with planning_pipeline/ orchestration logic"
          ],
          "implementation": {
            "frontend": [
              "No direct frontend - internal planning configuration system",
              "If planning UI exists: plan editor, version selector, validation feedback"
            ],
            "backend": [
              "Create silmari-messenger-plans/templates/ for plan templates",
              "Create silmari-messenger-plans/active/ for currently active plans",
              "Create silmari-messenger-plans/archived/ for deprecated plans",
              "Implement plan file parser supporting YAML/JSON formats",
              "Create plan validation service checking schema compliance",
              "Implement plan versioning system with semantic versioning",
              "Create plan loader integrated with planning_pipeline/ orchestration",
              "Implement plan execution tracker logging plan usage",
              "Create plan migration utility for upgrading deprecated plans",
              "Implement plan catalog generator creating PLANS_INDEX",
              "Create plan diff utility showing changes between versions",
              "Implement plan testing framework for integration validation"
            ],
            "middleware": [
              "Create plan validation middleware for pipeline execution",
              "Implement plan authorization checks for agent access",
              "Set up plan caching for performance optimization",
              "Create plan hot-reload mechanism for development"
            ],
            "shared": [
              "Define PlanMetadata model with version, author, status, timestamps",
              "Create PlanConfiguration model defining agents, roles, and workflows",
              "Define PlanValidationSchema for structural validation",
              "Implement PlanParser utility for parsing YAML/JSON plan files",
              "Create PlanValidator ensuring compliance with schema",
              "Define AgentConfiguration model for messenger agent settings",
              "Implement PlanVersionManager for version tracking",
              "Create PlanTemplate model for template-based plan generation",
              "Define MessengerProtocol interface for communication rules",
              "Implement PlanExecutionContext for runtime plan tracking",
              "Create PlanMigrator utility for upgrading plan formats",
              "Define PlanIndex model for cataloging available plans"
            ]
          },
          "testable_properties": [],
          "function_id": "MessengerPlanning.maintainPlanningDirectory",
          "related_concepts": [
            "messenger integration",
            "planning pipeline",
            "agent configuration",
            "workflow orchestration",
            "plan versioning",
            "execution tracking",
            "plan templates",
            "messenger protocols",
            "agent coordination",
            "plan validation"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_006",
      "description": "The system must provide root-level configuration with pyproject.toml for Python, go.mod/go.sum for Go modules, docker-compose.yml for containers, poetry.lock for dependencies, and pytest.ini/mypy.ini for testing and type checking",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_006.1",
          "description": "Configure Python project settings in pyproject.toml with build system, project metadata, dependencies (core, optional, dev), package inclusions, CLI scripts, and tool-specific configurations for pytest, ruff, black, and mypy integration",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "[build-system] section must specify poetry-core>=1.0.0 as build backend",
            "[tool.poetry] section must include name, version, description, authors, readme, license, keywords, and classifiers",
            "Python version constraint must be defined (e.g., ^3.10 for Python 3.10+)",
            "Project must declare packages to include with paths (silmari_rlm_act, planning_pipeline, context_window_array)",
            "Core dependencies must include click>=8.1.0, requests>=2.31.0, numpy>=2.0.0, claude-agent-sdk>=0.1.0",
            "Optional dependencies must be grouped under [tool.poetry.extras] (e.g., baml group for baml-py)",
            "Dev dependencies must include pytest>=8.0.0, hypothesis, pytest-asyncio, pytest-cov, black, ruff",
            "[tool.poetry.scripts] must define CLI entry point (silmari-rlm-act = silmari_rlm_act.cli:main)",
            "[tool.pytest.ini_options] must configure asyncio_mode=auto and testpaths for all test directories",
            "[tool.ruff] must configure line-length=100, target-version=py310, and lint rules (E, F, I, W with E501 ignored)",
            "[tool.black] must configure line-length=100 and target-version for py310, py311, py312",
            "File must be valid TOML syntax and parseable by poetry commands",
            "Running 'poetry install' must successfully install all dependencies",
            "Running 'poetry build' must successfully create distribution packages",
            "CLI command must be accessible after installation (silmari-rlm-act --help works)"
          ],
          "implementation": {
            "frontend": [
              "N/A - Configuration file only"
            ],
            "backend": [
              "N/A - Configuration file only"
            ],
            "middleware": [
              "N/A - Configuration file only"
            ],
            "shared": [
              "Create/update pyproject.toml in project root",
              "Define build-system with poetry-core backend",
              "Configure project metadata (name, version, description, authors, license, readme)",
              "Define package inclusions with paths to all distributable packages",
              "Declare core runtime dependencies with version constraints",
              "Declare optional dependency groups under [tool.poetry.extras]",
              "Declare development dependencies under [tool.poetry.group.dev.dependencies]",
              "Configure CLI entry points under [tool.poetry.scripts]",
              "Configure pytest settings: asyncio mode, fixture scope, test paths",
              "Configure ruff linter: line length, target version, select/ignore rules",
              "Configure black formatter: line length, target Python versions",
              "Ensure all tool configurations are compatible with each other",
              "Validate TOML syntax with poetry check command",
              "Document any project-specific configuration decisions in comments"
            ]
          },
          "testable_properties": [],
          "function_id": "ConfigurationManagement.configurePyprojectToml",
          "related_concepts": [
            "Poetry build system",
            "Python packaging standards (PEP 621)",
            "Semantic versioning",
            "Dependency management with extras",
            "CLI entry points",
            "Code formatting and linting configuration",
            "Test configuration integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.2",
          "description": "Configure Go module dependencies with go.mod for module declaration and version requirements, and go.sum for cryptographic checksums of module dependencies to ensure reproducible builds and dependency integrity",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "go.mod must declare module path (github.com/silmari/context-engine)",
            "go.mod must specify Go version requirement (go 1.25.1 or compatible)",
            "go.mod must list all required dependencies with versions in require block",
            "Direct dependencies must be explicitly marked (no // indirect comment)",
            "Indirect dependencies must be marked with // indirect comment",
            "Current dependencies must include: github.com/google/uuid v1.6.0, github.com/spf13/cobra v1.10.2, github.com/spf13/pflag v1.0.9, golang.org/x/sync v0.19.0",
            "go.sum must contain cryptographic checksums (h1:) for all dependencies and their transitive dependencies",
            "go.sum must include checksums for both module content (.../go.mod) and module zip (.../module@version)",
            "Running 'go mod verify' must pass without errors",
            "Running 'go mod tidy' must not change the files (files are already tidy)",
            "Running 'go build ./...' must successfully compile all Go packages",
            "All dependency versions must be resolvable from Go module proxy",
            "go.sum entries must match the exact versions specified in go.mod"
          ],
          "implementation": {
            "frontend": [
              "N/A - Configuration files only"
            ],
            "backend": [
              "N/A - Configuration files only"
            ],
            "middleware": [
              "N/A - Configuration files only"
            ],
            "shared": [
              "Create/update go.mod in project root with module declaration",
              "Specify Go language version (minimum required version)",
              "Declare direct dependencies in require block without // indirect",
              "Allow go mod tidy to add indirect dependencies automatically",
              "Ensure dependency versions use semantic versioning (vX.Y.Z)",
              "Create/update go.sum with cryptographic checksums for all dependencies",
              "Include checksums for both .../go.mod files and .../zip files",
              "Verify checksum format: algorithm:base64-encoded-hash (e.g., h1:...)",
              "Run 'go mod verify' to validate all checksums match downloaded code",
              "Run 'go mod tidy' to remove unused dependencies and add missing ones",
              "Document module purpose and major dependencies in module-level comments",
              "Ensure GOPROXY and GOSUMDB environment variables are set appropriately for builds",
              "Commit both go.mod and go.sum to version control (both required for reproducibility)",
              "Test dependency resolution: 'go list -m all' should list all dependencies without errors"
            ]
          },
          "testable_properties": [],
          "function_id": "ConfigurationManagement.configureGoModules",
          "related_concepts": [
            "Go modules system",
            "Semantic import versioning",
            "Dependency resolution",
            "Checksum verification",
            "Module proxy and sumdb",
            "Minimal version selection (MVS)",
            "Direct vs indirect dependencies"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.3",
          "description": "Configure container orchestration with docker-compose.yml defining services, volumes, environment variables, build context, networking, and runtime settings for Claude Code development environment with workspace mounting and persistent configuration",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "docker-compose.yml must specify version: '3.8' or compatible",
            "Service 'claude-code' must be defined with appropriate build context and dockerfile",
            "Build context must be set to '.' (project root) and dockerfile to 'Dockerfile'",
            "Container name must be 'claude-code-dev' for easy identification",
            "Project directory must be mounted as bind mount: .:/workspace",
            "Claude config directory must be mounted as named volume: claude-config:/root/.config/claude",
            "Git config must be mounted as named volume: git-config:/root/.gitconfig (optional for git operations)",
            "ANTHROPIC_API_KEY environment variable must be injected from .env file with default empty string",
            "PYTHONUNBUFFERED=1 environment variable must be set for real-time Python output",
            "CONTEXT_ENGINE_PATH=/workspace environment variable must be set for project path reference",
            "Working directory must be set to /workspace inside container",
            "stdin_open: true and tty: true must be enabled for interactive sessions",
            "Container must stay running with command: tail -f /dev/null",
            "Named volumes must be defined in volumes section with local driver",
            "Running 'docker-compose up -d' must successfully start the container",
            "Running 'docker-compose exec claude-code bash' must provide interactive shell",
            "Mounted workspace must reflect real-time file changes from host",
            "Claude config must persist across container restarts"
          ],
          "implementation": {
            "frontend": [
              "N/A - Container configuration only"
            ],
            "backend": [
              "N/A - Container configuration only"
            ],
            "middleware": [
              "N/A - Container configuration only"
            ],
            "shared": [
              "Create/update docker-compose.yml in project root",
              "Set Docker Compose file version to 3.8 or compatible",
              "Define 'claude-code' service with build configuration",
              "Set build context to '.' and dockerfile path to 'Dockerfile'",
              "Assign container_name as 'claude-code-dev'",
              "Configure bind mount for project directory: .:/workspace (enables live code editing)",
              "Configure named volume for Claude config: claude-config:/root/.config/claude (persists MCP settings)",
              "Configure named volume for git config: git-config:/root/.gitconfig (persists git user settings)",
              "Set environment variables: ANTHROPIC_API_KEY from .env with fallback, PYTHONUNBUFFERED=1, CONTEXT_ENGINE_PATH=/workspace",
              "Set working_dir to /workspace for default command execution context",
              "Enable stdin_open and tty for interactive terminal access",
              "Set command to 'tail -f /dev/null' to keep container running",
              "Define named volumes in volumes section with local driver",
              "Create .env.example file documenting required environment variables",
              "Validate YAML syntax with docker-compose config command",
              "Test container startup: docker-compose up -d",
              "Test interactive access: docker-compose exec claude-code bash",
              "Test workspace mounting: create file in host, verify in container",
              "Test volume persistence: create config in container, restart, verify persistence",
              "Document usage instructions in README or docker-compose.yml comments"
            ]
          },
          "testable_properties": [],
          "function_id": "ConfigurationManagement.configureDockerCompose",
          "related_concepts": [
            "Docker Compose version 3.8",
            "Container orchestration",
            "Volume mounting and persistence",
            "Environment variable injection",
            "Build context and Dockerfile",
            "Container networking",
            "Development environment consistency",
            "Docker volumes vs bind mounts"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.4",
          "description": "Configure test settings in pytest.ini for async test execution and test discovery, and type checking in mypy.ini with exclusions for generated code, import handling, and strict type checking rules for Python codebase quality assurance",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "pytest.ini must configure asyncio_mode = auto for automatic async test detection",
            "pytest.ini must configure asyncio_default_fixture_loop_scope = function for fixture isolation",
            "pytest.ini configuration must be consistent with [tool.pytest.ini_options] in pyproject.toml",
            "mypy.ini must exclude baml_client directory from type checking using regex pattern",
            "mypy.ini must set ignore_missing_imports = True to handle third-party packages without stubs",
            "mypy.ini must configure warn_return_any = False to reduce noise from untyped APIs",
            "mypy.ini must configure warn_unused_ignores = True to catch unnecessary type: ignore comments",
            "mypy.ini must configure strict_optional = True for proper None handling",
            "mypy.ini must have specific section [mypy-baml_client.*] with ignore_errors = True",
            "Running 'pytest' must discover and execute all tests in configured testpaths",
            "Async tests must execute without asyncio warnings or event loop issues",
            "Running 'mypy .' must check all non-excluded Python files",
            "mypy must not report errors for excluded baml_client directory",
            "mypy must not fail due to missing imports from third-party packages",
            "Type checking must pass on all core application code (non-generated)",
            "Configuration files must be parseable by respective tools (pytest --collect-only, mypy --version)"
          ],
          "implementation": {
            "frontend": [
              "N/A - Configuration files only"
            ],
            "backend": [
              "N/A - Configuration files only"
            ],
            "middleware": [
              "N/A - Configuration files only"
            ],
            "shared": [
              "Create/update pytest.ini in project root",
              "Configure [pytest] section with asyncio_mode = auto",
              "Configure asyncio_default_fixture_loop_scope = function for isolated async fixtures",
              "Ensure pytest.ini settings align with [tool.pytest.ini_options] in pyproject.toml (avoid conflicts)",
              "Create/update mypy.ini in project root",
              "Configure [mypy] section with exclude pattern for generated code: exclude = (?x)(^baml_client/.*$)",
              "Set ignore_missing_imports = True to handle packages without type stubs",
              "Set warn_return_any = False to reduce false positives from untyped third-party APIs",
              "Set warn_unused_ignores = True to maintain clean type: ignore comments",
              "Set strict_optional = True to enforce proper Optional[T] and None handling",
              "Add specific [mypy-baml_client.*] section with ignore_errors = True for generated BAML code",
              "Document rationale for each configuration setting in comments",
              "Test pytest configuration: run 'pytest --collect-only' to verify test discovery",
              "Test async configuration: run sample async test to verify no event loop warnings",
              "Test mypy configuration: run 'mypy .' to verify type checking works on core code",
              "Verify baml_client exclusion: ensure mypy doesn't report errors from generated code",
              "Verify missing imports handling: ensure mypy doesn't fail on third-party packages without stubs",
              "Add type hints to at least one module and verify mypy catches type errors",
              "Document testing and type checking workflows in developer documentation",
              "Consider adding pre-commit hooks for pytest and mypy to enforce quality checks"
            ]
          },
          "testable_properties": [],
          "function_id": "ConfigurationManagement.configureTestingAndTypeChecking",
          "related_concepts": [
            "Pytest configuration",
            "Async test execution with pytest-asyncio",
            "Test discovery patterns",
            "Static type checking with mypy",
            "Type stub files and protocols",
            "Generated code exclusion",
            "Type checking strictness levels",
            "Import resolution in type checkers"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    }
  ],
  "metadata": {
    "source": "agent_sdk_decomposition",
    "research_length": 7005,
    "decomposition_stats": {
      "requirements_found": 7,
      "subprocesses_expanded": 28,
      "total_nodes": 35,
      "extraction_time_ms": 16962,
      "expansion_time_ms": 587411
    },
    "source_research": "thoughts/searchable/research/2026-01-14-project-structure.md",
    "decomposed_at": "2026-01-14T14:20:20.717729"
  }
}